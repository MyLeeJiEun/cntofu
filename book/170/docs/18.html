
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>1.17. 神经网络模型（有监督）-scikit-learn (sklearn) 官方文档中文版</title>
<meta content='1.17. 神经网络模型（有监督）,scikit-learn (sklearn) 官方文档中文版' name='keywords'>
<meta content='1.17. 神经网络模型（有监督）,scikit-learn (sklearn) 官方文档中文版' name='description'>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=1, user-scalable=no"../../../>
<meta name="applicable-device" content="pc,mobile">
<link rel="shortcut icon" href="../../../favicon.ico" type="image/x-icon" />
<meta name="renderer" content="webkit">
<link rel="stylesheet" href="../../../static/components/uikit-2.27.5/css/uikit.custom.css">
<link rel="stylesheet" href="../../../static/components/social-share/social-share.min.css">
<link rel="stylesheet" href="../../../static/components/highlight/styles/custom.css">
<link rel="stylesheet" href="../../../static/components/css/base.css">
<link rel="stylesheet" href="../../../static/components/css/reader.css">
<link rel="stylesheet" href="../../../static/components/css/markdown.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5313208362165053" crossorigin="anonymous"></script>
</head>
<body>
<div class=" book-main-wrap uk-container uk-container-center uk-margin-top ">
<div class="uk-grid">
<div class="uk-width-1-1 reader-wrap ">
<div class=" bottom-nav uk-clearfix ">
<div class="uk-align-left ">
<a href="../../../book/170/docs/17.html">
<i class="nav-icon-left uk-icon-small  uk-icon-caret-left"></i>
<span class="">1.16. 概率校准</span>
</a>
</div>
<div class="uk-align-right ">
<a href="../../../book/170/docs/19.html">
<span class="">2. 无监督学习</span>
<i class="nav-icon-right uk-icon-small  uk-icon-caret-right"></i>
</a>
</div>
</div>
<div class="uk-text-center">
<h2 class="book-page-title uk-container-center">
<a href="../../../book/170/index.html">scikit-learn (sklearn) 官方文档中文版</a>
<a target="_blank" rel="nofollow" href="https://github.com/apachecn/scikit-learn-doc-zh" class="uk-icon-button uk-icon-github" title="github项目地址"></a>
</h2>
</div>
<script type="text/javascript" src="../../../static/components/js/app_intro.js"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5313208362165053" data-ad-slot="1328047120"></ins>
<script>(adsbygoogle =window.adsbygoogle ||[]).push({});</script>
<hr class="uk-article-divider">
<div class="book-content-section  md-content-section  uk-margin-bottom">
<h1 id="117-神经网络模型有监督">1.17. 神经网络模型（有监督）</h1>
<p>校验者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/tiantian1412">@tiantian1412</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@火星</a> 翻译者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@A</a></p>
<p>Warning</p>
<p>此实现不适用于大规模数据应用。 特别是 scikit-learn 不支持 GPU。如果想要提高运行速度并使用基于 GPU 的实现以及为构建深度学习架构提供更多灵活性的框架，请参阅 <a href="../related_projects.html#related-projects">Related Projects</a> 。</p>
<h2 id="1171-多层感知器">1.17.1. 多层感知器</h2>
<p><strong>多层感知器(MLP)</strong> 是一种监督学习算法，通过在数据集上训练来学习函数 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/fd6f65ce4fb7491d7628d1ce576c19d4.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/fd6f65ce4fb7491d7628d1ce576c19d4.jpg" alt="f(\cdot): Rm \rightarrow Ro"></a>，其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/94156b879a7455cb0d516efa9c9c0991.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/94156b879a7455cb0d516efa9c9c0991.jpg" alt="m"></a> 是输入的维数，<a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f7f0b321634c8d80ceacdc75ee3c68b6.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f7f0b321634c8d80ceacdc75ee3c68b6.jpg" alt="o"></a> 是输出的维数。 给定一组特征 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d7228aff11bb03497e40badd984560a6.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d7228aff11bb03497e40badd984560a6.jpg" alt="X = {x_1, x_2, ..., x_m}"></a> 和标签 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0775c03fc710a24df297dedcec515aaf.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0775c03fc710a24df297dedcec515aaf.jpg" alt="y"></a> ，它可以学习用于分类或回归的非线性函数。 与逻辑回归不同的是，在输入层和输出层之间，可以有一个或多个非线性层，称为隐藏层。 图1 展示了一个具有标量输出的单隐藏层 MLP。</p>
<p><a href="http://sklearn.apachecn.org/cn/0.19.0/_images/multilayerperceptron_network.png"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a060693e746caf8e0ff030ed5411520f.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a060693e746caf8e0ff030ed5411520f.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/multilayerperceptron_network.png"></a></a></p>
<p><strong>图1：单隐藏层MLP.</strong></p>
<p>最左层的输入层由一组代表输入特征的神经元 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/3cc550ecff73666ed35ae1efee48b4f4.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/3cc550ecff73666ed35ae1efee48b4f4.jpg" alt="\{x_i | x_1, x_2, ..., x_m\}"></a> 组成。 每个隐藏层中的神经元将前一层的值进行加权线性求和转换 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f1fb5834480bfa9770be94da12bbd514.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f1fb5834480bfa9770be94da12bbd514.jpg" alt="w_1x_1 + w_2x_2 + ... + w_mx_m"></a> ，再通过非线性激活函数 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/80a5660d27392922e501744cab3623da.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/80a5660d27392922e501744cab3623da.jpg" alt="g(\cdot):R \rightarrow R"></a> - 比如双曲正切函数 tanh 。 输出层接收到的值是最后一个隐藏层的输出经过变换而来的。</p>
<p>该模块包含公共属性 <code>coefs_</code> 和 <code>intercepts_</code> 。 <code>coefs_</code> 是一系列权重矩阵，其中下标为 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"></a> 的权重矩阵表示第 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"></a> 层和第 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4aafe42b7f9cf8d06d93b9246d01bbfd.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4aafe42b7f9cf8d06d93b9246d01bbfd.jpg" alt="i+1"></a> 层之间的权重。 <code>intercepts_</code> 是一系列偏置向量，其中的下标为 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"></a> 的向量表示添加到第 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4aafe42b7f9cf8d06d93b9246d01bbfd.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4aafe42b7f9cf8d06d93b9246d01bbfd.jpg" alt="i+1"></a> 层的偏置值。</p>
<p>多层感知器的优点:</p>
<blockquote>
<ul>
<li>可以学习得到非线性模型。</li>
<li>使用<code>partial_fit</code> 可以学习得到实时模型(在线学习)。</li>
</ul>
</blockquote>
<p>多层感知器(MLP)的缺点:</p>
<blockquote>
<ul>
<li>具有隐藏层的 MLP 具有非凸的损失函数，它有不止一个的局部最小值。 因此不同的随机权重初始化会导致不同的验证集准确率。</li>
<li>MLP 需要调试一些超参数，例如隐藏层神经元的数量、层数和迭代轮数。</li>
<li>MLP 对特征归一化很敏感.</li>
</ul>
</blockquote>
<p>解决这些缺点的方法请参阅 <a href="#mlp-tips">实用使用技巧</a> 部分。</p>
<h2 id="1172-分类">1.17.2. 分类</h2>
<blockquote>
<p><a href="generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier" title="sklearn.neural_network.MLPClassifier"><code>MLPClassifier</code></a> 类实现了通过 <a href="http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm">Backpropagation</a> 进行训练的多层感知器（MLP）算法。</p>
</blockquote>
<p>MLP 在两个 array 上进行训练:大小为 (n_samples, n_features) 的 array X 储存表示训练样本的浮点型特征向量; 大小为 (n_samples,) 的 array y 储存训练样本的目标值（类别标签）:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.neural_network import MLPClassifier
&gt;&gt;&gt; X = [[0., 0.], [1., 1.]]
&gt;&gt;&gt; y = [0, 1]
&gt;&gt;&gt; clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
...                     hidden_layer_sizes=(5, 2), random_state=1)
...
&gt;&gt;&gt; clf.fit(X, y)                         
MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',
 beta_1=0.9, beta_2=0.999, early_stopping=False,
 epsilon=1e-08, hidden_layer_sizes=(5, 2), learning_rate='constant',
 learning_rate_init=0.001, max_iter=200, momentum=0.9,
 nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,
 solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,
 warm_start=False)

</code></pre>
<p>拟合（训练）后，该模型可以预测新样本的标签:</p>
<pre><code class="language-py">&gt;&gt;&gt; clf.predict([[2., 2.], [-1., -2.]])
array([1, 0])

</code></pre>
<p>MLP 可以为训练数据拟合一个非线性模型。 <code>clf.coefs_</code> 包含了构建模型的权值矩阵:</p>
<pre><code class="language-py">&gt;&gt;&gt; [coef.shape for coef in clf.coefs_]
[(2, 5), (5, 2), (2, 1)]

</code></pre>
<p>目前， <a href="generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier" title="sklearn.neural_network.MLPClassifier"><code>MLPClassifier</code></a> 只支持交叉熵损失函数，通过运行 <code>predict_proba</code> 方法进行概率估计。</p>
<p>MLP 算法使用的是反向传播的方式。 更准确地说，它使用了通过反向传播计算得到的梯度和某种形式的梯度下降来进行训练。 对于分类来说，它最小化交叉熵损失函数，为每个样本 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/5c82dbae35dc43d2f556f9f284d9d184.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/5c82dbae35dc43d2f556f9f284d9d184.jpg" alt="x"></a> 给出一个向量形式的概率估计 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/3cca81fd08a4732dc7061cd246b323ed.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/3cca81fd08a4732dc7061cd246b323ed.jpg" alt="P(y|x)"></a></p>
<pre><code class="language-py">&gt;&gt;&gt; clf.predict_proba([[2., 2.], [1., 2.]])  
array([[  1.967...e-04,   9.998...-01],
 [  1.967...e-04,   9.998...-01]])

</code></pre>
<p><a href="generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier" title="sklearn.neural_network.MLPClassifier"><code>MLPClassifier</code></a> 通过应用 <a href="https://en.wikipedia.org/wiki/Softmax_activation_function">Softmax</a> 作为输出函数来支持多分类。</p>
<p>此外，该模型支持 <a href="multiclass.html#multiclass">多标签分类</a> ，一个样本可能属于多个类别。 对于每个类，原始输出经过 logistic 函数变换后，大于或等于 0.5 的值将进为 1，否则为 0。 对于样本的预测输出，值为 1 的索引位置表示该样本的分类类别:</p>
<pre><code class="language-py">&gt;&gt;&gt; X = [[0., 0.], [1., 1.]]
&gt;&gt;&gt; y = [[0, 1], [1, 1]]
&gt;&gt;&gt; clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
...                     hidden_layer_sizes=(15,), random_state=1)
...
&gt;&gt;&gt; clf.fit(X, y)                         
MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',
 beta_1=0.9, beta_2=0.999, early_stopping=False,
 epsilon=1e-08, hidden_layer_sizes=(15,), learning_rate='constant',
 learning_rate_init=0.001, max_iter=200, momentum=0.9,
 nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,
 solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,
 warm_start=False)
&gt;&gt;&gt; clf.predict([[1., 2.]])
array([[1, 1]])
&gt;&gt;&gt; clf.predict([[0., 0.]])
array([[0, 1]])

</code></pre>
<p>更多内容请参阅下面的示例和文档 <a href="generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier.fit" title="sklearn.neural_network.MLPClassifier.fit"><code>MLPClassifier.fit</code></a> 。</p>
<p>示例:</p>
<ul>
<li><a href="../auto_examples/neural_networks/plot_mlp_training_curves.html#sphx-glr-auto-examples-neural-networks-plot-mlp-training-curves-py">Compare Stochastic learning strategies for MLPClassifier</a></li>
<li><a href="../auto_examples/neural_networks/plot_mnist_filters.html#sphx-glr-auto-examples-neural-networks-plot-mnist-filters-py">Visualization of MLP weights on MNIST</a></li>
</ul>
<h2 id="1173-回归">1.17.3. 回归</h2>
<p><a href="generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor" title="sklearn.neural_network.MLPRegressor"><code>MLPRegressor</code></a> 类多层感知器（MLP）的实现，在使用反向传播进行训练时的输出层没有使用激活函数，也可以看作是使用恒等函数（identity function）作为激活函数。 因此，它使用平方误差作为损失函数，输出是一组连续值。</p>
<p><a href="generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor" title="sklearn.neural_network.MLPRegressor"><code>MLPRegressor</code></a> 还支持多输出回归，其中一个样本可以有多个目标值。</p>
<h2 id="1174-正则化">1.17.4. 正则化</h2>
<p><a href="generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor" title="sklearn.neural_network.MLPRegressor"><code>MLPRegressor</code></a> 类和 <a href="generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier" title="sklearn.neural_network.MLPClassifier"><code>MLPClassifier</code></a> 类都使用参数 <code>alpha</code> 作为正则化( L2 正则化)系数，正则化通过惩罚大数量级的权重值以避免过拟合问题。 下面的图表展示了不同的 alpha 值下的决策函数的变化。</p>
<p><a href="../auto_examples/neural_networks/plot_mlp_alpha.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/cfe45a2d171ae9c5933cd6d48cd48cb0.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/cfe45a2d171ae9c5933cd6d48cd48cb0.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_mlp_alpha_0011.png"></a></a></p>
<p>详细信息，请参阅下面的示例。</p>
<p>示例:</p>
<ul>
<li><a href="../auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py">Varying regularization in Multi-layer Perceptron</a></li>
</ul>
<h2 id="1175-算法">1.17.5. 算法</h2>
<p>MLP 使用 <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent（随机梯度下降）(SGD)</a>, <a href="http://arxiv.org/abs/1412.6980">Adam</a>, 或者 <a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS">L-BFGS</a> 进行训练。 随机梯度下降（SGD） 使用关于需要适应的一个参数的损失函数的梯度来更新参数，即</p>
<pre><code class="language-py">
![w \leftarrow w - \eta (\alpha \frac{\partial R(w)}{\partial w}
+ \frac{\partial Loss}{\partial w})](img/cdc5ef75d769259ef0537940296ab0b4.jpg)

</code></pre>
<p>其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/fe1d79339349f9b6263e123094ffce7b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/fe1d79339349f9b6263e123094ffce7b.jpg" alt="\eta"></a> 是控制训练过程参数更新步长的学习率（learning rate）。 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/16622481c2bbb001363e20660b549ae9.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/16622481c2bbb001363e20660b549ae9.jpg" alt="Loss"></a> 是损失函数（loss function）。</p>
<p>更多细节可以在这个文档中找到 <a href="http://scikit-learn.org/stable/modules/sgd.html">SGD</a> 。</p>
<p>Adam 类似于 SGD，因为它是 stochastic optimizer （随机优化器），但它可以根据低阶矩的自适应估计自动调整参数更新的量。</p>
<p>使用 SGD 或 Adam ，训练过程支持在线模式和小批量学习模式。</p>
<p>L-BFGS 是利用 Hessian 矩阵来近似函数的二阶偏导数的求解器，它使用 Hessian 的逆矩阵来近似进行参数更新。 该实现使用 Scipy 版本的 <a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html">L-BFGS</a>。</p>
<p>如果所选择的方法是 ‘L-BFGS’，训练过程不支持在线学习模式和小批量学习模式。</p>
<h2 id="1176-复杂度">1.17.6. 复杂度</h2>
<p>假设有 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 个训练样本， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/94156b879a7455cb0d516efa9c9c0991.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/94156b879a7455cb0d516efa9c9c0991.jpg" alt="m"></a> 个特征， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a> 个隐藏层，每个包含 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c5f49595b56010ad04fce358940848e5.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c5f49595b56010ad04fce358940848e5.jpg" alt="h"></a> 个神经元 - 为简单起见， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f7f0b321634c8d80ceacdc75ee3c68b6.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f7f0b321634c8d80ceacdc75ee3c68b6.jpg" alt="o"></a> 个输出神经元。 反向传播的时间复杂度是 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/9ef5bf146675caa32b298d7e8318fc43.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/9ef5bf146675caa32b298d7e8318fc43.jpg" alt="O(n\cdot m \cdot h^k \cdot o \cdot i)"></a> ，其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"></a> 是迭代次数。 由于反向传播具有高时间复杂性，最好以较少数量的隐藏层神经元和较少的隐藏层个数开始训练。</p>
<h2 id="1177-数学公式">1.17.7. 数学公式</h2>
<p>给出一组训练样本 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/ad854ab6b0056f9b521d823a98548d3f.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/ad854ab6b0056f9b521d823a98548d3f.jpg" alt="(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)"></a> 其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/1f1667a67d885f419222cbd85c70dd56.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/1f1667a67d885f419222cbd85c70dd56.jpg" alt="x_i \in \mathbf{R}^n"></a> ， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6a8621a4ada40acd48b43436ca6a4527.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6a8621a4ada40acd48b43436ca6a4527.jpg" alt="y_i \in \{0, 1\}"></a> ，一个单隐藏层单神经元 MLP 学习到的函数是 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d2fed0ae8e2b987a781ee01a92c31dfb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d2fed0ae8e2b987a781ee01a92c31dfb.jpg" alt="f(x) = W_2 g(W_1^T x + b_1) + b_2"></a> ，其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/77eee205b1d286584f4002a39c9b32a3.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/77eee205b1d286584f4002a39c9b32a3.jpg" alt="W_1 \in \mathbf{R}^m"></a> 和 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/855d4e5dae2b0286042ee7eef0c91ab5.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/855d4e5dae2b0286042ee7eef0c91ab5.jpg" alt="W_2, b_1, b_2 \in \mathbf{R}"></a> 是模型参数. <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4609693b88f682790da8203535625471.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4609693b88f682790da8203535625471.jpg" alt="W_1, W_2"></a> 分别是输入层与隐藏层之间和隐藏层与输出层之间的权重， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/09ed5f467366506cf3b8d425d00db588.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/09ed5f467366506cf3b8d425d00db588.jpg" alt="b_1, b_2"></a> 分别是隐藏层和输出层的偏置值. <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f7129cf20abc58eaa0e261335a7606a6.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f7129cf20abc58eaa0e261335a7606a6.jpg" alt="g(\cdot) : R \rightarrow R"></a> 是激活函数，默认为双曲正切函数。 具体形式如下，</p>
<p><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f72a2f9f160a11abc8568b72386776fe.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f72a2f9f160a11abc8568b72386776fe.jpg" alt="g(z)= \frac{ez-e{-z}}{ez+e{-z}}"></a></p>
<p>对于二分类， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/da2ce2d49bbab0c389600d1c82fccf9b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/da2ce2d49bbab0c389600d1c82fccf9b.jpg" alt="f(x)"></a> 经过 logistic 函数 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/05c3632395ec8941c82954de930b9d3e.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/05c3632395ec8941c82954de930b9d3e.jpg" alt="g(z)=1/(1+e^{-z})"></a> 得到 0 到 1 之间的输出值。 阈值设置为 0.5 ，输出大于等于 0.5 的样本分到 positive class （正类），其他的分为 negative class （负类）。</p>
<p>如果多于两类，则 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/da2ce2d49bbab0c389600d1c82fccf9b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/da2ce2d49bbab0c389600d1c82fccf9b.jpg" alt="f(x)"></a> 本身将是一个大小为 (n_classes,) 的向量。 它需要经过 softmax 函数而不是 logistic 函数进行变换，具体形式如下，</p>
<p><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/2d4c303729e327500afa8bdb343713ff.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/2d4c303729e327500afa8bdb343713ff.jpg" alt="\text{softmax}(z)i = \frac{\exp(z_i)}{\sum{l=1}^k\exp(z_l)}"></a></p>
<p>其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e0532dc18cc4c92c2b39f4b29d33cd13.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e0532dc18cc4c92c2b39f4b29d33cd13.jpg" alt="z_i"></a> 表示 softmax 函数的第 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"></a> 个输入的元素，它对应于第 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"></a> 类， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e279b8169ddd6581c5606c868ba52fae.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e279b8169ddd6581c5606c868ba52fae.jpg" alt="K"></a> 是类别的数量。 计算结果是样本 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/5c82dbae35dc43d2f556f9f284d9d184.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/5c82dbae35dc43d2f556f9f284d9d184.jpg" alt="x"></a> 属于每个类别的概率的向量。 最终输出的分类结果是具有最高概率的类别。</p>
<p>在回归问题中，输出依然是 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/da2ce2d49bbab0c389600d1c82fccf9b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/da2ce2d49bbab0c389600d1c82fccf9b.jpg" alt="f(x)"></a> ;因此，输出激活函数就是恒等函数。</p>
<p>MLP 根据特定问题使用不同的损失函数。 二分类问题的损失函数的是交叉熵，具体形式如下，</p>
<p><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a201561ab545f4fd9cba5a2e0eae9a94.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a201561ab545f4fd9cba5a2e0eae9a94.jpg" alt="Loss(\hat{y},y,W) = -y \ln {\hat{y}} - (1-y) \ln{(1-\hat{y})} + \alpha ||W||_2^2"></a></p>
<p>其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/1f7b275b5002d3772b809055d9199f91.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/1f7b275b5002d3772b809055d9199f91.jpg" alt="\alpha ||W||_2^2"></a> 是 L2 正则化的模型复杂度惩罚项; <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/11cde057716cf1a820780a60c8ffa8e4.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/11cde057716cf1a820780a60c8ffa8e4.jpg" alt="\alpha > 0"></a> 这个非负的超参数控制惩罚的程度。</p>
<p>对于回归问题，MLP 使用平方误差损失函数，具体形式如下，</p>
<p><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/929e25fd2cb34bf9709d68d266786fd3.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/929e25fd2cb34bf9709d68d266786fd3.jpg" alt="Loss(\hat{y},y,W) = \frac{1}{2}||\hat{y} - y ||_22 + \frac{\alpha}{2} ||W||_22"></a></p>
<p>从随机初始化权重开始，多层感知器（MLP）不断更新这些权重值来最小化损失函数。计算完损失之后，从输出层到前面各层进行反向传播，更新权重参数的值，旨在减小损失函数。</p>
<p>在梯度下降中，计算得到损失函数关于每个权重的梯度 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/9ca39b9e9aa5f1a4660e45f3c9b5ef7b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/9ca39b9e9aa5f1a4660e45f3c9b5ef7b.jpg" alt="\nabla Loss_{W}"></a> 并从权重 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/369b6e6bd43ee84fe99e14c8d78cdc9f.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/369b6e6bd43ee84fe99e14c8d78cdc9f.jpg" alt="W"></a> 中减掉。用公式表示为，</p>
<p><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/92e5a41435bd53653e9ad36f030cbd61.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/92e5a41435bd53653e9ad36f030cbd61.jpg" alt="W{i+1} = Wi - \epsilon \nabla {Loss}_{W}^{i}"></a></p>
<p>其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"></a> 是当前迭代步数， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/58ef9e1b5d2ee139dcb588a3879ca1a6.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/58ef9e1b5d2ee139dcb588a3879ca1a6.jpg" alt="\epsilon"></a> 是大于 0 学习率。</p>
<p>算法停止的条件或者是达到预设的最大迭代次数，或者是损失函数低于某个特定值。</p>
<h2 id="1178-实用技巧">1.17.8. 实用技巧</h2>
<blockquote>
<ul>
<li>多层感知器对特征的缩放是敏感的，所以它强烈建议您归一化你的数据。 例如，将输入向量 X 的每个属性放缩到到 [0, 1] 或 [-1，+1] ，或者将其标准化使它具有 0 均值和方差 1。</li>
</ul>
<p>注意，为了得到有意义的结果，您必须对测试集也应用 <em>相同的</em> 尺度缩放。 您可以使用 <code>StandardScaler</code> 进行标准化。</p>
<p>&gt; <code>py &amp;gt; &amp;gt;&amp;gt;&amp;gt; from sklearn.preprocessing import StandardScaler &amp;gt; &amp;gt;&amp;gt;&amp;gt; scaler = StandardScaler() &amp;gt; &amp;gt;&amp;gt;&amp;gt; # Don't cheat - fit only on training data &amp;gt; &amp;gt;&amp;gt;&amp;gt; scaler.fit(X_train) &amp;gt; &amp;gt;&amp;gt;&amp;gt; X_train = scaler.transform(X_train) &amp;gt; &amp;gt;&amp;gt;&amp;gt; # apply same transformation to test data &amp;gt; &amp;gt;&amp;gt;&amp;gt; X_test = scaler.transform(X_test) &amp;gt; &amp;gt;</code> &gt; &gt; 另一个推荐的方法是在 <code>Pipeline</code> 中使用的 <code>StandardScaler</code> 。</p>
<ul>
<li>最好使用 <code>GridSearchCV</code> 找到一个合理的正则化参数 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d8b3d5242d513369a44f8bf0c6112744.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d8b3d5242d513369a44f8bf0c6112744.jpg" alt="\alpha"></a> ，通常范围是在 <code>10.0 ** -np.arange(1, 7)</code> 。</li>
<li>据经验可知，我们观察到 &lt;cite&gt;L-BFGS&lt;/cite&gt; 收敛速度是更快的并且是小数据集上更好的解决方案。对于规模相对比较大的数据集，&lt;cite&gt;Adam&lt;/cite&gt; 是非常鲁棒的。 它通常会迅速收敛，并得到相当不错的表现。</li>
</ul>
<p>另一方面，如果学习率调整得正确， 使用 momentum 或 nesterov’s momentum 的 &lt;cite&gt;SGD&lt;/cite&gt; 可以比这两种算法更好。</p>
</blockquote>
<h2 id="1179-使用-warm-start-的更多控制">1.17.9. 使用 warm_start 的更多控制</h2>
<p>如果您希望更多地控制 SGD 中的停止标准或学习率，或者想要进行额外的监视，使用 <code>warm_start=True</code> 和 <code>max_iter=1</code> 并且自身迭代可能会有所帮助:</p>
<pre><code class="language-py">&gt;&gt;&gt; X = [[0., 0.], [1., 1.]]
&gt;&gt;&gt; y = [0, 1]
&gt;&gt;&gt; clf = MLPClassifier(hidden_layer_sizes=(15,), random_state=1, max_iter=1, warm_start=True)
&gt;&gt;&gt; for i in range(10):
...     clf.fit(X, y)
...     # additional monitoring / inspection 
MLPClassifier(...

</code></pre>
<p>参考文献:</p>
<ul>
<li><a href="http://www.iro.umontreal.ca/~pift6266/A06/refs/backprop_old.pdf">“Learning representations by back-propagating errors.”</a> Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams.</li>
<li><a href="http://leon.bottou.org/projects/sgd">“Stochastic Gradient Descent”</a> L. Bottou - Website, 2010.</li>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm">“Backpropagation”</a> Andrew Ng, Jiquan Ngiam, Chuan Yu Foo, Yifan Mai, Caroline Suen - Website, 2011.</li>
<li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">“Efficient BackProp”</a> Y. LeCun, L. Bottou, G. Orr, K. Müller - In Neural Networks: Tricks of the Trade 1998.</li>
<li><a href="http://arxiv.org/pdf/1412.6980v8.pdf">“Adam: A method for stochastic optimization.”</a> Kingma, Diederik, and Jimmy Ba. arXiv preprint arXiv:1412.6980 (2014).</li>
</ul>
</div>
<hr class="uk-article-divider">
<div class="uk-block uk-block-muted uk-padding-top-remove uk-padding-bottom-remove uk-margin-large-top  book-recommend-wrap">
<div class="uk-margin-top uk-margin-bottom uk-margin-left uk-margin-right">
<div class="uk-margin uk-text-muted "><i class="uk-icon-outdent uk-icon-justify uk-margin-small-right"></i>书籍推荐</div>
<div class="books">
<ul class="uk-book-list">
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/162/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/162/index.html">Python方向综合面试题</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/92.html">jackfrued</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">115页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 35个">35</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/74/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/74/index.html">Python进阶</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/46.html">东滨社</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">73页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月8日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 2664个">2664</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/166/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/166/index.html">What the f*ck Python中文版</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/95.html">leisurelicht</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">70页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 7300个">7300</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/167/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/git_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/167/index.html">Git 菜单-高质量的 Git 中文教程</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/96.html">geeeeeeeeek</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="git">git</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">1页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 11199个">11199</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/64/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/code_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/64/index.html">免费的编程中文书籍索引</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/40.html">justjavac</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="code">code</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">56页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月5日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 33914个">33914</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/31/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/linux_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/31/index.html">操作系统思考</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/15.html">wizardforcel</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="linux">linux</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">15页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年5月3日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 74个">74</span>
</div>
</div>
</div>
</li>
<hr>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<nav class="tm-navbar uk-navbar uk-navbar-attached reader-nav">
<div class="uk-float-left uk-margin-small-top">
<a href="javascript:;" title="目录菜单" class="show-menu  uk-icon-hover  uk-icon-align-justify uk-margin-right"></a>
<div data-uk-dropdown="{mode:'click',pos:'bottom-left'}" class="font-setting-wrap">
<a class="uk-icon-hover uk-icon-font uk-margin-right" aria-label="字体设置" href="javascript:;"></a>
<div class="uk-dropdown dropdown-menu">
<div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-reduce">小字</button>
<button class="uk-button-link button size-2 font-enlarge">大字</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-1 ">宋体</button>
<button class="uk-button-link button size-2 font-2 ">黑体</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-3 color-theme-sun "><i class="uk-icon-sun-o"></i>白天</button>
<button class="uk-button-link button size-3 color-theme-eye "><i class="uk-icon-eye"></i>护眼</button>
<button class="uk-button-link button size-3 color-theme-moon "><i class="uk-icon-moon-o"></i>夜晚</button></div>
</div>
</div>
<a class="logo uk-margin-right" href="../../../" title="返回首页"><img class="" src="../../../static/components/images/icon_32.png" /></a>
</div>
<div class="uk-navbar-flip  uk-hidden-small">
<div id="share-box"></div>
</div>
</nav>
<div id="menu-id" class="uk-offcanvas reader-offcanvas">
<div class="uk-offcanvas-bar">
<ul class="book-menu-bar uk-nav uk-nav-offcanvas" data-uk-nav>
<li>
<a href="../../../book/170/index.html" data-book-page-rel-url="index.html" data-book-page-id="0" title="封面">封面</a>
</li>
<li>
<a class="pjax" href="../../../book/170/readme.html" data-book-page-rel-url="readme.html" data-book-page-id="0" title="简介">简介</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/79.html" title="安装 scikit-learn" data-book-page-rel-url="docs/79.html" data-book-page-id="11491">安装 scikit-learn</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/1.html" title="1. 监督学习" data-book-page-rel-url="docs/1.html" data-book-page-id="11492">1. 监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/2.html" title="1.1. 广义线性模型" data-book-page-rel-url="docs/2.html" data-book-page-id="11493">1.1. 广义线性模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/3.html" title="1.2. 线性和二次判别分析" data-book-page-rel-url="docs/3.html" data-book-page-id="11494">1.2. 线性和二次判别分析</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/4.html" title="1.3. 内核岭回归" data-book-page-rel-url="docs/4.html" data-book-page-id="11495">1.3. 内核岭回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/5.html" title="1.4. 支持向量机" data-book-page-rel-url="docs/5.html" data-book-page-id="11496">1.4. 支持向量机</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/6.html" title="1.5. 随机梯度下降" data-book-page-rel-url="docs/6.html" data-book-page-id="11497">1.5. 随机梯度下降</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/7.html" title="1.6. 最近邻" data-book-page-rel-url="docs/7.html" data-book-page-id="11498">1.6. 最近邻</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/8.html" title="1.7. 高斯过程" data-book-page-rel-url="docs/8.html" data-book-page-id="11499">1.7. 高斯过程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/9.html" title="1.8. 交叉分解" data-book-page-rel-url="docs/9.html" data-book-page-id="11500">1.8. 交叉分解</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/10.html" title="1.9. 朴素贝叶斯" data-book-page-rel-url="docs/10.html" data-book-page-id="11501">1.9. 朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/11.html" title="1.10. 决策树" data-book-page-rel-url="docs/11.html" data-book-page-id="11502">1.10. 决策树</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/12.html" title="1.11. 集成方法" data-book-page-rel-url="docs/12.html" data-book-page-id="11503">1.11. 集成方法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/13.html" title="1.12. 多类和多标签算法" data-book-page-rel-url="docs/13.html" data-book-page-id="11504">1.12. 多类和多标签算法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/14.html" title="1.13. 特征选择" data-book-page-rel-url="docs/14.html" data-book-page-id="11505">1.13. 特征选择</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/15.html" title="1.14. 半监督学习" data-book-page-rel-url="docs/15.html" data-book-page-id="11506">1.14. 半监督学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/16.html" title="1.15. 等式回归" data-book-page-rel-url="docs/16.html" data-book-page-id="11507">1.15. 等式回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/17.html" title="1.16. 概率校准" data-book-page-rel-url="docs/17.html" data-book-page-id="11508">1.16. 概率校准</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/18.html" title="1.17. 神经网络模型（有监督）" data-book-page-rel-url="docs/18.html" data-book-page-id="11509">1.17. 神经网络模型（有监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/19.html" title="2. 无监督学习" data-book-page-rel-url="docs/19.html" data-book-page-id="11510">2. 无监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/20.html" title="2.1. 高斯混合模型" data-book-page-rel-url="docs/20.html" data-book-page-id="11511">2.1. 高斯混合模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/21.html" title="2.2. 流形学习" data-book-page-rel-url="docs/21.html" data-book-page-id="11512">2.2. 流形学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/22.html" title="2.3. 聚类" data-book-page-rel-url="docs/22.html" data-book-page-id="11513">2.3. 聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/23.html" title="2.4. 双聚类" data-book-page-rel-url="docs/23.html" data-book-page-id="11514">2.4. 双聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/24.html" title="2.5. 分解成分中的信号（矩阵分解问题）" data-book-page-rel-url="docs/24.html" data-book-page-id="11515">2.5. 分解成分中的信号（矩阵分解问题）</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/25.html" title="2.6. 协方差估计" data-book-page-rel-url="docs/25.html" data-book-page-id="11516">2.6. 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/26.html" title="2.7. 经验协方差" data-book-page-rel-url="docs/26.html" data-book-page-id="11517">2.7. 经验协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/27.html" title="2.8. 收敛协方差" data-book-page-rel-url="docs/27.html" data-book-page-id="11518">2.8. 收敛协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/28.html" title="2.9. 稀疏逆协方差" data-book-page-rel-url="docs/28.html" data-book-page-id="11519">2.9. 稀疏逆协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/29.html" title="2.10. Robust 协方差估计" data-book-page-rel-url="docs/29.html" data-book-page-id="11520">2.10. Robust 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/30.html" title="2.11. 新奇和异常值检测" data-book-page-rel-url="docs/30.html" data-book-page-id="11521">2.11. 新奇和异常值检测</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/31.html" title="2.12. 密度估计" data-book-page-rel-url="docs/31.html" data-book-page-id="11522">2.12. 密度估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/32.html" title="2.13. 神经网络模型（无监督）" data-book-page-rel-url="docs/32.html" data-book-page-id="11523">2.13. 神经网络模型（无监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/33.html" title="3. 模型选择和评估" data-book-page-rel-url="docs/33.html" data-book-page-id="11524">3. 模型选择和评估</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/34.html" title="3.1. 交叉验证：评估估算器的表现" data-book-page-rel-url="docs/34.html" data-book-page-id="11525">3.1. 交叉验证：评估估算器的表现</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/35.html" title="3.2. 调整估计器的超参数" data-book-page-rel-url="docs/35.html" data-book-page-id="11526">3.2. 调整估计器的超参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/53.html" title="3.3. 模型评估: 量化预测的质量" data-book-page-rel-url="docs/53.html" data-book-page-id="11527">3.3. 模型评估: 量化预测的质量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/54.html" title="3.4. 模型持久化" data-book-page-rel-url="docs/54.html" data-book-page-id="11528">3.4. 模型持久化</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/55.html" title="3.5. 验证曲线: 绘制分数以评估模型" data-book-page-rel-url="docs/55.html" data-book-page-id="11529">3.5. 验证曲线: 绘制分数以评估模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/56.html" title="4. 数据集转换" data-book-page-rel-url="docs/56.html" data-book-page-id="11530">4. 数据集转换</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/57.html" title="4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器" data-book-page-rel-url="docs/57.html" data-book-page-id="11531">4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/58.html" title="4.2. 特征提取" data-book-page-rel-url="docs/58.html" data-book-page-id="11532">4.2. 特征提取</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/59.html" title="4.3. 预处理数据" data-book-page-rel-url="docs/59.html" data-book-page-id="11533">4.3. 预处理数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/60.html" title="4.4. 无监督降维" data-book-page-rel-url="docs/60.html" data-book-page-id="11534">4.4. 无监督降维</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/61.html" title="4.5. 随机投影" data-book-page-rel-url="docs/61.html" data-book-page-id="11535">4.5. 随机投影</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/62.html" title="4.6. 内核近似" data-book-page-rel-url="docs/62.html" data-book-page-id="11536">4.6. 内核近似</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/63.html" title="4.7. 成对的矩阵, 类别和核函数" data-book-page-rel-url="docs/63.html" data-book-page-id="11537">4.7. 成对的矩阵, 类别和核函数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/64.html" title="4.8. 预测目标 (`y`.html) 的转换" data-book-page-rel-url="docs/64.html" data-book-page-id="11538">4.8. 预测目标 (`y`.html) 的转换</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/65.html" title="5. 数据集加载工具" data-book-page-rel-url="docs/65.html" data-book-page-id="11539">5. 数据集加载工具</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/66.html" title="6. 大规模计算的策略: 更大量的数据" data-book-page-rel-url="docs/66.html" data-book-page-id="11540">6. 大规模计算的策略: 更大量的数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/67.html" title="7. 计算性能" data-book-page-rel-url="docs/67.html" data-book-page-id="11541">7. 计算性能</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/68.html" title="使用 scikit-learn 介绍机器学习" data-book-page-rel-url="docs/68.html" data-book-page-id="11542">使用 scikit-learn 介绍机器学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/69.html" title="关于科学数据处理的统计学习教程" data-book-page-rel-url="docs/69.html" data-book-page-id="11543">关于科学数据处理的统计学习教程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/70.html" title="机器学习: scikit-learn 中的设置以及预估对象" data-book-page-rel-url="docs/70.html" data-book-page-id="11544">机器学习: scikit-learn 中的设置以及预估对象</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/71.html" title="监督学习：从高维观察预测输出变量" data-book-page-rel-url="docs/71.html" data-book-page-id="11545">监督学习：从高维观察预测输出变量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/72.html" title="模型选择：选择估计量及其参数" data-book-page-rel-url="docs/72.html" data-book-page-id="11546">模型选择：选择估计量及其参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/73.html" title="无监督学习: 寻求数据表示" data-book-page-rel-url="docs/73.html" data-book-page-id="11547">无监督学习: 寻求数据表示</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/74.html" title="把它们放在一起" data-book-page-rel-url="docs/74.html" data-book-page-id="11548">把它们放在一起</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/75.html" title="寻求帮助" data-book-page-rel-url="docs/75.html" data-book-page-id="11549">寻求帮助</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/76.html" title="处理文本数据" data-book-page-rel-url="docs/76.html" data-book-page-id="11550">处理文本数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/77.html" title="选择正确的评估器(estimator.html)" data-book-page-rel-url="docs/77.html" data-book-page-id="11551">选择正确的评估器(estimator.html)</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/78.html" title="外部资源，视频和谈话" data-book-page-rel-url="docs/78.html" data-book-page-id="11552">外部资源，视频和谈话</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/80.html" title="常见问题" data-book-page-rel-url="docs/80.html" data-book-page-id="11553">常见问题</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/81.html" title="时光轴" data-book-page-rel-url="docs/81.html" data-book-page-id="11554">时光轴</a>
</li>
</ul>
</div>
</div>
<script src="https://cdn.staticfile.net/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="../../../static/components/uikit-2.27.5/js/uikit.reader.js"></script>
<script type="text/javascript" src="../../../static/components/social-share/social-share.min.js"></script>
<script>(function(){var bp =document.createElement('script');var curProtocol =window.location.protocol.split(':')[0];if (curProtocol ==='https') {bp.src ='https://zz.bdstatic.com/linksubmit/push.js';}
else {bp.src ='http://push.zhanzhang.baidu.com/push.js';}
var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp,s);})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
<script src="https://cdn.staticfile.net/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.net/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script src="https://cdn.staticfile.net/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="https://cdn.staticfile.net/uikit/2.27.5/js/components/lightbox.min.js"></script>
<link rel="dns-prefetch" href="../../..//cdn.mathjax.org" />
<script type="text/x-mathjax-config">
 function initMathJax() {
    var mathId = $("book-content-section")[0];
    MathJax.Hub.Config({
        tex2jax: {skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a']},
        showProcessingMessages: false,
        messageStyle: "none"
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub,mathId]);
 };
initMathJax();
</script>
<script src='https://cdn.staticfile.net/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML' async></script>
<style>
	.MathJax_Display{display:inline!important;}
</style>
<script type="text/javascript" src="../../../static/components/js/reader.js"></script>
<script type="text/javascript">var bookId =170;var bookPageId =11509;var bookPageRelUrl ='docs/18.html';</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
</body>
</html>