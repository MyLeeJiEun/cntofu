
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>3.1. 交叉验证：评估估算器的表现-scikit-learn (sklearn) 官方文档中文版</title>
<meta content='3.1. 交叉验证：评估估算器的表现,scikit-learn (sklearn) 官方文档中文版' name='keywords'>
<meta content='3.1. 交叉验证：评估估算器的表现,scikit-learn (sklearn) 官方文档中文版' name='description'>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=1, user-scalable=no"../../../>
<meta name="applicable-device" content="pc,mobile">
<link rel="shortcut icon" href="../../../favicon.ico" type="image/x-icon" />
<meta name="renderer" content="webkit">
<link rel="stylesheet" href="../../../static/components/uikit-2.27.5/css/uikit.custom.css">
<link rel="stylesheet" href="../../../static/components/social-share/social-share.min.css">
<link rel="stylesheet" href="../../../static/components/highlight/styles/custom.css">
<link rel="stylesheet" href="../../../static/components/css/base.css">
<link rel="stylesheet" href="../../../static/components/css/reader.css">
<link rel="stylesheet" href="../../../static/components/css/markdown.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5313208362165053" crossorigin="anonymous"></script>
</head>
<body>
<div class=" book-main-wrap uk-container uk-container-center uk-margin-top ">
<div class="uk-grid">
<div class="uk-width-1-1 reader-wrap ">
<div class=" bottom-nav uk-clearfix ">
<div class="uk-align-left ">
<a href="../../../book/170/docs/33.html">
<i class="nav-icon-left uk-icon-small  uk-icon-caret-left"></i>
<span class="">3. 模型选择和评估</span>
</a>
</div>
<div class="uk-align-right ">
<a href="../../../book/170/docs/35.html">
<span class="">3.2. 调整估计器的..</span>
<i class="nav-icon-right uk-icon-small  uk-icon-caret-right"></i>
</a>
</div>
</div>
<div class="uk-text-center">
<h2 class="book-page-title uk-container-center">
<a href="../../../book/170/index.html">scikit-learn (sklearn) 官方文档中文版</a>
<a target="_blank" rel="nofollow" href="https://github.com/apachecn/scikit-learn-doc-zh" class="uk-icon-button uk-icon-github" title="github项目地址"></a>
</h2>
</div>
<script type="text/javascript" src="../../../static/components/js/app_intro.js"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5313208362165053" data-ad-slot="1328047120"></ins>
<script>(adsbygoogle =window.adsbygoogle ||[]).push({});</script>
<hr class="uk-article-divider">
<div class="book-content-section  md-content-section  uk-margin-bottom">
<h1 id="31-交叉验证评估估算器的表现">3.1. 交叉验证：评估估算器的表现</h1>
<p>校验者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@想和太阳肩并肩</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@樊雯</a> 翻译者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@\SRY/</a></p>
<p>学习预测函数的参数，并在相同数据集上进行测试是一种错误的做法: 一个仅给出测试用例标签的模型将会获得极高的分数，但对于尚未出现过的数据它则无法预测出任何有用的信息。 这种情况称为 <strong>overfitting（过拟合）</strong>. 为了避免这种情况，在进行（监督）机器学习实验时，通常取出部分可利用数据作为 <strong>test set（测试数据集）</strong> <code>X_test, y_test</code>。</p>
<p>需要强调的是这里说的 “experiment(实验)” 并不仅限于学术（academic），因为即使是在商业场景下机器学习也往往是从实验开始的。</p>
<p>利用 scikit-learn 包中的 <a href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code>train_test_split</code></a> 辅助函数可以很快地将实验数据集划分为任何训练集（training sets）和测试集（test sets）。 下面让我们载入 iris 数据集，并在此数据集上训练出线性支持向量机:</p>
<pre><code class="language-py">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; from sklearn import datasets
&gt;&gt;&gt; from sklearn import svm

&gt;&gt;&gt; iris = datasets.load_iris()
&gt;&gt;&gt; iris.data.shape, iris.target.shape
((150, 4), (150,))

</code></pre>
<p>我们能快速采样到原数据集的 40% 作为测试集，从而测试（评估）我们的分类器:</p>
<pre><code class="language-py">&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     iris.data, iris.target, test_size=0.4, random_state=0)

&gt;&gt;&gt; X_train.shape, y_train.shape
((90, 4), (90,))
&gt;&gt;&gt; X_test.shape, y_test.shape
((60, 4), (60,))

&gt;&gt;&gt; clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
&gt;&gt;&gt; clf.score(X_test, y_test)                           
0.96...

</code></pre>
<p>当评价估计器的不同设置（”hyperparameters(超参数)”）时，例如手动为 SVM 设置的 <code>C</code> 参数， 由于在训练集上，通过调整参数设置使估计器的性能达到了最佳状态；但 <em>在测试集上</em> 可能会出现过拟合的情况。 此时，测试集上的信息反馈足以颠覆训练好的模型，评估的指标不再有效反映出模型的泛化性能。 为了解决此类问题，还应该准备另一部分被称为 “validation set(验证集)” 的数据集，模型训练完成以后在验证集上对模型进行评估。 当验证集上的评估实验比较成功时，在测试集上进行最后的评估。</p>
<p>然而，通过将原始数据分为3个数据集合，我们就大大减少了可用于模型学习的样本数量， 并且得到的结果依赖于集合对（训练，验证）的随机选择。</p>
<p>这个问题可以通过 <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">交叉验证（CV 缩写）</a> 来解决。 交叉验证仍需要测试集做最后的模型评估，但不再需要验证集。</p>
<p>最基本的方法被称之为，<em>k-折交叉验证</em> 。 k-折交叉验证将训练集划分为 k 个较小的集合（其他方法会在下面描述，主要原则基本相同）。 每一个 <em>k</em> 折都会遵循下面的过程：</p>
<blockquote>
<ul>
<li>将 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/51d052e3e4c7f694f3c05eb4159ba243.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/51d052e3e4c7f694f3c05eb4159ba243.jpg" alt="k-1"></a> 份训练集子集作为 training data （训练集）训练模型，</li>
<li>将剩余的 1 份训练集子集作为验证集用于模型验证（也就是利用该数据集计算模型的性能指标，例如准确率）。</li>
</ul>
</blockquote>
<p><em>k</em>-折交叉验证得出的性能指标是循环计算中每个值的平均值。 该方法虽然计算代价很高，但是它不会浪费太多的数据（如固定任意测试集的情况一样）， 在处理样本数据集较少的问题（例如，逆向推理）时比较有优势。</p>
<h2 id="311-计算交叉验证的指标">3.1.1. 计算交叉验证的指标</h2>
<p>使用交叉验证最简单的方法是在估计器和数据集上调用 <a href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code>cross_val_score</code></a> 辅助函数。</p>
<p>下面的例子展示了如何通过分割数据，拟合模型和计算连续 5 次的分数（每次不同分割）来估计 linear kernel 支持向量机在 iris 数据集上的精度:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import cross_val_score
&gt;&gt;&gt; clf = svm.SVC(kernel='linear', C=1)
&gt;&gt;&gt; scores = cross_val_score(clf, iris.data, iris.target, cv=5)
&gt;&gt;&gt; scores                                              
array([ 0.96...,  1\.  ...,  0.96...,  0.96...,  1\.        ])

</code></pre>
<p>评分估计的平均得分和 95% 置信区间由此给出:</p>
<pre><code class="language-py">&gt;&gt;&gt; print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
Accuracy: 0.98 (+/- 0.03)

</code></pre>
<p>默认情况下，每个 CV 迭代计算的分数是估计器的 <code>score</code> 方法。可以通过使用 scoring 参数来改变计算方式如下:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn import metrics
&gt;&gt;&gt; scores = cross_val_score(
...     clf, iris.data, iris.target, cv=5, scoring='f1_macro')
&gt;&gt;&gt; scores                                              
array([ 0.96...,  1\.  ...,  0.96...,  0.96...,  1\.        ])

</code></pre>
<p>详情请参阅 <a href="model_evaluation.html#scoring-parameter">scoring 参数: 定义模型评估规则</a> 。 在 Iris 数据集的情形下，样本在各个目标类别之间是平衡的，因此准确度和 F1-score 几乎相等。</p>
<p>当 <code>cv</code> 参数是一个整数时， <a href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code>cross_val_score</code></a> 默认使用 <a href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> 或 <a href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code>StratifiedKFold</code></a> 策略，后者会在估计器派生自 <a href="generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><code>ClassifierMixin</code></a> 时使用。</p>
<p>也可以通过传入一个交叉验证迭代器来使用其他交叉验证策略，比如:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import ShuffleSplit
&gt;&gt;&gt; n_samples = iris.data.shape[0]
&gt;&gt;&gt; cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)
&gt;&gt;&gt; cross_val_score(clf, iris.data, iris.target, cv=cv)
...                                                     
array([ 0.97...,  0.97...,  1\.        ])

</code></pre>
<p>保留数据的数据转换</p>
<p>正如在训练集中保留的数据上测试一个 predictor （预测器）是很重要的一样，预处理（如标准化，特征选择等）和类似的 <a href="../data_transforms.html#data-transforms">data transformations</a> 也应该从训练集中学习，并应用于预测数据以进行预测:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn import preprocessing
&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     iris.data, iris.target, test_size=0.4, random_state=0)
&gt;&gt;&gt; scaler = preprocessing.StandardScaler().fit(X_train)
&gt;&gt;&gt; X_train_transformed = scaler.transform(X_train)
&gt;&gt;&gt; clf = svm.SVC(C=1).fit(X_train_transformed, y_train)
&gt;&gt;&gt; X_test_transformed = scaler.transform(X_test)
&gt;&gt;&gt; clf.score(X_test_transformed, y_test)  
0.9333...

</code></pre>
<p><a href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a> 可以更容易地组合估计器，在交叉验证下使用如下:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.pipeline import make_pipeline
&gt;&gt;&gt; clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))
&gt;&gt;&gt; cross_val_score(clf, iris.data, iris.target, cv=cv)
...                                                 
array([ 0.97...,  0.93...,  0.95...])

</code></pre>
<p>可以参阅 <a href="pipeline.html#combining-estimators">Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器</a>.</p>
<h3 id="3111-cross-validate-函数和多度量评估">3.1.1.1. cross_validate 函数和多度量评估</h3>
<p><code>cross_validate</code> 函数与 <code>cross_val_score</code> 在下面的两个方面有些不同 -</p>
<ul>
<li>它允许指定多个指标进行评估.</li>
<li>除了测试得分之外，它还会返回一个包含训练得分，拟合次数， score-times （得分次数）的一个字典。 It returns a dict containing training scores, fit-times and score-times in addition to the test score.</li>
</ul>
<p>对于单个度量评估，其中 scoring 参数是一个字符串，可以调用或 None ， keys 将是 - <code>['test_score', 'fit_time', 'score_time']</code></p>
<p>而对于多度量评估，返回值是一个带有以下的 keys 的字典 - <code>['test_&amp;lt;scorer1_name&amp;gt;', 'test_&amp;lt;scorer2_name&amp;gt;', 'test_&amp;lt;scorer...&amp;gt;', 'fit_time', 'score_time']</code></p>
<p><code>return_train_score</code> 默认设置为 <code>True</code> 。 它增加了所有 scorers(得分器) 的训练得分 keys 。如果不需要训练 scores ，则应将其明确设置为 <code>False</code> 。</p>
<p>可以将多个指标指定为 predefined scorer names（预定义的得分器的名称） list ，tuple 或者 set</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import cross_validate
&gt;&gt;&gt; from sklearn.metrics import recall_score
&gt;&gt;&gt; scoring = ['precision_macro', 'recall_macro']
&gt;&gt;&gt; clf = svm.SVC(kernel='linear', C=1, random_state=0)
&gt;&gt;&gt; scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,
...                         cv=5, return_train_score=False)
&gt;&gt;&gt; sorted(scores.keys())
['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']
&gt;&gt;&gt; scores['test_recall_macro']                       
array([ 0.96...,  1\.  ...,  0.96...,  0.96...,  1\.        ])

</code></pre>
<p>或作为一个字典 mapping 得分器名称预定义或自定义的得分函数:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.metrics.scorer import make_scorer
&gt;&gt;&gt; scoring = {'prec_macro': 'precision_macro',
...            'rec_micro': make_scorer(recall_score, average='macro')}
&gt;&gt;&gt; scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,
...                         cv=5, return_train_score=True)
&gt;&gt;&gt; sorted(scores.keys())                 
['fit_time', 'score_time', 'test_prec_macro', 'test_rec_micro',
 'train_prec_macro', 'train_rec_micro']
&gt;&gt;&gt; scores['train_rec_micro']                         
array([ 0.97...,  0.97...,  0.99...,  0.98...,  0.98...])

</code></pre>
<p>这里是一个使用单一指标的 <code>cross_validate</code> 的例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; scores = cross_validate(clf, iris.data, iris.target,
...                         scoring='precision_macro')
&gt;&gt;&gt; sorted(scores.keys())
['fit_time', 'score_time', 'test_score', 'train_score']

</code></pre>
<h3 id="3112-通过交叉验证获取预测">3.1.1.2. 通过交叉验证获取预测</h3>
<p>除了返回结果不同，函数 <a href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code>cross_val_predict</code></a> 具有和 <a href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code>cross_val_score</code></a> 相同的接口， 对于每一个输入的元素，如果其在测试集合中，将会得到预测结果。交叉验证策略会将可用的元素提交到测试集合有且仅有一次（否则会抛出一个异常）。</p>
<p>这些预测可以用于评价分类器的效果:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import cross_val_predict
&gt;&gt;&gt; predicted = cross_val_predict(clf, iris.data, iris.target, cv=10)
&gt;&gt;&gt; metrics.accuracy_score(iris.target, predicted) 
0.973...

</code></pre>
<p>注意，这个计算的结果和 <a href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code>cross_val_score</code></a> 有轻微的差别，因为后者用另一种方式组织元素。</p>
<p>可用的交叉验证迭代器在下面的部分中。</p>
<p>示例</p>
<ul>
<li><a href="../auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py">Receiver Operating Characteristic (ROC) with cross validation</a>,</li>
<li><a href="../auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py">Recursive feature elimination with cross-validation</a>,</li>
<li><a href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py">Parameter estimation using grid search with cross-validation</a>,</li>
<li><a href="../auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py">Sample pipeline for text feature extraction and evaluation</a>,</li>
<li><a href="../auto_examples/plot_cv_predict.html#sphx-glr-auto-examples-plot-cv-predict-py">绘制交叉验证预测图</a>,</li>
<li><a href="../auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py">Nested versus non-nested cross-validation</a>.</li>
</ul>
<h2 id="312-交叉验证迭代器">3.1.2. 交叉验证迭代器</h2>
<p>接下来的部分列出了一些用于生成索引标号，用于在不同的交叉验证策略中生成数据划分的工具。</p>
<h2 id="313-交叉验证迭代器循环遍历数据">3.1.3. 交叉验证迭代器–循环遍历数据</h2>
<p>假设一些数据是独立的和相同分布的 (i.i.d) 假定所有的样本来源于相同的生成过程，并假设生成过程没有记忆过去生成的样本。</p>
<p>在这种情况下可以使用下面的交叉验证器。</p>
<p><strong>注意</strong></p>
<p>而 i.i.d 数据是机器学习理论中的一个常见假设，在实践中很少成立。如果知道样本是使用时间相关的过程生成的，则使用 <a href="#timeseries-cv">time-series aware cross-validation scheme</a> 更安全。 同样，如果我们知道生成过程具有 group structure （群体结构）（从不同 subjects（主体） ， experiments（实验）， measurement devices （测量设备）收集的样本），则使用 <a href="#group-cv">group-wise cross-validation</a> 更安全。</p>
<h3 id="3131-k-折">3.1.3.1. K 折</h3>
<p><a href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> 将所有的样例划分为 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a> 个组，称为折叠 (fold) （如果 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/2953c3498ec0877c5ebcc172050cce88.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/2953c3498ec0877c5ebcc172050cce88.jpg" alt="k = n"></a>， 这等价于 <em>Leave One Out（留一）</em> 策略），都具有相同的大小（如果可能）。预测函数学习时使用 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/79b52c5c00ce59ba04383f6a0d670c6d.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/79b52c5c00ce59ba04383f6a0d670c6d.jpg" alt="k - 1"></a> 个折叠中的数据，最后一个剩下的折叠会用于测试。</p>
<p>在 4 个样例的数据集上使用 2-fold 交叉验证的例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import KFold

&gt;&gt;&gt; X = ["a", "b", "c", "d"]
&gt;&gt;&gt; kf = KFold(n_splits=2)
&gt;&gt;&gt; for train, test in kf.split(X):
...     print("%s  %s" % (train, test))
[2 3] [0 1]
[0 1] [2 3]

</code></pre>
<p>每个折叠由两个 arrays 组成，第一个作为 <em>training set</em> ，另一个作为 <em>test set</em> 。 由此，可以通过使用 numpy 的索引创建训练/测试集合:</p>
<pre><code class="language-py">&gt;&gt;&gt; X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])
&gt;&gt;&gt; y = np.array([0, 1, 0, 1])
&gt;&gt;&gt; X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]

</code></pre>
<h3 id="3132-重复-k-折交叉验证">3.1.3.2. 重复 K-折交叉验证</h3>
<p><a href="generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold" title="sklearn.model_selection.RepeatedKFold"><code>RepeatedKFold</code></a> 重复 K-Fold n 次。当需要运行时可以使用它 <a href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> n 次，在每次重复中产生不同的分割。</p>
<p>2折 K-Fold 重复 2 次的示例:</p>
<pre><code class="language-py">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.model_selection import RepeatedKFold
&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
&gt;&gt;&gt; random_state = 12883823
&gt;&gt;&gt; rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)
&gt;&gt;&gt; for train, test in rkf.split(X):
...     print("%s  %s" % (train, test))
...
[2 3] [0 1]
[0 1] [2 3]
[0 2] [1 3]
[1 3] [0 2]

</code></pre>
<p>类似地， <a href="generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code>RepeatedStratifiedKFold</code></a> 在每个重复中以不同的随机化重复 n 次分层的 K-Fold 。</p>
<h3 id="3133-留一交叉验证-loo">3.1.3.3. 留一交叉验证 (LOO)</h3>
<p><a href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code>LeaveOneOut</code></a> (或 LOO) 是一个简单的交叉验证。每个学习集都是通过除了一个样本以外的所有样本创建的，测试集是被留下的样本。 因此，对于 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 个样本，我们有 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 个不同的训练集和 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 个不同的测试集。这种交叉验证程序不会浪费太多数据，因为只有一个样本是从训练集中删除掉的:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import LeaveOneOut

&gt;&gt;&gt; X = [1, 2, 3, 4]
&gt;&gt;&gt; loo = LeaveOneOut()
&gt;&gt;&gt; for train, test in loo.split(X):
...     print("%s  %s" % (train, test))
[1 2 3] [0]
[0 2 3] [1]
[0 1 3] [2]
[0 1 2] [3]

</code></pre>
<p>LOO 潜在的用户选择模型应该权衡一些已知的警告。 当与 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a> 折交叉验证进行比较时，可以从 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 样本中构建 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 模型，而不是 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a> 模型，其中 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/5cc4d35f246f0aeb95f154a5343635c2.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/5cc4d35f246f0aeb95f154a5343635c2.jpg" alt="n > k"></a> 。 此外，每个在 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/06d3f93ccdf3b4b5cd0fea7225848848.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/06d3f93ccdf3b4b5cd0fea7225848848.jpg" alt="n - 1"></a> 个样本而不是在 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/b38aca53acb7894dca026d3325f61a00.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/b38aca53acb7894dca026d3325f61a00.jpg" alt="(k-1) n / k"></a> 上进行训练。在两种方式中，假设 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a> 不是太大，并且 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d6f34fca0b5561181aa5263dbb97df74.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/d6f34fca0b5561181aa5263dbb97df74.jpg" alt="k < n"></a> ， LOO 比 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a> 折交叉验证计算开销更加昂贵。</p>
<p>就精度而言， LOO 经常导致较高的方差作为测试误差的估计器。直观地说，因为 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 个样本中的 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/06d3f93ccdf3b4b5cd0fea7225848848.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/06d3f93ccdf3b4b5cd0fea7225848848.jpg" alt="n - 1"></a> 被用来构建每个模型，折叠构建的模型实际上是相同的，并且是从整个训练集建立的模型。</p>
<p>但是，如果学习曲线对于所讨论的训练大小是陡峭的，那么 5- 或 10- 折交叉验证可以泛化误差增高。</p>
<p>作为一般规则，大多数作者和经验证据表明， 5- 或者 10- 交叉验证应该优于 LOO 。</p>
<p>参考文献:</p>
<ul>
<li><a href="http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html">http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html</a>;</li>
<li>T. Hastie, R. Tibshirani, J. Friedman, <a href="http://statweb.stanford.edu/~tibs/ElemStatLearn">The Elements of Statistical Learning</a>, Springer 2009</li>
<li>L. Breiman, P. Spector <a href="http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf">Submodel selection and evaluation in regression: The X-random case</a>, International Statistical Review 1992;</li>
<li>R. Kohavi, <a href="http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf">A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection</a>, Intl. Jnt. Conf. AI</li>
<li>R. Bharat Rao, G. Fung, R. Rosales, <a href="http://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf">On the Dangers of Cross-Validation. An Experimental Evaluation</a>, SIAM 2008;</li>
<li>G. James, D. Witten, T. Hastie, R Tibshirani, <a href="http://www-bcf.usc.edu/~gareth/ISL">An Introduction to Statistical Learning</a>, Springer 2013.</li>
</ul>
<h3 id="3134-留-p-交叉验证-lpo">3.1.3.4. 留 P 交叉验证 (LPO)</h3>
<p><a href="generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut" title="sklearn.model_selection.LeavePOut"><code>LeavePOut</code></a> 与 <a href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code>LeaveOneOut</code></a> 非常相似，因为它通过从整个集合中删除 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" alt="p"></a> 个样本来创建所有可能的 训练/测试集。对于 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 个样本，这产生了 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c683d0fa5d21d783e383612dda8ecad3.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c683d0fa5d21d783e383612dda8ecad3.jpg" alt="{n \choose p}"></a> 个 训练-测试 对。与 <a href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code>LeaveOneOut</code></a> 和 <a href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> 不同，当 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/aaa84c285eb96ed446fd34be4b51bbec.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/aaa84c285eb96ed446fd34be4b51bbec.jpg" alt="p > 1"></a> 时，测试集会重叠。</p>
<p>在有 4 个样例的数据集上使用 Leave-2-Out 的例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import LeavePOut

&gt;&gt;&gt; X = np.ones(4)
&gt;&gt;&gt; lpo = LeavePOut(p=2)
&gt;&gt;&gt; for train, test in lpo.split(X):
...     print("%s  %s" % (train, test))
[2 3] [0 1]
[1 3] [0 2]
[1 2] [0 3]
[0 3] [1 2]
[0 2] [1 3]
[0 1] [2 3]

</code></pre>
<h3 id="3135-随机排列交叉验证-aka-shuffle--split">3.1.3.5. 随机排列交叉验证 a.k.a. Shuffle &amp; Split</h3>
<p><a href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code>ShuffleSplit</code></a></p>
<p><a href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code>ShuffleSplit</code></a> 迭代器 将会生成一个用户给定数量的独立的训练/测试数据划分。样例首先被打散然后划分为一对训练测试集合。</p>
<p>可以通过设定明确的 <code>random_state</code> ，使得伪随机生成器的结果可以重复。</p>
<p>这是一个使用的小例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import ShuffleSplit
&gt;&gt;&gt; X = np.arange(5)
&gt;&gt;&gt; ss = ShuffleSplit(n_splits=3, test_size=0.25,
...     random_state=0)
&gt;&gt;&gt; for train_index, test_index in ss.split(X):
...     print("%s  %s" % (train_index, test_index))
...
[1 3 4] [2 0]
[1 4 3] [0 2]
[4 0 2] [1 3]

</code></pre>
<p><a href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code>ShuffleSplit</code></a> 可以替代 <a href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> 交叉验证，因为其提供了细致的训练 / 测试划分的 数量和样例所占的比例等的控制。</p>
<h2 id="314-基于类标签具有分层的交叉验证迭代器">3.1.4. 基于类标签、具有分层的交叉验证迭代器</h2>
<p>一些分类问题在目标类别的分布上可能表现出很大的不平衡性：例如，可能会出现比正样本多数倍的负样本。在这种情况下，建议采用如 <a href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code>StratifiedKFold</code></a> 和 <a href="generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit" title="sklearn.model_selection.StratifiedShuffleSplit"><code>StratifiedShuffleSplit</code></a> 中实现的分层抽样方法，确保相对的类别频率在每个训练和验证 折叠 中大致保留。</p>
<h3 id="3141-分层-k-折">3.1.4.1. 分层 k 折</h3>
<p><a href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code>StratifiedKFold</code></a> 是 <em>k-fold</em> 的变种，会返回 <em>stratified（分层）</em> 的折叠：每个小集合中， 各个类别的样例比例大致和完整数据集中相同。</p>
<p>在有 10 个样例的，有两个略不均衡类别的数据集上进行分层 3-fold 交叉验证的例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import StratifiedKFold

&gt;&gt;&gt; X = np.ones(10)
&gt;&gt;&gt; y = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]
&gt;&gt;&gt; skf = StratifiedKFold(n_splits=3)
&gt;&gt;&gt; for train, test in skf.split(X, y):
...     print("%s  %s" % (train, test))
[2 3 6 7 8 9] [0 1 4 5]
[0 1 3 4 5 8 9] [2 6 7]
[0 1 2 4 5 6 7] [3 8 9]

</code></pre>
<p><a href="generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code>RepeatedStratifiedKFold</code></a> 可用于在每次重复中用不同的随机化重复分层 K-Fold n 次。</p>
<h3 id="3142-分层随机-split">3.1.4.2. 分层随机 Split</h3>
<p><a href="generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit" title="sklearn.model_selection.StratifiedShuffleSplit"><code>StratifiedShuffleSplit</code></a> 是 <em>ShuffleSplit</em> 的一个变种，会返回直接的划分，比如： 创建一个划分，但是划分中每个类的比例和完整数据集中的相同。</p>
<h2 id="315-用于分组数据的交叉验证迭代器">3.1.5. 用于分组数据的交叉验证迭代器</h2>
<p>如果潜在的生成过程产生依赖样本的 groups ，那么 i.i.d. 假设将会被打破。</p>
<p>这样的数据分组是特定于域的。一个例子是从多个患者收集医学数据，从每个患者身上采集多个样本。而这样的数据很可能取决于个人群体。 在我们的例子中，每个样本的患者 ID 将是其 group identifier （组标识符）。</p>
<p>在这种情况下，我们想知道在一组特定的 groups 上训练的模型是否能很好地适用于看不见的 group 。为了衡量这一点，我们需要确保验证对象中的所有样本来自配对训练折叠中完全没有表示的组。</p>
<p>下面的交叉验证分离器可以用来做到这一点。 样本的 grouping identifier （分组标识符） 通过 <code>groups</code> 参数指定。</p>
<h3 id="3151-组-k-fold">3.1.5.1. 组 k-fold</h3>
<p><a href="generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code>GroupKFold</code></a> 是 k-fold 的变体，它确保同一个 group 在测试和训练集中都不被表示。 例如，如果数据是从不同的 subjects 获得的，每个 subject 有多个样本，并且如果模型足够灵活以高度人物指定的特征中学习，则可能无法推广到新的 subject 。 <a href="generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code>GroupKFold</code></a> 可以检测到这种过拟合的情况。 Imagine you have three subjects, each with an associated number from 1 to 3:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import GroupKFold

&gt;&gt;&gt; X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]
&gt;&gt;&gt; y = ["a", "b", "b", "b", "c", "c", "c", "d", "d", "d"]
&gt;&gt;&gt; groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

&gt;&gt;&gt; gkf = GroupKFold(n_splits=3)
&gt;&gt;&gt; for train, test in gkf.split(X, y, groups=groups):
...     print("%s  %s" % (train, test))
[0 1 2 3 4 5] [6 7 8 9]
[0 1 2 6 7 8 9] [3 4 5]
[3 4 5 6 7 8 9] [0 1 2]

</code></pre>
<p>每个 subject 都处于不同的测试阶段，同一个科目从来没有在测试和训练过程中。请注意，由于数据不平衡，折叠的大小并不完全相同。</p>
<h3 id="3152-留一组交叉验证">3.1.5.2. 留一组交叉验证</h3>
<p><a href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code>LeaveOneGroupOut</code></a> 是一个交叉验证方案，它根据第三方提供的 array of integer groups （整数组的数组）来提供样本。这个组信息可以用来编码任意域特定的预定义交叉验证折叠。</p>
<p>每个训练集都是由除特定组别以外的所有样本构成的。</p>
<p>例如，在多个实验的情况下， <a href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code>LeaveOneGroupOut</code></a> 可以用来根据不同的实验创建一个交叉验证：我们使用除去一个实验的所有实验的样本创建一个训练集:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import LeaveOneGroupOut

&gt;&gt;&gt; X = [1, 5, 10, 50, 60, 70, 80]
&gt;&gt;&gt; y = [0, 1, 1, 2, 2, 2, 2]
&gt;&gt;&gt; groups = [1, 1, 2, 2, 3, 3, 3]
&gt;&gt;&gt; logo = LeaveOneGroupOut()
&gt;&gt;&gt; for train, test in logo.split(X, y, groups=groups):
...     print("%s  %s" % (train, test))
[2 3 4 5 6] [0 1]
[0 1 4 5 6] [2 3]
[0 1 2 3] [4 5 6]

</code></pre>
<p>另一个常见的应用是使用时间信息：例如，组可以是收集样本的年份，从而允许与基于时间的分割进行交叉验证。</p>
<h3 id="3153-留-p-组交叉验证">3.1.5.3. 留 P 组交叉验证</h3>
<p><a href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code>LeavePGroupsOut</code></a> 类似于 <a href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code>LeaveOneGroupOut</code></a> ，但为每个训练/测试集删除与 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4bfe956324cef23278c5192b0fb8029b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4bfe956324cef23278c5192b0fb8029b.jpg" alt="P"></a> 组有关的样本。</p>
<p>Leave-2-Group Out 的示例:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import LeavePGroupsOut

&gt;&gt;&gt; X = np.arange(6)
&gt;&gt;&gt; y = [1, 1, 1, 2, 2, 2]
&gt;&gt;&gt; groups = [1, 1, 2, 2, 3, 3]
&gt;&gt;&gt; lpgo = LeavePGroupsOut(n_groups=2)
&gt;&gt;&gt; for train, test in lpgo.split(X, y, groups=groups):
...     print("%s  %s" % (train, test))
[4 5] [0 1 2 3]
[2 3] [0 1 4 5]
[0 1] [2 3 4 5]

</code></pre>
<h3 id="3154-group-shuffle-split">3.1.5.4. Group Shuffle Split</h3>
<p><a href="generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit" title="sklearn.model_selection.GroupShuffleSplit"><code>GroupShuffleSplit</code></a> 迭代器是 <a href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code>ShuffleSplit</code></a> 和 <a href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code>LeavePGroupsOut</code></a> 的组合，它生成一个随机划分分区的序列，其中为每个分组提供了一个组子集。</p>
<p>这是使用的示例:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import GroupShuffleSplit

&gt;&gt;&gt; X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]
&gt;&gt;&gt; y = ["a", "b", "b", "b", "c", "c", "c", "a"]
&gt;&gt;&gt; groups = [1, 1, 2, 2, 3, 3, 4, 4]
&gt;&gt;&gt; gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)
&gt;&gt;&gt; for train, test in gss.split(X, y, groups=groups):
...     print("%s  %s" % (train, test))
...
[0 1 2 3] [4 5 6 7]
[2 3 6 7] [0 1 4 5]
[2 3 4 5] [0 1 6 7]
[4 5 6 7] [0 1 2 3]

</code></pre>
<p>当需要 <a href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code>LeavePGroupsOut</code></a> 的操作时，这个类的信息是很有必要的，但是 组 的数目足够大，以至于用 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4bfe956324cef23278c5192b0fb8029b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4bfe956324cef23278c5192b0fb8029b.jpg" alt="P"></a> 组生成所有可能的分区将会花费很大的代价。在这种情况下， <a href="generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit" title="sklearn.model_selection.GroupShuffleSplit"><code>GroupShuffleSplit</code></a> 通过 <a href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code>LeavePGroupsOut</code></a> 提供了一个随机（可重复）的训练 / 测试划分采样。</p>
<h2 id="316-预定义的折叠--验证集">3.1.6. 预定义的折叠 / 验证集</h2>
<p>对一些数据集，一个预定义的，将数据划分为训练和验证集合或者划分为几个交叉验证集合的划分已经存在。 可以使用 <a href="generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit" title="sklearn.model_selection.PredefinedSplit"><code>PredefinedSplit</code></a> 来使用这些集合来搜索超参数。</p>
<p>比如，当使用验证集合时，设置所有验证集合中的样例的 <code>test_fold</code> 为 0，而将其他样例设置为 -1 。</p>
<h2 id="317-交叉验证在时间序列数据中应用">3.1.7. 交叉验证在时间序列数据中应用</h2>
<p>时间序列数据的特点是时间 (<em>autocorrelation(自相关性)</em>) 附近的观测之间的相关性。 然而，传统的交叉验证技术，例如 <a href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> 和 <a href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code>ShuffleSplit</code></a> 假设样本是独立的且分布相同的，并且在时间序列数据上会导致训练和测试实例之间不合理的相关性（产生广义误差的估计较差）。 因此，对 “future(未来)” 观测的时间序列数据模型的评估至少与用于训练模型的观测模型非常重要。为了达到这个目的，一个解决方案是由 <a href="generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><code>TimeSeriesSplit</code></a> 提供的。</p>
<h3 id="3171-时间序列分割">3.1.7.1. 时间序列分割</h3>
<p><a href="generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><code>TimeSeriesSplit</code></a> 是 <em>k-fold</em> 的一个变体，它首先返回 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a> 折作为训练数据集，并且 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/b25f834ac79280901c702fb1449740a3.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/b25f834ac79280901c702fb1449740a3.jpg" alt="(k+1)"></a> 折作为测试数据集。 请注意，与标准的交叉验证方法不同，连续的训练集是超越前者的超集。 另外，它将所有的剩余数据添加到第一个训练分区，它总是用来训练模型。</p>
<p>这个类可以用来交叉验证以固定时间间隔观察到的时间序列数据样本。</p>
<p>对具有 6 个样本的数据集进行 3-split 时间序列交叉验证的示例:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

&gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])
&gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5, 6])
&gt;&gt;&gt; tscv = TimeSeriesSplit(n_splits=3)
&gt;&gt;&gt; print(tscv)  
TimeSeriesSplit(max_train_size=None, n_splits=3)
&gt;&gt;&gt; for train, test in tscv.split(X):
...     print("%s  %s" % (train, test))
[0 1 2] [3]
[0 1 2 3] [4]
[0 1 2 3 4] [5]

</code></pre>
<h2 id="318-a-note-on-shuffling">3.1.8. A note on shuffling</h2>
<p>(如果数据的顺序不是任意的（比如说，相同标签的样例连续出现），为了获得有意义的交叉验证结果，首先对其进行 打散是很有必要的。然而，当样例不是独立同分布时打散则是不可行的。例如：样例是相关的文章，以他们发表的时间 进行排序，这时候如果对数据进行打散，将会导致模型过拟合，得到一个过高的验证分数：因为验证样例更加相似（在时间上更接近） 于训练数据。</p>
<p>一些交叉验证迭代器， 比如 <a href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> ，有一个内建的在划分数据前进行数据索引打散的选项。注意:</p>
<ul>
<li>这种方式仅需要很少的内存就可以打散数据。</li>
<li>默认不会进行打散，包括设置 <code>cv=some_integer</code> （直接）k 折叠交叉验证的 <a href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code>cross_val_score</code></a> ， 表格搜索等。注意 <a href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code>train_test_split</code></a> 会返回一个随机的划分。</li>
<li>参数 <code>random_state</code> 默认设置为 <code>None</code> ，这意为着每次进行 <code>KFold(..., shuffle=True)</code> 时，打散都是不同的。 然而， <code>GridSearchCV</code> 通过调用 <code>fit</code> 方法验证时，将会使用相同的打散来训练每一组参数。</li>
<li>为了保证结果的可重复性（在相同的平台上），应该给 <code>random_state</code> 设定一个固定的值。</li>
</ul>
<h2 id="319-交叉验证和模型选择">3.1.9. 交叉验证和模型选择</h2>
<p>交叉验证迭代器可以通过网格搜索得到最优的模型超参数，从而直接用于模型的选择。 这是另一部分 <a href="grid_search.html#grid-search">调整估计器的超参数</a> 的主要内容。</p>
</div>
<hr class="uk-article-divider">
<div class="uk-block uk-block-muted uk-padding-top-remove uk-padding-bottom-remove uk-margin-large-top  book-recommend-wrap">
<div class="uk-margin-top uk-margin-bottom uk-margin-left uk-margin-right">
<div class="uk-margin uk-text-muted "><i class="uk-icon-outdent uk-icon-justify uk-margin-small-right"></i>书籍推荐</div>
<div class="books">
<ul class="uk-book-list">
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/161/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/161/index.html">关于python的面试题</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/92.html">jackfrued</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">271页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 33个">33</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/172/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/172/index.html">Seaborn 0.9 中文文档</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/18.html">ApacheCN</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">76页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 32个">32</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/162/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/162/index.html">Python方向综合面试题</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/92.html">jackfrued</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">115页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 35个">35</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/206/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/code_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/206/index.html">HTTP/2 标准(RFC 7540)中文版</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/116.html">abbshr</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="code">code</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">1页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2021年10月24日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 374个">374</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/101/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/chrome_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/101/index.html">Chromium中文文档</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/62.html">tzivanmoe</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="chrome">chrome</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">165页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月29日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 0个">0</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/179/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/179/index.html">30秒学会常用Python代码</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/99.html">kriadmin</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">1页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 2716个">2716</span>
</div>
</div>
</div>
</li>
<hr>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<nav class="tm-navbar uk-navbar uk-navbar-attached reader-nav">
<div class="uk-float-left uk-margin-small-top">
<a href="javascript:;" title="目录菜单" class="show-menu  uk-icon-hover  uk-icon-align-justify uk-margin-right"></a>
<div data-uk-dropdown="{mode:'click',pos:'bottom-left'}" class="font-setting-wrap">
<a class="uk-icon-hover uk-icon-font uk-margin-right" aria-label="字体设置" href="javascript:;"></a>
<div class="uk-dropdown dropdown-menu">
<div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-reduce">小字</button>
<button class="uk-button-link button size-2 font-enlarge">大字</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-1 ">宋体</button>
<button class="uk-button-link button size-2 font-2 ">黑体</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-3 color-theme-sun "><i class="uk-icon-sun-o"></i>白天</button>
<button class="uk-button-link button size-3 color-theme-eye "><i class="uk-icon-eye"></i>护眼</button>
<button class="uk-button-link button size-3 color-theme-moon "><i class="uk-icon-moon-o"></i>夜晚</button></div>
</div>
</div>
<a class="logo uk-margin-right" href="../../../" title="返回首页"><img class="" src="../../../static/components/images/icon_32.png" /></a>
</div>
<div class="uk-navbar-flip  uk-hidden-small">
<div id="share-box"></div>
</div>
</nav>
<div id="menu-id" class="uk-offcanvas reader-offcanvas">
<div class="uk-offcanvas-bar">
<ul class="book-menu-bar uk-nav uk-nav-offcanvas" data-uk-nav>
<li>
<a href="../../../book/170/index.html" data-book-page-rel-url="index.html" data-book-page-id="0" title="封面">封面</a>
</li>
<li>
<a class="pjax" href="../../../book/170/readme.html" data-book-page-rel-url="readme.html" data-book-page-id="0" title="简介">简介</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/79.html" title="安装 scikit-learn" data-book-page-rel-url="docs/79.html" data-book-page-id="11491">安装 scikit-learn</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/1.html" title="1. 监督学习" data-book-page-rel-url="docs/1.html" data-book-page-id="11492">1. 监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/2.html" title="1.1. 广义线性模型" data-book-page-rel-url="docs/2.html" data-book-page-id="11493">1.1. 广义线性模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/3.html" title="1.2. 线性和二次判别分析" data-book-page-rel-url="docs/3.html" data-book-page-id="11494">1.2. 线性和二次判别分析</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/4.html" title="1.3. 内核岭回归" data-book-page-rel-url="docs/4.html" data-book-page-id="11495">1.3. 内核岭回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/5.html" title="1.4. 支持向量机" data-book-page-rel-url="docs/5.html" data-book-page-id="11496">1.4. 支持向量机</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/6.html" title="1.5. 随机梯度下降" data-book-page-rel-url="docs/6.html" data-book-page-id="11497">1.5. 随机梯度下降</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/7.html" title="1.6. 最近邻" data-book-page-rel-url="docs/7.html" data-book-page-id="11498">1.6. 最近邻</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/8.html" title="1.7. 高斯过程" data-book-page-rel-url="docs/8.html" data-book-page-id="11499">1.7. 高斯过程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/9.html" title="1.8. 交叉分解" data-book-page-rel-url="docs/9.html" data-book-page-id="11500">1.8. 交叉分解</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/10.html" title="1.9. 朴素贝叶斯" data-book-page-rel-url="docs/10.html" data-book-page-id="11501">1.9. 朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/11.html" title="1.10. 决策树" data-book-page-rel-url="docs/11.html" data-book-page-id="11502">1.10. 决策树</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/12.html" title="1.11. 集成方法" data-book-page-rel-url="docs/12.html" data-book-page-id="11503">1.11. 集成方法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/13.html" title="1.12. 多类和多标签算法" data-book-page-rel-url="docs/13.html" data-book-page-id="11504">1.12. 多类和多标签算法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/14.html" title="1.13. 特征选择" data-book-page-rel-url="docs/14.html" data-book-page-id="11505">1.13. 特征选择</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/15.html" title="1.14. 半监督学习" data-book-page-rel-url="docs/15.html" data-book-page-id="11506">1.14. 半监督学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/16.html" title="1.15. 等式回归" data-book-page-rel-url="docs/16.html" data-book-page-id="11507">1.15. 等式回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/17.html" title="1.16. 概率校准" data-book-page-rel-url="docs/17.html" data-book-page-id="11508">1.16. 概率校准</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/18.html" title="1.17. 神经网络模型（有监督）" data-book-page-rel-url="docs/18.html" data-book-page-id="11509">1.17. 神经网络模型（有监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/19.html" title="2. 无监督学习" data-book-page-rel-url="docs/19.html" data-book-page-id="11510">2. 无监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/20.html" title="2.1. 高斯混合模型" data-book-page-rel-url="docs/20.html" data-book-page-id="11511">2.1. 高斯混合模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/21.html" title="2.2. 流形学习" data-book-page-rel-url="docs/21.html" data-book-page-id="11512">2.2. 流形学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/22.html" title="2.3. 聚类" data-book-page-rel-url="docs/22.html" data-book-page-id="11513">2.3. 聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/23.html" title="2.4. 双聚类" data-book-page-rel-url="docs/23.html" data-book-page-id="11514">2.4. 双聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/24.html" title="2.5. 分解成分中的信号（矩阵分解问题）" data-book-page-rel-url="docs/24.html" data-book-page-id="11515">2.5. 分解成分中的信号（矩阵分解问题）</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/25.html" title="2.6. 协方差估计" data-book-page-rel-url="docs/25.html" data-book-page-id="11516">2.6. 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/26.html" title="2.7. 经验协方差" data-book-page-rel-url="docs/26.html" data-book-page-id="11517">2.7. 经验协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/27.html" title="2.8. 收敛协方差" data-book-page-rel-url="docs/27.html" data-book-page-id="11518">2.8. 收敛协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/28.html" title="2.9. 稀疏逆协方差" data-book-page-rel-url="docs/28.html" data-book-page-id="11519">2.9. 稀疏逆协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/29.html" title="2.10. Robust 协方差估计" data-book-page-rel-url="docs/29.html" data-book-page-id="11520">2.10. Robust 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/30.html" title="2.11. 新奇和异常值检测" data-book-page-rel-url="docs/30.html" data-book-page-id="11521">2.11. 新奇和异常值检测</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/31.html" title="2.12. 密度估计" data-book-page-rel-url="docs/31.html" data-book-page-id="11522">2.12. 密度估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/32.html" title="2.13. 神经网络模型（无监督）" data-book-page-rel-url="docs/32.html" data-book-page-id="11523">2.13. 神经网络模型（无监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/33.html" title="3. 模型选择和评估" data-book-page-rel-url="docs/33.html" data-book-page-id="11524">3. 模型选择和评估</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/34.html" title="3.1. 交叉验证：评估估算器的表现" data-book-page-rel-url="docs/34.html" data-book-page-id="11525">3.1. 交叉验证：评估估算器的表现</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/35.html" title="3.2. 调整估计器的超参数" data-book-page-rel-url="docs/35.html" data-book-page-id="11526">3.2. 调整估计器的超参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/53.html" title="3.3. 模型评估: 量化预测的质量" data-book-page-rel-url="docs/53.html" data-book-page-id="11527">3.3. 模型评估: 量化预测的质量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/54.html" title="3.4. 模型持久化" data-book-page-rel-url="docs/54.html" data-book-page-id="11528">3.4. 模型持久化</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/55.html" title="3.5. 验证曲线: 绘制分数以评估模型" data-book-page-rel-url="docs/55.html" data-book-page-id="11529">3.5. 验证曲线: 绘制分数以评估模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/56.html" title="4. 数据集转换" data-book-page-rel-url="docs/56.html" data-book-page-id="11530">4. 数据集转换</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/57.html" title="4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器" data-book-page-rel-url="docs/57.html" data-book-page-id="11531">4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/58.html" title="4.2. 特征提取" data-book-page-rel-url="docs/58.html" data-book-page-id="11532">4.2. 特征提取</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/59.html" title="4.3. 预处理数据" data-book-page-rel-url="docs/59.html" data-book-page-id="11533">4.3. 预处理数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/60.html" title="4.4. 无监督降维" data-book-page-rel-url="docs/60.html" data-book-page-id="11534">4.4. 无监督降维</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/61.html" title="4.5. 随机投影" data-book-page-rel-url="docs/61.html" data-book-page-id="11535">4.5. 随机投影</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/62.html" title="4.6. 内核近似" data-book-page-rel-url="docs/62.html" data-book-page-id="11536">4.6. 内核近似</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/63.html" title="4.7. 成对的矩阵, 类别和核函数" data-book-page-rel-url="docs/63.html" data-book-page-id="11537">4.7. 成对的矩阵, 类别和核函数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/64.html" title="4.8. 预测目标 (`y`.html) 的转换" data-book-page-rel-url="docs/64.html" data-book-page-id="11538">4.8. 预测目标 (`y`.html) 的转换</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/65.html" title="5. 数据集加载工具" data-book-page-rel-url="docs/65.html" data-book-page-id="11539">5. 数据集加载工具</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/66.html" title="6. 大规模计算的策略: 更大量的数据" data-book-page-rel-url="docs/66.html" data-book-page-id="11540">6. 大规模计算的策略: 更大量的数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/67.html" title="7. 计算性能" data-book-page-rel-url="docs/67.html" data-book-page-id="11541">7. 计算性能</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/68.html" title="使用 scikit-learn 介绍机器学习" data-book-page-rel-url="docs/68.html" data-book-page-id="11542">使用 scikit-learn 介绍机器学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/69.html" title="关于科学数据处理的统计学习教程" data-book-page-rel-url="docs/69.html" data-book-page-id="11543">关于科学数据处理的统计学习教程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/70.html" title="机器学习: scikit-learn 中的设置以及预估对象" data-book-page-rel-url="docs/70.html" data-book-page-id="11544">机器学习: scikit-learn 中的设置以及预估对象</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/71.html" title="监督学习：从高维观察预测输出变量" data-book-page-rel-url="docs/71.html" data-book-page-id="11545">监督学习：从高维观察预测输出变量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/72.html" title="模型选择：选择估计量及其参数" data-book-page-rel-url="docs/72.html" data-book-page-id="11546">模型选择：选择估计量及其参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/73.html" title="无监督学习: 寻求数据表示" data-book-page-rel-url="docs/73.html" data-book-page-id="11547">无监督学习: 寻求数据表示</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/74.html" title="把它们放在一起" data-book-page-rel-url="docs/74.html" data-book-page-id="11548">把它们放在一起</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/75.html" title="寻求帮助" data-book-page-rel-url="docs/75.html" data-book-page-id="11549">寻求帮助</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/76.html" title="处理文本数据" data-book-page-rel-url="docs/76.html" data-book-page-id="11550">处理文本数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/77.html" title="选择正确的评估器(estimator.html)" data-book-page-rel-url="docs/77.html" data-book-page-id="11551">选择正确的评估器(estimator.html)</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/78.html" title="外部资源，视频和谈话" data-book-page-rel-url="docs/78.html" data-book-page-id="11552">外部资源，视频和谈话</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/80.html" title="常见问题" data-book-page-rel-url="docs/80.html" data-book-page-id="11553">常见问题</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/81.html" title="时光轴" data-book-page-rel-url="docs/81.html" data-book-page-id="11554">时光轴</a>
</li>
</ul>
</div>
</div>
<script src="https://cdn.staticfile.net/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="../../../static/components/uikit-2.27.5/js/uikit.reader.js"></script>
<script type="text/javascript" src="../../../static/components/social-share/social-share.min.js"></script>
<script>(function(){var bp =document.createElement('script');var curProtocol =window.location.protocol.split(':')[0];if (curProtocol ==='https') {bp.src ='https://zz.bdstatic.com/linksubmit/push.js';}
else {bp.src ='http://push.zhanzhang.baidu.com/push.js';}
var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp,s);})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
<script src="https://cdn.staticfile.net/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.net/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script src="https://cdn.staticfile.net/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="https://cdn.staticfile.net/uikit/2.27.5/js/components/lightbox.min.js"></script>
<link rel="dns-prefetch" href="../../..//cdn.mathjax.org" />
<script type="text/x-mathjax-config">
 function initMathJax() {
    var mathId = $("book-content-section")[0];
    MathJax.Hub.Config({
        tex2jax: {skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a']},
        showProcessingMessages: false,
        messageStyle: "none"
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub,mathId]);
 };
initMathJax();
</script>
<script src='https://cdn.staticfile.net/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML' async></script>
<style>
	.MathJax_Display{display:inline!important;}
</style>
<script type="text/javascript" src="../../../static/components/js/reader.js"></script>
<script type="text/javascript">var bookId =170;var bookPageId =11525;var bookPageRelUrl ='docs/34.html';</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
</body>
</html>