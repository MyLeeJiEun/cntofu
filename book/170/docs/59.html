
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>4.3. 预处理数据-scikit-learn (sklearn) 官方文档中文版</title>
<meta content='4.3. 预处理数据,scikit-learn (sklearn) 官方文档中文版' name='keywords'>
<meta content='4.3. 预处理数据,scikit-learn (sklearn) 官方文档中文版' name='description'>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=1, user-scalable=no"../../../>
<meta name="applicable-device" content="pc,mobile">
<link rel="shortcut icon" href="../../../favicon.ico" type="image/x-icon" />
<meta name="renderer" content="webkit">
<link rel="stylesheet" href="../../../static/components/uikit-2.27.5/css/uikit.custom.css">
<link rel="stylesheet" href="../../../static/components/social-share/social-share.min.css">
<link rel="stylesheet" href="../../../static/components/highlight/styles/custom.css">
<link rel="stylesheet" href="../../../static/components/css/base.css">
<link rel="stylesheet" href="../../../static/components/css/reader.css">
<link rel="stylesheet" href="../../../static/components/css/markdown.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5313208362165053" crossorigin="anonymous"></script>
</head>
<body>
<div class=" book-main-wrap uk-container uk-container-center uk-margin-top ">
<div class="uk-grid">
<div class="uk-width-1-1 reader-wrap ">
<div class=" bottom-nav uk-clearfix ">
<div class="uk-align-left ">
<a href="../../../book/170/docs/58.html">
<i class="nav-icon-left uk-icon-small  uk-icon-caret-left"></i>
<span class="">4.2. 特征提取</span>
</a>
</div>
<div class="uk-align-right ">
<a href="../../../book/170/docs/60.html">
<span class="">4.4. 无监督降维</span>
<i class="nav-icon-right uk-icon-small  uk-icon-caret-right"></i>
</a>
</div>
</div>
<div class="uk-text-center">
<h2 class="book-page-title uk-container-center">
<a href="../../../book/170/index.html">scikit-learn (sklearn) 官方文档中文版</a>
<a target="_blank" rel="nofollow" href="https://github.com/apachecn/scikit-learn-doc-zh" class="uk-icon-button uk-icon-github" title="github项目地址"></a>
</h2>
</div>
<script type="text/javascript" src="../../../static/components/js/app_intro.js"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5313208362165053" data-ad-slot="1328047120"></ins>
<script>(adsbygoogle =window.adsbygoogle ||[]).push({});</script>
<hr class="uk-article-divider">
<div class="book-content-section  md-content-section  uk-margin-bottom">
<h1 id="43-预处理数据">4.3. 预处理数据</h1>
<p>校验者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh"></a><a href="https://github.com/if"><strong>@if</strong></a> only 翻译者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@Trembleguy</a></p>
<p><code>sklearn.preprocessing</code> 包提供了几个常见的实用功能和变换器类型，用来将原始特征向量更改为更适合机器学习模型的形式。</p>
<p>一般来说，机器学习算法受益于数据集的标准化。如果数据集中存在一些离群值，那么稳定的缩放或转换更合适。不同缩放、转换以及归一在一个包含边缘离群值的数据集中的表现在 <a href="../auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py">Compare the effect of different scalers on data with outliers</a> 中有着重说明。</p>
<h2 id="431-标准化也称去均值和方差按比例缩放">4.3.1. 标准化，也称去均值和方差按比例缩放</h2>
<p>数据集的 <strong>标准化</strong> 对scikit-learn中实现的大多数机器学习算法来说是 <strong>常见的要求</strong> 。如果个别特征或多或少看起来不是很像标准正态分布(<strong>具有零均值和单位方差</strong>)，那么它们的表现力可能会较差。</p>
<p>在实际情况中,我们经常忽略特征的分布形状，直接经过去均值来对某个特征进行中心化，再通过除以非常量特征(non-constant features)的标准差进行缩放。</p>
<p>例如，在机器学习算法的目标函数(例如SVM的RBF内核或线性模型的l1和l2正则化)，许多学习算法中目标函数的基础都是假设所有的特征都是零均值并且具有同一阶数上的方差。如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致学习器并不能像我们说期望的那样，从其他特征中学习。</p>
<p>函数 <a href="generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><code>scale</code></a> 为数组形状的数据集的标准化提供了一个快捷实现:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn import preprocessing
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X_train = np.array([[ 1., -1.,  2.],
...                     [ 2.,  0.,  0.],
...                     [ 0.,  1., -1.]])
&gt;&gt;&gt; X_scaled = preprocessing.scale(X_train)

&gt;&gt;&gt; X_scaled                                          
array([[ 0\.  ..., -1.22...,  1.33...],
 [ 1.22...,  0\.  ..., -0.26...],
 [-1.22...,  1.22..., -1.06...]])

</code></pre>
<p>经过缩放后的数据具有零均值以及标准方差:</p>
<pre><code class="language-py">&gt;&gt;&gt; X_scaled.mean(axis=0)
array([ 0.,  0.,  0.])

&gt;&gt;&gt; X_scaled.std(axis=0)
array([ 1.,  1.,  1.])

</code></pre>
<p><code>预处理</code> 模块还提供了一个实用类 <a href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> ，它实现了转化器的API来计算训练集上的平均值和标准偏差，以便以后能够在测试集上重新应用相同的变换。因此，这个类适用于 <a href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>sklearn.pipeline.Pipeline</code></a> 的早期步骤:</p>
<pre><code class="language-py">&gt;&gt;&gt; scaler = preprocessing.StandardScaler().fit(X_train)
&gt;&gt;&gt; scaler
StandardScaler(copy=True, with_mean=True, with_std=True)

&gt;&gt;&gt; scaler.mean_                                      
array([ 1\. ...,  0\. ...,  0.33...])

&gt;&gt;&gt; scaler.scale_                                       
array([ 0.81...,  0.81...,  1.24...])

&gt;&gt;&gt; scaler.transform(X_train)                           
array([[ 0\.  ..., -1.22...,  1.33...],
 [ 1.22...,  0\.  ..., -0.26...],
 [-1.22...,  1.22..., -1.06...]])

</code></pre>
<p>缩放类对象可以在新的数据上实现和训练集相同缩放操作:</p>
<pre><code class="language-py">&gt;&gt;&gt; X_test = [[-1., 1., 0.]]
&gt;&gt;&gt; scaler.transform(X_test)                
array([[-2.44...,  1.22..., -0.26...]])

</code></pre>
<p>你也可以通过在构造函数 :class:StandardScaler 中传入参数 <code>with_mean=False</code> 或者``with_std=False` 来取消中心化或缩放操作。</p>
<h3 id="4311-将特征缩放至特定范围内">4.3.1.1. 将特征缩放至特定范围内</h3>
<p>一种标准化是将特征缩放到给定的最小值和最大值之间，通常在零和一之间，或者也可以将每个特征的最大绝对值转换至单位大小。可以分别使用 <a href="generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code>MinMaxScaler</code></a> 和 <a href="generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code>MaxAbsScaler</code></a> 实现。</p>
<p>使用这种缩放的目的包括实现特征极小方差的鲁棒性以及在稀疏矩阵中保留零元素。</p>
<p>以下是一个将简单的数据矩阵缩放到<code>[0, 1]</code>的例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; X_train = np.array([[ 1., -1.,  2.],
...                     [ 2.,  0.,  0.],
...                     [ 0.,  1., -1.]])
...
&gt;&gt;&gt; min_max_scaler = preprocessing.MinMaxScaler()
&gt;&gt;&gt; X_train_minmax = min_max_scaler.fit_transform(X_train)
&gt;&gt;&gt; X_train_minmax
array([[ 0.5       ,  0\.        ,  1\.        ],
 [ 1\.        ,  0.5       ,  0.33333333],
 [ 0\.        ,  1\.        ,  0\.        ]])

</code></pre>
<p>同样的转换实例可以被用与在训练过程中不可见的测试数据:实现和训练数据一致的缩放和移位操作:</p>
<pre><code class="language-py">&gt;&gt;&gt; X_test = np.array([[ -3., -1.,  4.]])
&gt;&gt;&gt; X_test_minmax = min_max_scaler.transform(X_test)
&gt;&gt;&gt; X_test_minmax
array([[-1.5       ,  0\.        ,  1.66666667]])

</code></pre>
<p>可以检查缩放器（scaler）属性，来观察在训练集中学习到的转换操作的基本性质:</p>
<pre><code class="language-py">&gt;&gt;&gt; min_max_scaler.scale_                             
array([ 0.5       ,  0.5       ,  0.33...])

&gt;&gt;&gt; min_max_scaler.min_                               
array([ 0\.        ,  0.5       ,  0.33...])

</code></pre>
<p>如果给 <a href="generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code>MinMaxScaler</code></a> 提供一个明确的 <code>feature_range=(min, max)</code> ，完整的公式是:</p>
<pre><code class="language-py">X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))

X_scaled = X_std * (max - min) + min

</code></pre>
<p>类 <a href="generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code>MaxAbsScaler</code></a> 的工作原理非常相似，但是它只通过除以每个特征的最大值将训练数据特征缩放至 <code>[-1, 1]</code> 范围内，这就意味着，训练数据应该是已经零中心化或者是稀疏数据。 例子::用先前例子的数据实现最大绝对值缩放操作。</p>
<p>以下是使用上例中数据运用这个缩放器的例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; X_train = np.array([[ 1., -1.,  2.],
...                     [ 2.,  0.,  0.],
...                     [ 0.,  1., -1.]])
...
&gt;&gt;&gt; max_abs_scaler = preprocessing.MaxAbsScaler()
&gt;&gt;&gt; X_train_maxabs = max_abs_scaler.fit_transform(X_train)
&gt;&gt;&gt; X_train_maxabs                # doctest +NORMALIZE_WHITESPACE^
array([[ 0.5, -1\. ,  1\. ],
 [ 1\. ,  0\. ,  0\. ],
 [ 0\. ,  1\. , -0.5]])
&gt;&gt;&gt; X_test = np.array([[ -3., -1.,  4.]])
&gt;&gt;&gt; X_test_maxabs = max_abs_scaler.transform(X_test)
&gt;&gt;&gt; X_test_maxabs                 
array([[-1.5, -1\. ,  2\. ]])
&gt;&gt;&gt; max_abs_scaler.scale_         
array([ 2.,  1.,  2.])

</code></pre>
<p>在 <a href="generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><code>scale</code></a> 模块中进一步提供了方便的功能。当你不想创建对象时，可以使用如 <a href="generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale" title="sklearn.preprocessing.minmax_scale"><code>minmax_scale</code></a> 以及 <a href="generated/sklearn.preprocessing.maxabs_scale.html#sklearn.preprocessing.maxabs_scale" title="sklearn.preprocessing.maxabs_scale"><code>maxabs_scale</code></a> 。</p>
<h3 id="4312-缩放稀疏矩阵数据">4.3.1.2. 缩放稀疏（矩阵）数据</h3>
<p>中心化稀疏(矩阵)数据会破坏数据的稀疏结构，因此很少有一个比较明智的实现方式。但是缩放稀疏输入是有意义的，尤其是当几个特征在不同的量级范围时。</p>
<p><a href="generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code>MaxAbsScaler</code></a> 以及 <a href="generated/sklearn.preprocessing.maxabs_scale.html#sklearn.preprocessing.maxabs_scale" title="sklearn.preprocessing.maxabs_scale"><code>maxabs_scale</code></a> 是专为缩放数据而设计的，并且是缩放数据的推荐方法。但是， <a href="generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><code>scale</code></a> 和 <a href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> 也能够接受 <code>scipy.sparse</code> 作为输入，只要参数 <code>with_mean=False</code> 被准确传入它的构造器。否则会出现 <code>ValueError</code> 的错误，因为默认的中心化会破坏稀疏性，并且经常会因为分配过多的内存而使执行崩溃。 <a href="generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="sklearn.preprocessing.RobustScaler"><code>RobustScaler</code></a> 不能适应稀疏输入，但你可以在稀疏输入使用 <code>transform</code> 方法。</p>
<p>注意，缩放器同时接受压缩的稀疏行和稀疏列(参见 <code>scipy.sparse.csr_matrix</code> 以及 <code>scipy.sparse.csc_matrix</code> )。任何其他稀疏输入将会 <strong>转化为压缩稀疏行表示</strong> 。为了避免不必要的内存复制，建议在上游(早期)选择CSR或CSC表示。</p>
<p>最后，最后，如果已经中心化的数据并不是很大，使用 <code>toarray</code> 方法将输入的稀疏矩阵显式转换为数组是另一种选择。</p>
<h3 id="4313-缩放有离群值的数据">4.3.1.3. 缩放有离群值的数据</h3>
<p>如果你的数据包含许多异常值，使用均值和方差缩放可能并不是一个很好的选择。这种情况下，你可以使用 <a href="generated/sklearn.preprocessing.robust_scale.html#sklearn.preprocessing.robust_scale" title="sklearn.preprocessing.robust_scale"><code>robust_scale</code></a> 以及 <a href="generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="sklearn.preprocessing.RobustScaler"><code>RobustScaler</code></a> 作为替代品。它们对你的数据的中心和范围使用更有鲁棒性的估计。</p>
<p>参考:</p>
<p>更多关于中心化和缩放数据的重要性讨论在此FAQ中提及: <a href="http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html">Should I normalize/standardize/rescale the data?</a></p>
<p>Scaling vs Whitening 有时候独立地中心化和缩放数据是不够的，因为下游的机器学习模型能够对特征之间的线性依赖做出一些假设(这对模型的学习过程来说是不利的)。</p>
<p>要解决这个问题，你可以使用 <a href="generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="sklearn.decomposition.PCA"><code>sklearn.decomposition.PCA</code></a> 或 <a href="generated/sklearn.decomposition.RandomizedPCA.html#sklearn.decomposition.RandomizedPCA" title="sklearn.decomposition.RandomizedPCA"><code>sklearn.decomposition.RandomizedPCA</code></a> 并指定参数 <code>whiten=True</code> 来更多移除特征间的线性关联。</p>
<p>在回归中缩放目标变量</p>
<p><a href="generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale" title="sklearn.preprocessing.scale"><code>scale</code></a> 以及 <a href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> 可以直接处理一维数组。在回归中，缩放目标/相应变量时非常有用。</p>
<h3 id="4314-核矩阵的中心化">4.3.1.4. 核矩阵的中心化</h3>
<p>如果你有一个核矩阵 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e279b8169ddd6581c5606c868ba52fae.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e279b8169ddd6581c5606c868ba52fae.jpg" alt="K"></a> ，它计算由函数 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a8e210a94f6eac6c32bc219dbc049288.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a8e210a94f6eac6c32bc219dbc049288.jpg" alt="phi"></a> 定义的特征空间的点积，那么一个 <a href="generated/sklearn.preprocessing.KernelCenterer.html#sklearn.preprocessing.KernelCenterer" title="sklearn.preprocessing.KernelCenterer"><code>KernelCenterer</code></a> 类能够转化这个核矩阵，通过移除特征空间的平均值，使它包含由函数 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a8e210a94f6eac6c32bc219dbc049288.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/a8e210a94f6eac6c32bc219dbc049288.jpg" alt="phi"></a> 定义的内部产物。</p>
<h2 id="432-非线性转换">4.3.2. 非线性转换</h2>
<p>类似于缩放， <a href="generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer" title="sklearn.preprocessing.QuantileTransformer"><code>QuantileTransformer</code></a> 类将每个特征缩放在同样的范围或分布情况下。但是，通过执行一个秩转换能够使异常的分布平滑化，并且能够比缩放更少地受到离群值的影响。但是它的确使特征间及特征内的关联和距离失真了。</p>
<p><a href="generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer" title="sklearn.preprocessing.QuantileTransformer"><code>QuantileTransformer</code></a> 类以及 <a href="generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform" title="sklearn.preprocessing.quantile_transform"><code>quantile_transform</code></a> 函数提供了一个基于分位数函数的无参数转换，将数据映射到了零到一的均匀分布上:</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; iris = load_iris()
&gt;&gt;&gt; X, y = iris.data, iris.target
&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
&gt;&gt;&gt; quantile_transformer = preprocessing.QuantileTransformer(random_state=0)
&gt;&gt;&gt; X_train_trans = quantile_transformer.fit_transform(X_train)
&gt;&gt;&gt; X_test_trans = quantile_transformer.transform(X_test)
&gt;&gt;&gt; np.percentile(X_train[:, 0], [0, 25, 50, 75, 100]) 
array([ 4.3,  5.1,  5.8,  6.5,  7.9])

</code></pre>
<p>这个特征是萼片的厘米单位的长度。一旦应用分位数转换，这些元素就接近于之前定义的百分位数:</p>
<pre><code class="language-py">&gt;&gt;&gt; np.percentile(X_train_trans[:, 0], [0, 25, 50, 75, 100])
... 
array([ 0.00... ,  0.24...,  0.49...,  0.73...,  0.99... ])

</code></pre>
<p>这可以在具有类似形式的独立测试集上确认:</p>
<pre><code class="language-py">&gt;&gt;&gt; np.percentile(X_test[:, 0], [0, 25, 50, 75, 100])
... 
array([ 4.4  ,  5.125,  5.75 ,  6.175,  7.3  ])
&gt;&gt;&gt; np.percentile(X_test_trans[:, 0], [0, 25, 50, 75, 100])
... 
array([ 0.01...,  0.25...,  0.46...,  0.60... ,  0.94...])

</code></pre>
<p>也可以通过设置 <code>output_distribution='normal'</code> 将转换后的数据映射到正态分布:</p>
<pre><code class="language-py">&gt;&gt;&gt; quantile_transformer = preprocessing.QuantileTransformer(
...     output_distribution='normal', random_state=0)
&gt;&gt;&gt; X_trans = quantile_transformer.fit_transform(X)
&gt;&gt;&gt; quantile_transformer.quantiles_ 
array([[ 4.3...,   2...,     1...,     0.1...],
 [ 4.31...,  2.02...,  1.01...,  0.1...],
 [ 4.32...,  2.05...,  1.02...,  0.1...],
 ...,
 [ 7.84...,  4.34...,  6.84...,  2.5...],
 [ 7.87...,  4.37...,  6.87...,  2.5...],
 [ 7.9...,   4.4...,   6.9...,   2.5...]])

</code></pre>
<p>这样，输入的中值称为输出的平均值，并且以0为中心。正常输出被剪切，使得输入的最小和最大值分别对应于1e-7和1-1e-7分位数——在变换下不会变得无限大。</p>
<h2 id="433-归一化">4.3.3. 归一化</h2>
<p><strong>归一化</strong> 是 <strong>缩放单个样本以具有单位范数</strong> 的过程。如果你计划使用二次形式(如点积或任何其他核函数)来量化任何样本间的相似度，则此过程将非常有用。</p>
<p>这个观点基于 <a href="https://en.wikipedia.org/wiki/Vector_Space_Model">向量空间模型(Vector Space Model)</a> ，经常在文本分类和内容聚类中使用.</p>
<p>函数 <a href="generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize" title="sklearn.preprocessing.normalize"><code>normalize</code></a> 提供了一个快速简单的方法在类似数组的数据集上执行操作，使用 <code>l1</code> 或 <code>l2</code> 范式:</p>
<pre><code class="language-py">&gt;&gt;&gt; X = [[ 1., -1.,  2.],
...      [ 2.,  0.,  0.],
...      [ 0.,  1., -1.]]
&gt;&gt;&gt; X_normalized = preprocessing.normalize(X, norm='l2')

&gt;&gt;&gt; X_normalized                                      
array([[ 0.40..., -0.40...,  0.81...],
 [ 1\.  ...,  0\.  ...,  0\.  ...],
 [ 0\.  ...,  0.70..., -0.70...]])

</code></pre>
<p><code>preprocessing</code> 预处理模块提供的 <a href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code>Normalizer</code></a> 工具类使用 <code>Transformer</code> API 实现了相同的操作(即使在这种情况下， <code>fit</code> 方法是无用的：该类是无状态的，因为该操作独立对待样本).</p>
<p>因此这个类适用于 <a href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>sklearn.pipeline.Pipeline</code></a> 的早期步骤:</p>
<pre><code class="language-py">&gt;&gt;&gt; normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing
&gt;&gt;&gt; normalizer
Normalizer(copy=True, norm='l2')

</code></pre>
<p>在这之后归一化实例可以被使用在样本向量中，像任何其他转换器一样:</p>
<pre><code class="language-py">&gt;&gt;&gt; normalizer.transform(X)                            
array([[ 0.40..., -0.40...,  0.81...],
 [ 1\.  ...,  0\.  ...,  0\.  ...],
 [ 0\.  ...,  0.70..., -0.70...]])

&gt;&gt;&gt; normalizer.transform([[-1.,  1., 0.]])             
array([[-0.70...,  0.70...,  0\.  ...]])

</code></pre>
<p>稀疏(数据)输入</p>
<p>函数 <a href="generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize" title="sklearn.preprocessing.normalize"><code>normalize</code></a> 以及类 <a href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code>Normalizer</code></a> 接收 <strong>来自scipy.sparse的密集类数组数据和稀疏矩阵</strong> 作为输入。</p>
<p>对于稀疏输入，在被提交给高效Cython例程前，数据被 <strong>转化为压缩的稀疏行形式</strong> (参见 <code>scipy.sparse.csr_matrix</code> )。为了避免不必要的内存复制，推荐在上游选择CSR表示。</p>
<h2 id="434-二值化">4.3.4. 二值化</h2>
<h3 id="4341-特征二值化">4.3.4.1. 特征二值化</h3>
<p><strong>特征二值化</strong> 是 <strong>将数值特征用阈值过滤得到布尔值</strong> 的过程。这对于下游的概率型模型是有用的，它们假设输入数据是多值 <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">伯努利分布(Bernoulli distribution)</a> 。例如这个例子 <a href="generated/sklearn.neural_network.BernoulliRBM.html#sklearn.neural_network.BernoulliRBM" title="sklearn.neural_network.BernoulliRBM"><code>sklearn.neural_network.BernoulliRBM</code></a> 。</p>
<p>即使归一化计数(又名术语频率)和TF-IDF值特征在实践中表现稍好一些，文本处理团队也常常使用二值化特征值(这可能会简化概率估计)。</p>
<p>相比于 <a href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code>Normalizer</code></a> ，实用程序类 <a href="generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><code>Binarizer</code></a> 也被用于 <a href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>sklearn.pipeline.Pipeline</code></a> 的早期步骤中。因为每个样本被当做是独立于其他样本的，所以 <code>fit</code> 方法是无用的:</p>
<pre><code class="language-py">&gt;&gt;&gt; X = [[ 1., -1.,  2.],
...      [ 2.,  0.,  0.],
...      [ 0.,  1., -1.]]

&gt;&gt;&gt; binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing
&gt;&gt;&gt; binarizer
Binarizer(copy=True, threshold=0.0)

&gt;&gt;&gt; binarizer.transform(X)
array([[ 1.,  0.,  1.],
 [ 1.,  0.,  0.],
 [ 0.,  1.,  0.]])

</code></pre>
<p>也可以为二值化器赋一个阈值:</p>
<pre><code class="language-py">&gt;&gt;&gt; binarizer = preprocessing.Binarizer(threshold=1.1)
&gt;&gt;&gt; binarizer.transform(X)
array([[ 0.,  0.,  1.],
 [ 1.,  0.,  0.],
 [ 0.,  0.,  0.]])

</code></pre>
<p>相比于 <a href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> 和 <a href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code>Normalizer</code></a> 类的情况，预处理模块提供了一个相似的函数 <a href="generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize" title="sklearn.preprocessing.binarize"><code>binarize</code></a> ，以便不需要转换接口时使用。</p>
<p>稀疏输入</p>
<p><a href="generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize" title="sklearn.preprocessing.binarize"><code>binarize</code></a> 以及 <a href="generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><code>Binarizer</code></a> 接收 <strong>来自scipy.sparse的密集类数组数据以及稀疏矩阵作为输入</strong> 。</p>
<p>对于稀疏输入，数据被 <strong>转化为压缩的稀疏行形式</strong> (参见 <code>scipy.sparse.csr_matrix</code> )。为了避免不必要的内存复制，推荐在上游选择CSR表示。</p>
<h2 id="435-分类特征编码">4.3.5. 分类特征编码</h2>
<p>在机器学习中，特征经常不是数值型的而是分类型的。举个例子，一个人可能有 <code>["male", "female"]</code> ， <code>["from Europe", "from US", "from Asia"]</code> ， <code>["uses Firefox", "uses Chrome", "uses Safari", "uses Internet Explorer"]</code> 等分类的特征。这些特征能够被有效地编码成整数，比如 <code>["male", "from US", "uses Internet Explorer"]</code> 可以被表示为 <code>[0, 1, 3]</code> ， <code>["female", "from Asia", "uses Chrome"]</code> 表示为 <code>[1, 2, 1]</code> 。</p>
<p>这个的整数特征表示并不能在scikit-learn的估计器中直接使用，因为这样的连续输入，估计器会认为类别之间是有序的，但实际却是无序的。(例如：浏览器的类别数据则是任意排序的)</p>
<p>一种将分类特征转换为能够被scikit-learn中模型使用的编码是one-of-K或one-hot编码，在 <a href="generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code>OneHotEncoder</code></a> 中实现。这个类使用 <code>m</code> 个可能值转换为 <code>m</code> 值化特征，将分类特征的每个元素转化为一个值。</p>
<p>考虑如下例子:</p>
<pre><code class="language-py">&gt;&gt;&gt; enc = preprocessing.OneHotEncoder()
&gt;&gt;&gt; enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])  
OneHotEncoder(categorical_features='all', dtype=&lt;... 'numpy.float64'&gt;,
 handle_unknown='error', n_values='auto', sparse=True)
&gt;&gt;&gt; enc.transform([[0, 1, 3]]).toarray()
array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])

</code></pre>
<p>默认情况下，每个特征使用几维的数值由数据集自动推断。当然，你也可以通过使用参数<code>n_values</code>来精确指定。 在我们的例子数据集中，有两个可能得性别类别，三个洲，四个网络浏览器。接着，我们训练编码算法，并用来对一个样本数据进行转换。 在结果中，前两个数值是性别编码，紧接着的三个数值是洲编码，最后的四个数值是浏览器编码</p>
<p>注意，如果训练集中有丢失的分类特征值，必须显式地设置 <code>n_values</code> ，举个例子，</p>
<pre><code class="language-py">&gt;&gt;&gt; enc = preprocessing.OneHotEncoder(n_values=[2, 3, 4])
&gt;&gt;&gt; # 注意到第二、三个特征是不全的
&gt;&gt;&gt; # features
&gt;&gt;&gt; enc.fit([[1, 2, 3], [0, 2, 0]])  
OneHotEncoder(categorical_features='all', dtype=&lt;... 'numpy.float64'&gt;,
 handle_unknown='error', n_values=[2, 3, 4], sparse=True)
&gt;&gt;&gt; enc.transform([[1, 0, 0]]).toarray()
array([[ 0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.]])

</code></pre>
<p>参见 <a href="feature_extraction.html#dict-feature-extraction">从字典类型加载特征</a> ，它对于分类特征代表一个dict，而不是整数。</p>
<h2 id="436-缺失值插补">4.3.6. 缺失值插补</h2>
<p>因为各种各样的原因，真实世界中的许多数据集都包含缺失数据，这类数据经常被编码成空格、NaNs，或者是其他的占位符。但是这样的数据集并不能scikit-learn学习算法兼容，因为大多的学习算法都默认假设数组中的元素都是数值，因而所有的元素都有自己的意义。 使用不完整的数据集的一个基本策略就是舍弃掉整行或整列包含缺失值的数据。但是这样就付出了舍弃可能有价值数据（即使是不完整的 ）的代价。 处理缺失数值的一个更好的策略就是从已有的数据推断出缺失的数值。</p>
<p><a href="generated/sklearn.preprocessing.Imputer.html#sklearn.preprocessing.Imputer" title="sklearn.preprocessing.Imputer"><code>Imputer</code></a> 类提供了估算缺失值的基本策略，使用缺失值所在的行/列中的平均值、中位数或者众数来填充。这个类也支持不同的缺失值编码。</p>
<p>以下代码段演示了如何使用包含缺失值的列(轴0)的平均值来替换编码为 <code>np.nan</code> 的缺失值:</p>
<pre><code class="language-py">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.preprocessing import Imputer
&gt;&gt;&gt; imp = Imputer(missing_values='NaN', strategy='mean', axis=0)
&gt;&gt;&gt; imp.fit([[1, 2], [np.nan, 3], [7, 6]])
Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)
&gt;&gt;&gt; X = [[np.nan, 2], [6, np.nan], [7, 6]]
&gt;&gt;&gt; print(imp.transform(X))                           
[[ 4\.          2\.        ]
 [ 6\.          3.666...]
 [ 7\.          6\.        ]]

</code></pre>
<p><a href="generated/sklearn.preprocessing.Imputer.html#sklearn.preprocessing.Imputer" title="sklearn.preprocessing.Imputer"><code>Imputer</code></a> 类也支持稀疏矩阵:</p>
<pre><code class="language-py">&gt;&gt;&gt; import scipy.sparse as sp
&gt;&gt;&gt; X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])
&gt;&gt;&gt; imp = Imputer(missing_values=0, strategy='mean', axis=0)
&gt;&gt;&gt; imp.fit(X)
Imputer(axis=0, copy=True, missing_values=0, strategy='mean', verbose=0)
&gt;&gt;&gt; X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])
&gt;&gt;&gt; print(imp.transform(X_test))                      
[[ 4\.          2\.        ]
 [ 6\.          3.666...]
 [ 7\.          6\.        ]]

</code></pre>
<p>注意，缺失值被编码为0，因此隐式地存储在矩阵中。当缺失值比可观察到的值多的时候，这种格式是合适的。</p>
<p><a href="generated/sklearn.preprocessing.Imputer.html#sklearn.preprocessing.Imputer" title="sklearn.preprocessing.Imputer"><code>Imputer</code></a> 可以在 Pipeline 中用作构建支持插补的合成模型。参见 <a href="../auto_examples/plot_missing_values.html#sphx-glr-auto-examples-plot-missing-values-py">Imputing missing values before building an estimator</a> 。</p>
<h2 id="437-生成多项式特征">4.3.7. 生成多项式特征</h2>
<p>在机器学习中，通过增加一些输入数据的非线性特征来增加模型的复杂度通常是有效的。一个简单通用的办法是使用多项式特征，这可以获得特征的更高维度和互相间关系的项。这在 <a href="generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures" title="sklearn.preprocessing.PolynomialFeatures"><code>PolynomialFeatures</code></a> 中实现:</p>
<pre><code class="language-py">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.preprocessing import PolynomialFeatures
&gt;&gt;&gt; X = np.arange(6).reshape(3, 2)
&gt;&gt;&gt; X                                                 
array([[0, 1],
 [2, 3],
 [4, 5]])
&gt;&gt;&gt; poly = PolynomialFeatures(2)
&gt;&gt;&gt; poly.fit_transform(X)                             
array([[  1.,   0.,   1.,   0.,   0.,   1.],
 [  1.,   2.,   3.,   4.,   6.,   9.],
 [  1.,   4.,   5.,  16.,  20.,  25.]])

</code></pre>
<p>X 的特征已经从 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/23bd4397a3e30a81d2ee26977f708e63.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/23bd4397a3e30a81d2ee26977f708e63.jpg" alt="(X_1, X_2)"></a> 转换为 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/77ee769c7c80ba4738fa4b34ff922e25.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/77ee769c7c80ba4738fa4b34ff922e25.jpg" alt="(1, X_1, X_2, X_12, X_1X_2, X_22)"></a> 。</p>
<p>在一些情况下，只需要特征间的交互项，这可以通过设置 <code>interaction_only=True</code> 来得到:</p>
<pre><code class="language-py">&gt;&gt;&gt; X = np.arange(9).reshape(3, 3)
&gt;&gt;&gt; X                                                 
array([[0, 1, 2],
 [3, 4, 5],
 [6, 7, 8]])
&gt;&gt;&gt; poly = PolynomialFeatures(degree=3, interaction_only=True)
&gt;&gt;&gt; poly.fit_transform(X)                             
array([[   1.,    0.,    1.,    2.,    0.,    0.,    2.,    0.],
 [   1.,    3.,    4.,    5.,   12.,   15.,   20.,   60.],
 [   1.,    6.,    7.,    8.,   42.,   48.,   56.,  336.]])

</code></pre>
<p>X的特征已经从 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/300d1995dc6050bbfd575b2c14ec81ae.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/300d1995dc6050bbfd575b2c14ec81ae.jpg" alt="(X_1, X_2, X_3)"></a> 转换为 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f4c7787828dd90f6b47e1677bbc806da.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f4c7787828dd90f6b47e1677bbc806da.jpg" alt="(1, X_1, X_2, X_3, X_1X_2, X_1X_3, X_2X_3, X_1X_2X_3)"></a> 。</p>
<p>注意，当使用多项的 <a href="#id14">:ref:<code>svm_kernels</code>时 ，多项式特征被隐式地使用在 <code>核函数(kernel methods) &amp;lt;https://en.wikipedia.org/wiki/Kernel_method&amp;gt;</code>_</a> 中(比如， <a href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code>sklearn.svm.SVC</code></a> ， <a href="generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA" title="sklearn.decomposition.KernelPCA"><code>sklearn.decomposition.KernelPCA</code></a> )。</p>
<p>创建并使用多项式特征的岭回归实例请见 <a href="../auto_examples/linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py">Polynomial interpolation</a> 。</p>
<h2 id="438-自定义转换器">4.3.8. 自定义转换器</h2>
<p>在机器学习中，想要将一个已有的 Python 函数转化为一个转换器来协助数据清理或处理。可以使用 <a href="generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><code>FunctionTransformer</code></a> 从任意函数中实现一个转换器。例如，在一个管道中构建一个实现日志转换的转化器，这样做:</p>
<pre><code class="language-py">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.preprocessing import FunctionTransformer
&gt;&gt;&gt; transformer = FunctionTransformer(np.log1p)
&gt;&gt;&gt; X = np.array([[0, 1], [2, 3]])
&gt;&gt;&gt; transformer.transform(X)
array([[ 0\.        ,  0.69314718],
 [ 1.09861229,  1.38629436]])

</code></pre>
<p>使用一个 <a href="generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><code>FunctionTransformer</code></a> 类来做定制化特征选择的例子，请见 <a href="../auto_examples/preprocessing/plot_function_transformer.html#sphx-glr-auto-examples-preprocessing-plot-function-transformer-py">Using FunctionTransformer to select columns</a> 。</p>
</div>
<hr class="uk-article-divider">
<div class="uk-block uk-block-muted uk-padding-top-remove uk-padding-bottom-remove uk-margin-large-top  book-recommend-wrap">
<div class="uk-margin-top uk-margin-bottom uk-margin-left uk-margin-right">
<div class="uk-margin uk-text-muted "><i class="uk-icon-outdent uk-icon-justify uk-margin-small-right"></i>书籍推荐</div>
<div class="books">
<ul class="uk-book-list">
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/160/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/160/index.html">Python - 100天从新手到大师</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/92.html">jackfrued</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">75页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 33569个">33569</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/169/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/169/index.html">PyTorch 1.0 中文文档 & 教程</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/18.html">ApacheCN</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">87页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 874个">874</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/166/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/166/index.html">What the f*ck Python中文版</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/95.html">leisurelicht</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">70页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 7300个">7300</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/134/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/github_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/134/index.html">GitHub 漫游指南</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/72.html">phodal</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="github">github</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">1页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年8月3日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 3472个">3472</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/107/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/laravel_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/107/index.html">Laravel 源码详解</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/62.html">tzivanmoe</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="laravel">laravel</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">42页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年7月1日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 4个">4</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/24/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/cplusplus_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/24/index.html">复杂性思维第二版</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/17.html">Kivy Developers From China</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="cplusplus">cplusplus</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">16页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年5月3日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 83个">83</span>
</div>
</div>
</div>
</li>
<hr>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<nav class="tm-navbar uk-navbar uk-navbar-attached reader-nav">
<div class="uk-float-left uk-margin-small-top">
<a href="javascript:;" title="目录菜单" class="show-menu  uk-icon-hover  uk-icon-align-justify uk-margin-right"></a>
<div data-uk-dropdown="{mode:'click',pos:'bottom-left'}" class="font-setting-wrap">
<a class="uk-icon-hover uk-icon-font uk-margin-right" aria-label="字体设置" href="javascript:;"></a>
<div class="uk-dropdown dropdown-menu">
<div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-reduce">小字</button>
<button class="uk-button-link button size-2 font-enlarge">大字</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-1 ">宋体</button>
<button class="uk-button-link button size-2 font-2 ">黑体</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-3 color-theme-sun "><i class="uk-icon-sun-o"></i>白天</button>
<button class="uk-button-link button size-3 color-theme-eye "><i class="uk-icon-eye"></i>护眼</button>
<button class="uk-button-link button size-3 color-theme-moon "><i class="uk-icon-moon-o"></i>夜晚</button></div>
</div>
</div>
<a class="logo uk-margin-right" href="../../../" title="返回首页"><img class="" src="../../../static/components/images/icon_32.png" /></a>
</div>
<div class="uk-navbar-flip  uk-hidden-small">
<div id="share-box"></div>
</div>
</nav>
<div id="menu-id" class="uk-offcanvas reader-offcanvas">
<div class="uk-offcanvas-bar">
<ul class="book-menu-bar uk-nav uk-nav-offcanvas" data-uk-nav>
<li>
<a href="../../../book/170/index.html" data-book-page-rel-url="index.html" data-book-page-id="0" title="封面">封面</a>
</li>
<li>
<a class="pjax" href="../../../book/170/readme.html" data-book-page-rel-url="readme.html" data-book-page-id="0" title="简介">简介</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/79.html" title="安装 scikit-learn" data-book-page-rel-url="docs/79.html" data-book-page-id="11491">安装 scikit-learn</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/1.html" title="1. 监督学习" data-book-page-rel-url="docs/1.html" data-book-page-id="11492">1. 监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/2.html" title="1.1. 广义线性模型" data-book-page-rel-url="docs/2.html" data-book-page-id="11493">1.1. 广义线性模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/3.html" title="1.2. 线性和二次判别分析" data-book-page-rel-url="docs/3.html" data-book-page-id="11494">1.2. 线性和二次判别分析</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/4.html" title="1.3. 内核岭回归" data-book-page-rel-url="docs/4.html" data-book-page-id="11495">1.3. 内核岭回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/5.html" title="1.4. 支持向量机" data-book-page-rel-url="docs/5.html" data-book-page-id="11496">1.4. 支持向量机</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/6.html" title="1.5. 随机梯度下降" data-book-page-rel-url="docs/6.html" data-book-page-id="11497">1.5. 随机梯度下降</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/7.html" title="1.6. 最近邻" data-book-page-rel-url="docs/7.html" data-book-page-id="11498">1.6. 最近邻</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/8.html" title="1.7. 高斯过程" data-book-page-rel-url="docs/8.html" data-book-page-id="11499">1.7. 高斯过程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/9.html" title="1.8. 交叉分解" data-book-page-rel-url="docs/9.html" data-book-page-id="11500">1.8. 交叉分解</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/10.html" title="1.9. 朴素贝叶斯" data-book-page-rel-url="docs/10.html" data-book-page-id="11501">1.9. 朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/11.html" title="1.10. 决策树" data-book-page-rel-url="docs/11.html" data-book-page-id="11502">1.10. 决策树</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/12.html" title="1.11. 集成方法" data-book-page-rel-url="docs/12.html" data-book-page-id="11503">1.11. 集成方法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/13.html" title="1.12. 多类和多标签算法" data-book-page-rel-url="docs/13.html" data-book-page-id="11504">1.12. 多类和多标签算法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/14.html" title="1.13. 特征选择" data-book-page-rel-url="docs/14.html" data-book-page-id="11505">1.13. 特征选择</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/15.html" title="1.14. 半监督学习" data-book-page-rel-url="docs/15.html" data-book-page-id="11506">1.14. 半监督学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/16.html" title="1.15. 等式回归" data-book-page-rel-url="docs/16.html" data-book-page-id="11507">1.15. 等式回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/17.html" title="1.16. 概率校准" data-book-page-rel-url="docs/17.html" data-book-page-id="11508">1.16. 概率校准</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/18.html" title="1.17. 神经网络模型（有监督）" data-book-page-rel-url="docs/18.html" data-book-page-id="11509">1.17. 神经网络模型（有监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/19.html" title="2. 无监督学习" data-book-page-rel-url="docs/19.html" data-book-page-id="11510">2. 无监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/20.html" title="2.1. 高斯混合模型" data-book-page-rel-url="docs/20.html" data-book-page-id="11511">2.1. 高斯混合模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/21.html" title="2.2. 流形学习" data-book-page-rel-url="docs/21.html" data-book-page-id="11512">2.2. 流形学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/22.html" title="2.3. 聚类" data-book-page-rel-url="docs/22.html" data-book-page-id="11513">2.3. 聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/23.html" title="2.4. 双聚类" data-book-page-rel-url="docs/23.html" data-book-page-id="11514">2.4. 双聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/24.html" title="2.5. 分解成分中的信号（矩阵分解问题）" data-book-page-rel-url="docs/24.html" data-book-page-id="11515">2.5. 分解成分中的信号（矩阵分解问题）</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/25.html" title="2.6. 协方差估计" data-book-page-rel-url="docs/25.html" data-book-page-id="11516">2.6. 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/26.html" title="2.7. 经验协方差" data-book-page-rel-url="docs/26.html" data-book-page-id="11517">2.7. 经验协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/27.html" title="2.8. 收敛协方差" data-book-page-rel-url="docs/27.html" data-book-page-id="11518">2.8. 收敛协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/28.html" title="2.9. 稀疏逆协方差" data-book-page-rel-url="docs/28.html" data-book-page-id="11519">2.9. 稀疏逆协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/29.html" title="2.10. Robust 协方差估计" data-book-page-rel-url="docs/29.html" data-book-page-id="11520">2.10. Robust 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/30.html" title="2.11. 新奇和异常值检测" data-book-page-rel-url="docs/30.html" data-book-page-id="11521">2.11. 新奇和异常值检测</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/31.html" title="2.12. 密度估计" data-book-page-rel-url="docs/31.html" data-book-page-id="11522">2.12. 密度估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/32.html" title="2.13. 神经网络模型（无监督）" data-book-page-rel-url="docs/32.html" data-book-page-id="11523">2.13. 神经网络模型（无监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/33.html" title="3. 模型选择和评估" data-book-page-rel-url="docs/33.html" data-book-page-id="11524">3. 模型选择和评估</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/34.html" title="3.1. 交叉验证：评估估算器的表现" data-book-page-rel-url="docs/34.html" data-book-page-id="11525">3.1. 交叉验证：评估估算器的表现</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/35.html" title="3.2. 调整估计器的超参数" data-book-page-rel-url="docs/35.html" data-book-page-id="11526">3.2. 调整估计器的超参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/53.html" title="3.3. 模型评估: 量化预测的质量" data-book-page-rel-url="docs/53.html" data-book-page-id="11527">3.3. 模型评估: 量化预测的质量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/54.html" title="3.4. 模型持久化" data-book-page-rel-url="docs/54.html" data-book-page-id="11528">3.4. 模型持久化</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/55.html" title="3.5. 验证曲线: 绘制分数以评估模型" data-book-page-rel-url="docs/55.html" data-book-page-id="11529">3.5. 验证曲线: 绘制分数以评估模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/56.html" title="4. 数据集转换" data-book-page-rel-url="docs/56.html" data-book-page-id="11530">4. 数据集转换</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/57.html" title="4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器" data-book-page-rel-url="docs/57.html" data-book-page-id="11531">4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/58.html" title="4.2. 特征提取" data-book-page-rel-url="docs/58.html" data-book-page-id="11532">4.2. 特征提取</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/59.html" title="4.3. 预处理数据" data-book-page-rel-url="docs/59.html" data-book-page-id="11533">4.3. 预处理数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/60.html" title="4.4. 无监督降维" data-book-page-rel-url="docs/60.html" data-book-page-id="11534">4.4. 无监督降维</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/61.html" title="4.5. 随机投影" data-book-page-rel-url="docs/61.html" data-book-page-id="11535">4.5. 随机投影</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/62.html" title="4.6. 内核近似" data-book-page-rel-url="docs/62.html" data-book-page-id="11536">4.6. 内核近似</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/63.html" title="4.7. 成对的矩阵, 类别和核函数" data-book-page-rel-url="docs/63.html" data-book-page-id="11537">4.7. 成对的矩阵, 类别和核函数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/64.html" title="4.8. 预测目标 (`y`.html) 的转换" data-book-page-rel-url="docs/64.html" data-book-page-id="11538">4.8. 预测目标 (`y`.html) 的转换</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/65.html" title="5. 数据集加载工具" data-book-page-rel-url="docs/65.html" data-book-page-id="11539">5. 数据集加载工具</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/66.html" title="6. 大规模计算的策略: 更大量的数据" data-book-page-rel-url="docs/66.html" data-book-page-id="11540">6. 大规模计算的策略: 更大量的数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/67.html" title="7. 计算性能" data-book-page-rel-url="docs/67.html" data-book-page-id="11541">7. 计算性能</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/68.html" title="使用 scikit-learn 介绍机器学习" data-book-page-rel-url="docs/68.html" data-book-page-id="11542">使用 scikit-learn 介绍机器学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/69.html" title="关于科学数据处理的统计学习教程" data-book-page-rel-url="docs/69.html" data-book-page-id="11543">关于科学数据处理的统计学习教程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/70.html" title="机器学习: scikit-learn 中的设置以及预估对象" data-book-page-rel-url="docs/70.html" data-book-page-id="11544">机器学习: scikit-learn 中的设置以及预估对象</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/71.html" title="监督学习：从高维观察预测输出变量" data-book-page-rel-url="docs/71.html" data-book-page-id="11545">监督学习：从高维观察预测输出变量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/72.html" title="模型选择：选择估计量及其参数" data-book-page-rel-url="docs/72.html" data-book-page-id="11546">模型选择：选择估计量及其参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/73.html" title="无监督学习: 寻求数据表示" data-book-page-rel-url="docs/73.html" data-book-page-id="11547">无监督学习: 寻求数据表示</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/74.html" title="把它们放在一起" data-book-page-rel-url="docs/74.html" data-book-page-id="11548">把它们放在一起</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/75.html" title="寻求帮助" data-book-page-rel-url="docs/75.html" data-book-page-id="11549">寻求帮助</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/76.html" title="处理文本数据" data-book-page-rel-url="docs/76.html" data-book-page-id="11550">处理文本数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/77.html" title="选择正确的评估器(estimator.html)" data-book-page-rel-url="docs/77.html" data-book-page-id="11551">选择正确的评估器(estimator.html)</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/78.html" title="外部资源，视频和谈话" data-book-page-rel-url="docs/78.html" data-book-page-id="11552">外部资源，视频和谈话</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/80.html" title="常见问题" data-book-page-rel-url="docs/80.html" data-book-page-id="11553">常见问题</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/81.html" title="时光轴" data-book-page-rel-url="docs/81.html" data-book-page-id="11554">时光轴</a>
</li>
</ul>
</div>
</div>
<script src="https://cdn.staticfile.net/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="../../../static/components/uikit-2.27.5/js/uikit.reader.js"></script>
<script type="text/javascript" src="../../../static/components/social-share/social-share.min.js"></script>
<script>(function(){var bp =document.createElement('script');var curProtocol =window.location.protocol.split(':')[0];if (curProtocol ==='https') {bp.src ='https://zz.bdstatic.com/linksubmit/push.js';}
else {bp.src ='http://push.zhanzhang.baidu.com/push.js';}
var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp,s);})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
<script src="https://cdn.staticfile.net/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.net/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script src="https://cdn.staticfile.net/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="https://cdn.staticfile.net/uikit/2.27.5/js/components/lightbox.min.js"></script>
<link rel="dns-prefetch" href="../../..//cdn.mathjax.org" />
<script type="text/x-mathjax-config">
 function initMathJax() {
    var mathId = $("book-content-section")[0];
    MathJax.Hub.Config({
        tex2jax: {skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a']},
        showProcessingMessages: false,
        messageStyle: "none"
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub,mathId]);
 };
initMathJax();
</script>
<script src='https://cdn.staticfile.net/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML' async></script>
<style>
	.MathJax_Display{display:inline!important;}
</style>
<script type="text/javascript" src="../../../static/components/js/reader.js"></script>
<script type="text/javascript">var bookId =170;var bookPageId =11533;var bookPageRelUrl ='docs/59.html';</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
</body>
</html>