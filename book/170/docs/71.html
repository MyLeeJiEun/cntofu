
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>监督学习：从高维观察预测输出变量-scikit-learn (sklearn) 官方文档中文版</title>
<meta content='监督学习：从高维观察预测输出变量,scikit-learn (sklearn) 官方文档中文版' name='keywords'>
<meta content='监督学习：从高维观察预测输出变量,scikit-learn (sklearn) 官方文档中文版' name='description'>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=1, user-scalable=no"../../../>
<meta name="applicable-device" content="pc,mobile">
<link rel="shortcut icon" href="../../../favicon.ico" type="image/x-icon" />
<meta name="renderer" content="webkit">
<link rel="stylesheet" href="../../../static/components/uikit-2.27.5/css/uikit.custom.css">
<link rel="stylesheet" href="../../../static/components/social-share/social-share.min.css">
<link rel="stylesheet" href="../../../static/components/highlight/styles/custom.css">
<link rel="stylesheet" href="../../../static/components/css/base.css">
<link rel="stylesheet" href="../../../static/components/css/reader.css">
<link rel="stylesheet" href="../../../static/components/css/markdown.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5313208362165053" crossorigin="anonymous"></script>
</head>
<body>
<div class=" book-main-wrap uk-container uk-container-center uk-margin-top ">
<div class="uk-grid">
<div class="uk-width-1-1 reader-wrap ">
<div class=" bottom-nav uk-clearfix ">
<div class="uk-align-left ">
<a href="../../../book/170/docs/70.html">
<i class="nav-icon-left uk-icon-small  uk-icon-caret-left"></i>
<span class="">机器学习: sciki..</span>
</a>
</div>
<div class="uk-align-right ">
<a href="../../../book/170/docs/72.html">
<span class="">模型选择：选择估计量及..</span>
<i class="nav-icon-right uk-icon-small  uk-icon-caret-right"></i>
</a>
</div>
</div>
<div class="uk-text-center">
<h2 class="book-page-title uk-container-center">
<a href="../../../book/170/index.html">scikit-learn (sklearn) 官方文档中文版</a>
<a target="_blank" rel="nofollow" href="https://github.com/apachecn/scikit-learn-doc-zh" class="uk-icon-button uk-icon-github" title="github项目地址"></a>
</h2>
</div>
<script type="text/javascript" src="../../../static/components/js/app_intro.js"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5313208362165053" data-ad-slot="1328047120"></ins>
<script>(adsbygoogle =window.adsbygoogle ||[]).push({});</script>
<hr class="uk-article-divider">
<div class="book-content-section  md-content-section  uk-margin-bottom">
<h1 id="监督学习从高维观察预测输出变量">监督学习：从高维观察预测输出变量</h1>
<p>校验者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@Kyrie</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@片刻</a> 翻译者: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/apachecn/scikit-learn-doc-zh">@森系</a></p>
<p>监督学习解决的问题</p>
<p><a href="../../supervised_learning.html#supervised-learning">监督学习</a> 在于学习两个数据集的联系：观察数据 <code>X</code> 和我们正在尝试预测的额外变量 <code>y</code> (通常称“目标”或“标签”)， 而且通常是长度为 <code>n_samples</code> 的一维数组。</p>
<p>scikit-learn 中所有监督的 &lt;cite&gt;估计量 &lt;https://en.wikipedia.org/wiki/Estimator&gt;&lt;/cite&gt; 都有一个用来拟合模型的 <code>fit(X, y)</code> 方法，和根据给定的没有标签观察值 <code>X</code> 返回预测的带标签的 <code>y</code> 的 <code>predict(X)</code> 方法。</p>
<p>词汇：分类和回归</p>
<p>如果预测任务是为了将观察值分类到有限的标签集合中，换句话说，就是给观察对象命名，那任务就被称为 <strong>分类</strong> 任务。另外，如果任务是为了预测一个连续的目标变量，那就被称为 <strong>回归</strong> 任务。</p>
<p>当在 scikit-learn 中进行分类时，<code>y</code> 是一个整数或字符型的向量。</p>
<p>注：可以查看 :ref: &lt;cite&gt;用 scikit-learn 进行机器学习介绍 &lt;introduction&gt;&lt;/cite&gt; 快速了解机器学习中的基础词汇。</p>
<h2 id="最近邻和维度惩罚">最近邻和维度惩罚</h2>
<p>鸢尾属植物分类：</p>
<p><a href="../../auto_examples/datasets/plot_iris_dataset.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4246a718076893e37084bc69a7e16007.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4246a718076893e37084bc69a7e16007.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_iris_dataset_001.png"></a></a></p>
<p>鸢尾属植物数据集是根据花瓣长度、花瓣度度、萼片长度和萼片宽度4个特征对3种不同类型的鸢尾属植物进行分类:</p>
<pre><code class="language-py">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn import datasets
&gt;&gt;&gt; iris = datasets.load_iris()
&gt;&gt;&gt; iris_X = iris.data
&gt;&gt;&gt; iris_y = iris.target
&gt;&gt;&gt; np.unique(iris_y)
array([0, 1, 2])

</code></pre>
<h3 id="k近邻分类器">K近邻分类器</h3>
<p><a href="https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm">最近邻</a>: 也许是最简单的分类器：给定一个新的观察值 <code>X_test</code>，用最接近的特征向量在训练集(比如，用于训练估计器的数据)找到观察值。(请看 Scikit-learn 在线学习文档的 <a href="../../modules/neighbors.html#neighbors">最近邻章节</a> 获取更多关于这种分类器的信息)</p>
<p>训练集和测试集</p>
<p>当用任意的学习算法进行实验时，最重要的就是不要在用于拟合估计器的数据上测试一个估计器的预期值，因为这不会评估在 <strong>新数据</strong> 上估计器的执行情况。这也是数据集经常被分为 <em>训练</em> 和 <em>测试</em> 数据的原因。</p>
<p><strong>KNN(k 最近邻)分类器例子</strong>:</p>
<p><a href="../../auto_examples/neighbors/plot_classification.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/86003b5287219bcbec1586985a110629.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/86003b5287219bcbec1586985a110629.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_classification_001.png"></a></a></p>
<pre><code class="language-py">&gt;&gt;&gt; # 将鸢尾属植物数据集分解为训练集和测试集
&gt;&gt;&gt; # 随机排列，用于使分解的数据随机分布
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; indices = np.random.permutation(len(iris_X))
&gt;&gt;&gt; iris_X_train = iris_X[indices[:-10]]
&gt;&gt;&gt; iris_y_train = iris_y[indices[:-10]]
&gt;&gt;&gt; iris_X_test  = iris_X[indices[-10:]]
&gt;&gt;&gt; iris_y_test  = iris_y[indices[-10:]]
&gt;&gt;&gt; # 创建和拟合一个最近邻分类器
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; knn = KNeighborsClassifier()
&gt;&gt;&gt; knn.fit(iris_X_train, iris_y_train) 
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
 metric_params=None, n_jobs=1, n_neighbors=5, p=2,
 weights='uniform')
&gt;&gt;&gt; knn.predict(iris_X_test)
array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])
&gt;&gt;&gt; iris_y_test
array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])

</code></pre>
<h3 id="维度惩罚">维度惩罚</h3>
<p>为了使一个估计器有效，你需要邻接点间的距离小于一些值：<a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/adf83056bc2bd05628e24c40cb728b3d.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/adf83056bc2bd05628e24c40cb728b3d.jpg" alt="d"></a>，这取决于具体问题。在一维中，这需要平均 &lt;cite&gt;n sim 1/d&lt;/cite&gt; 点。在上文 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a>-NN 例子中，如果数据只是由一个0到1的特征值和 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"></a> 训练观察值所描述，那么新数据将不会超过 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0a3546c8f30354c128ef2acb96e91e16.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0a3546c8f30354c128ef2acb96e91e16.jpg" alt="1/n"></a>。因此，最近邻决策规则会很有效率，因为与类间特征变量范围相比， <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0a3546c8f30354c128ef2acb96e91e16.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0a3546c8f30354c128ef2acb96e91e16.jpg" alt="1/n"></a> 很小。</p>
<p>如果特征数是 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" alt="p"></a>，你现在就需要 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6bcc641ece97b81c42261e28eaad3ad7.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6bcc641ece97b81c42261e28eaad3ad7.jpg" alt="n \sim 1/d^p"></a> 点。也就是说我们在一维 !<a href="0,-1">0, 1</a>(img/35b3276dd7e50cda7dd79a91161a1a26.jpg) 空间里需要10个点，在 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" alt="p"></a> 维里就需要 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e5ad06b17e1bacf475bf9247d93d1419.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e5ad06b17e1bacf475bf9247d93d1419.jpg" alt="10^p"></a> 个点。当 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/e2f9b08680b30cfb80102f69264fdd5c.jpg" alt="p"></a> 增大时，为了得到一个好的估计器，相应的训练点数量就需要成倍增大。</p>
<p>比如，如果每个点只是单个数字(8个字节)，那么一个 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"></a>-NN 估计器在一个非常小的 <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/ac11972df0ad68aba63757a4ba1ee02b.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/ac11972df0ad68aba63757a4ba1ee02b.jpg" alt="p \sim 20"></a> 维度下就需要比现在估计的整个互联网的大小(±1000 艾字节或更多)还要多的训练数据。</p>
<p>这叫 <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">维度惩罚</a>，是机器学习领域的核心问题。</p>
<h2 id="线性模型从回归到稀疏">线性模型：从回归到稀疏</h2>
<p>糖尿病数据集</p>
<p>糖尿病数据集包括442名患者的10个生理特征(年龄，性别，体重，血压)，和一年后的疾病级别指标:</p>
<pre><code class="language-py">&gt;&gt;&gt; diabetes = datasets.load_diabetes()
&gt;&gt;&gt; diabetes_X_train = diabetes.data[:-20]
&gt;&gt;&gt; diabetes_X_test  = diabetes.data[-20:]
&gt;&gt;&gt; diabetes_y_train = diabetes.target[:-20]
&gt;&gt;&gt; diabetes_y_test  = diabetes.target[-20:]

</code></pre>
<p>手头上的任务是为了从生理特征预测疾病级别。</p>
<h3 id="线性回归">线性回归</h3>
<p><a href="../../modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code>LinearRegression</code></a>，最简单的拟合线性模型形式，是通过调整数据集的一系列参数令残差平方和尽可能小。</p>
<p><a href="../../auto_examples/linear_model/plot_ols.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/7a9775b9051c948f74639f1856f6c585.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/7a9775b9051c948f74639f1856f6c585.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_ols_001.png"></a></a></p>
<p>Linear models: <a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c5f2af9df9f65f0e399542ecf7f40554.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c5f2af9df9f65f0e399542ecf7f40554.jpg" alt="y = X\beta + \epsilon"></a></p>
<blockquote>
<ul>
<li><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43c1fea57579e54f80c0535bc582626f.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/43c1fea57579e54f80c0535bc582626f.jpg" alt="X"></a>: 数据</li>
<li><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0775c03fc710a24df297dedcec515aaf.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/0775c03fc710a24df297dedcec515aaf.jpg" alt="y"></a>: 目标变量</li>
<li><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/533e54759d696211ebe7819cc107d3bc.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/533e54759d696211ebe7819cc107d3bc.jpg" alt="\beta"></a>: 回归系数</li>
<li><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/58ef9e1b5d2ee139dcb588a3879ca1a6.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/58ef9e1b5d2ee139dcb588a3879ca1a6.jpg" alt="\epsilon"></a>: 观察噪声</li>
</ul>
</blockquote>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn import linear_model
&gt;&gt;&gt; regr = linear_model.LinearRegression()
&gt;&gt;&gt; regr.fit(diabetes_X_train, diabetes_y_train)
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
&gt;&gt;&gt; print(regr.coef_)
[   0.30349955 -237.63931533  510.53060544  327.73698041 -814.13170937
 492.81458798  102.84845219  184.60648906  743.51961675   76.09517222]

&gt;&gt;&gt; # 均方误差
&gt;&gt;&gt; np.mean((regr.predict(diabetes_X_test)-diabetes_y_test)**2)
2004.56760268...

&gt;&gt;&gt; # 方差分数：1 是完美的预测
&gt;&gt;&gt; # 0 意味着 X 和 y 之间没有线性关系。
&gt;&gt;&gt; regr.score(diabetes_X_test, diabetes_y_test) 
0.5850753022690...

</code></pre>
<h3 id="收缩">收缩</h3>
<p>如果每个维度的数据点很少，观察噪声就会导致很大的方差：</p>
<p><a href="../../auto_examples/linear_model/plot_ols_ridge_variance.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f28436a66fb892c9e8923e6649f19065.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/f28436a66fb892c9e8923e6649f19065.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_ols_ridge_variance_001.png"></a></a></p>
<pre><code class="language-py">&gt;&gt;&gt; X = np.c_[ .5, 1].T
&gt;&gt;&gt; y = [.5, 1]
&gt;&gt;&gt; test = np.c_[ 0, 2].T
&gt;&gt;&gt; regr = linear_model.LinearRegression()

&gt;&gt;&gt; import matplotlib.pyplot as plt 
&gt;&gt;&gt; plt.figure() 

&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; for _ in range(6): 
...    this_X = .1*np.random.normal(size=(2, 1)) + X
...    regr.fit(this_X, y)
...    plt.plot(test, regr.predict(test)) 
...    plt.scatter(this_X, y, s=3)  

</code></pre>
<p>高纬统计学习中的一个解决方法是 <em>收缩</em> 回归系数到0：任何两个随机选择的观察值数据集都很可能是不相关的。这称为 &lt;cite&gt;岭回归&lt;/cite&gt; ：</p>
<p><a href="../../auto_examples/linear_model/plot_ols_ridge_variance.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6518e8fbaaadd8a258c9a3f96b2ef42e.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6518e8fbaaadd8a258c9a3f96b2ef42e.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_ols_ridge_variance_002.png"></a></a></p>
<pre><code class="language-py">&gt;&gt;&gt; regr = linear_model.Ridge(alpha=.1)

&gt;&gt;&gt; plt.figure() 

&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; for _ in range(6): 
...    this_X = .1*np.random.normal(size=(2, 1)) + X
...    regr.fit(this_X, y)
...    plt.plot(test, regr.predict(test)) 
...    plt.scatter(this_X, y, s=3) 

</code></pre>
<p>这是 <strong>bias/variance tradeoff</strong> 中的一个例子：岭参数 <code>alpha</code> 越大，偏差越大，方差越小。</p>
<p>我们可以选择 <code>alpha</code> 来最小化排除错误，这里使用糖尿病数据集而不是人为数据:</p>
<pre><code class="language-py">&gt;&gt;&gt; alphas = np.logspace(-4, -1, 6)
&gt;&gt;&gt; from __future__ import print_function
&gt;&gt;&gt; print([regr.set_params(alpha=alpha
...             ).fit(diabetes_X_train, diabetes_y_train,
...             ).score(diabetes_X_test, diabetes_y_test) for alpha in alphas]) 
[0.5851110683883..., 0.5852073015444..., 0.5854677540698..., 0.5855512036503..., 0.5830717085554..., 0.57058999437...]

</code></pre>
<p>Note</p>
<p>捕获拟合参数噪声使得模型不能归纳新的数据称为 <a href="https://en.wikipedia.org/wiki/Overfitting">过拟合</a>。岭回归产生的偏差被称为 <a href="https://en.wikipedia.org/wiki/Regularization_%28machine_learning%29">正则化</a>。</p>
<h3 id="稀疏">稀疏</h3>
<p><strong>只拟合特征1和2</strong></p>
<p><strong><a href="../../auto_examples/linear_model/plot_ols_3d.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/9a5f8912e7fe77be2acea88fd091a5d8.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/9a5f8912e7fe77be2acea88fd091a5d8.jpg" alt="diabetes_ols_1"></a></a> <a href="../../auto_examples/linear_model/plot_ols_3d.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/14d65d3148b0ea7c9ecb364423ecb0ed.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/14d65d3148b0ea7c9ecb364423ecb0ed.jpg" alt="diabetes_ols_3"></a></a> <a href="../../auto_examples/linear_model/plot_ols_3d.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/8c8c09a18e398935473d8b69cf1b617e.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/8c8c09a18e398935473d8b69cf1b617e.jpg" alt="diabetes_ols_2"></a></a></strong></p>
<p>Note</p>
<p>整个糖尿病数据集包括11个维度(10个特征维度和1个目标变量)。很难直观地表示出来，但是记住那是一个比较 <em>空</em> 的空间可能比较有用。</p>
<p>我们可以看到，尽管特征2在整个模型占有一个很大的系数，但是当考虑特征1时，其对 <code>y</code> 的影响就较小了。</p>
<p>为了提高问题的条件(比如，缓解<code>维度惩罚</code>)，只选择信息特征和设置无信息时就会变得有趣，比如特征2到0。岭回归会减小他们的值，但不会减到0.另一种抑制方法，称为 <a href="../../modules/linear_model.html#lasso">Lasso</a> (最小绝对收缩和选择算子)，可以把一些系数设为0。这些方法称为 <strong>稀疏法</strong>，稀疏可以看作是奥卡姆剃刀的应用：<em>模型越简单越好</em>。</p>
<pre><code class="language-py">&gt;&gt;&gt; regr = linear_model.Lasso()
&gt;&gt;&gt; scores = [regr.set_params(alpha=alpha
...             ).fit(diabetes_X_train, diabetes_y_train
...             ).score(diabetes_X_test, diabetes_y_test)
...        for alpha in alphas]
&gt;&gt;&gt; best_alpha = alphas[scores.index(max(scores))]
&gt;&gt;&gt; regr.alpha = best_alpha
&gt;&gt;&gt; regr.fit(diabetes_X_train, diabetes_y_train)
Lasso(alpha=0.025118864315095794, copy_X=True, fit_intercept=True,
 max_iter=1000, normalize=False, positive=False, precompute=False,
 random_state=None, selection='cyclic', tol=0.0001, warm_start=False)
&gt;&gt;&gt; print(regr.coef_)
[   0\.         -212.43764548  517.19478111  313.77959962 -160.8303982    -0.
 -187.19554705   69.38229038  508.66011217   71.84239008]

</code></pre>
<p><strong>同一个问题的不同算法</strong></p>
<p>不同的算法可以用于解决同一个数学问题。比如在 scikit-learn 里 <code>Lasso</code> 对象使用 <a href="https://en.wikipedia.org/wiki/Coordinate_descent">coordinate descent</a> 方法解决 lasso 回归问题，对于大型数据集很有效。但是，scikit-learn 也提供了使用 <em>LARS</em> 算法 的:class:&lt;cite&gt;LassoLars&lt;/cite&gt; 对象，对于处理带权向量非常稀疏的数据非常有效(比如，问题的观察值很少)。</p>
<h3 id="分类">分类</h3>
<p><a href="../../auto_examples/linear_model/plot_logistic.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6efb484bc0e0c91b3ba13708bfe46aba.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/6efb484bc0e0c91b3ba13708bfe46aba.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_logistic_001.png"></a></a></p>
<p>对于分类，比如标定 <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">鸢尾属植物</a> 任务，线性回归就不是好方法了，因为它会给数据很多远离决策边界的权值。一个线性方法是为了拟合 sigmoid 函数 或 <strong>logistic</strong> 函数：</p>
<pre><code class="language-py">
![y = \textrm{sigmoid}(X\beta - \textrm{offset}) + \epsilon =
\frac{1}{1 + \textrm{exp}(- X\beta + \textrm{offset})} + \epsilon](img/5b84281b8f1a26c9e9cba1b6cb0126ce.jpg)

</code></pre>
<pre><code class="language-py">&gt;&gt;&gt; logistic = linear_model.LogisticRegression(C=1e5)
&gt;&gt;&gt; logistic.fit(iris_X_train, iris_y_train)
LogisticRegression(C=100000.0, class_weight=None, dual=False,
 fit_intercept=True, intercept_scaling=1, max_iter=100,
 multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,
 solver='liblinear', tol=0.0001, verbose=0, warm_start=False)

</code></pre>
<p>这就是有名的： <a href="../../modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code>LogisticRegression</code></a></p>
<p><a href="../../auto_examples/linear_model/plot_iris_logistic.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/b6305894a6f400569f3ff2b899370b54.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/b6305894a6f400569f3ff2b899370b54.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_iris_logistic_001.png"></a></a></p>
<p>多类分类</p>
<p>如果你有很多类需要预测，一种常用方法就是去拟合一对多分类器，然后使用根据投票为最后做决定。</p>
<p>使用 logistic 回归进行收缩和稀疏</p>
<p><a href="../../modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code>LogisticRegression</code></a> 对象中的 <code>C</code> 参数控制着正则化数量：<code>C</code> 值越大，正则化数量越小。<code>penalty="l2"</code> 提供 收缩<code>(比如，无稀疏系数)，同时 ``penalty=”l1”</code> 提供<code>稀疏化</code>。</p>
<p><strong>练习</strong></p>
<p>尝试用最近邻和线性模型分类数字数据集。留出最后 10%的数据，并测试观察值预期效果。</p>
<pre><code class="language-py">from sklearn import datasets, neighbors, linear_model

digits = datasets.load_digits()
X_digits = digits.data
y_digits = digits.target

</code></pre>
<p>方法: <a href="../../_downloads/plot_digits_classification_exercise.py"><code>../../auto_examples/exercises/plot_digits_classification_exercise.py</code></a></p>
<h2 id="支持向量积svms">支持向量积(SVMs)</h2>
<h3 id="线性-svms">线性 SVMs</h3>
<p><a href="../../modules/svm.html#svm">支持向量机</a> 属于判别模型家族：它们尝试通过找到样例的一个组合来构建一个两类之间最大化的平面。通过 <code>C</code> 参数进行正则化设置：<code>C</code> 的值小意味着边缘是通过分割线周围的所有观测样例进行计算得到的(更正则化)；<code>C</code> 的值大意味着边缘是通过邻近分割线的观测样例计算得到的(更少正则化)。</p>
<p>例子:</p>
<ul>
<li><a href="../../auto_examples/svm/plot_iris.html#sphx-glr-auto-examples-svm-plot-iris-py">Plot different SVM classifiers in the iris dataset</a></li>
</ul>
<p>SVMs 可以用于回归 –:class: &lt;cite&gt;SVR&lt;/cite&gt; (支持向量回归)–，或者分类 –:class: &lt;cite&gt;SVC&lt;/cite&gt; (支持向量分类)。</p>
<pre><code class="language-py">&gt;&gt;&gt; from sklearn import svm
&gt;&gt;&gt; svc = svm.SVC(kernel='linear')
&gt;&gt;&gt; svc.fit(iris_X_train, iris_y_train)    
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
 decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
 max_iter=-1, probability=False, random_state=None, shrinking=True,
 tol=0.001, verbose=False)

</code></pre>
<p>Warning</p>
<p><strong>规格化数据</strong></p>
<p>对很多估计器来说，包括 SVMs，为每个特征值使用单位标准偏差的数据集，是获得好的预测重要前提。</p>
<h3 id="使用核">使用核</h3>
<p>在特征空间类并不总是线性可分的。解决办法就是构建一个不是线性的但能是多项式的函数做代替。这要使用 <em>核技巧(kernel trick)</em>，它可以被看作通过设置 <em>kernels</em> 在观察样例上创建决策力量：</p>
<p>| <strong>线性核</strong> | <strong>多项式核</strong> | | <a href="../../auto_examples/svm/plot_svm_kernels.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/93401b902ac1e2a94ff3ce04e7f05882.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/93401b902ac1e2a94ff3ce04e7f05882.jpg" alt="svm_kernel_linear"></a></a> | <a href="../../auto_examples/svm/plot_svm_kernels.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/abed66e83395b34fe3c020cfcab3dce9.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/abed66e83395b34fe3c020cfcab3dce9.jpg" alt="svm_kernel_poly"></a></a> | |</p>
<pre><code class="language-py">&amp;gt;&amp;gt;&amp;gt; svc = svm.SVC(kernel='linear')

</code></pre>
<p>|</p>
<pre><code class="language-py">&amp;gt;&amp;gt;&amp;gt; svc = svm.SVC(kernel='poly',
...               degree=3)
&amp;gt;&amp;gt;&amp;gt; # degree: polynomial degree

</code></pre>
<p>|</p>
<p>| <strong>RBF 内核(径向基函数)</strong> | | <a href="../../auto_examples/svm/plot_svm_kernels.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c458cf14df5a22e0d44d7c4fa458361d.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/c458cf14df5a22e0d44d7c4fa458361d.jpg" alt="svm_kernel_rbf"></a></a> | |</p>
<pre><code class="language-py">&amp;gt;&amp;gt;&amp;gt; svc = svm.SVC(kernel='rbf')
&amp;gt;&amp;gt;&amp;gt; # gamma: inverse of size of
&amp;gt;&amp;gt;&amp;gt; # radial kernel

</code></pre>
<p>|</p>
<p><strong>交互例子</strong></p>
<p>查看 <a href="../../auto_examples/applications/svm_gui.html#sphx-glr-auto-examples-applications-svm-gui-py">SVM GUI</a> 通过下载 <code>svm_gui.py</code>；通过左右按键添加两类数据点，拟合模型并改变参数和数据。</p>
<p><a href="../../auto_examples/datasets/plot_iris_dataset.html"><a href="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4246a718076893e37084bc69a7e16007.jpg" data-uk-lightbox><img src="https://img.cntofu.com/book/scikit-learn-doc-zh/docs/img/4246a718076893e37084bc69a7e16007.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_iris_dataset_001.png"></a></a></p>
<p><strong>练习</strong></p>
<p>根据特征1和特征2，尝试用 SVMs 把1和2类从鸢尾属植物数据集中分出来。为每一个类留下10%，并测试这些观察值预期效果。</p>
<p><strong>警告</strong>: 类是有序的，不要留下最后10%，不然你只能测试一个类了。</p>
<p><strong>提示</strong>: 为了直观显示，你可以在网格上使用 <code>decision_function</code> 方法。</p>
<pre><code class="language-py">iris = datasets.load_iris()
X = iris.data
y = iris.target

X = X[y != 0, :2]
y = y[y != 0]

</code></pre>
<p>方法: <a href="../../_downloads/plot_iris_exercise.py"><code>../../auto_examples/exercises/plot_iris_exercise.py</code></a></p>
</div>
<hr class="uk-article-divider">
<div class="uk-block uk-block-muted uk-padding-top-remove uk-padding-bottom-remove uk-margin-large-top  book-recommend-wrap">
<div class="uk-margin-top uk-margin-bottom uk-margin-left uk-margin-right">
<div class="uk-margin uk-text-muted "><i class="uk-icon-outdent uk-icon-justify uk-margin-small-right"></i>书籍推荐</div>
<div class="books">
<ul class="uk-book-list">
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/130/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/130/index.html">进击的Python</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/68.html">HuberTRoy</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">23页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年7月8日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 169个">169</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/156/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/156/index.html">pyspider中文文档</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/88.html">aaronhua123</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">18页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月12日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 1个">1</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/154/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/154/index.html">Python 学习总结</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/86.html">itroger</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">11页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月12日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 0个">0</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/41/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/android_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/41/index.html">Android官方培訓課程中文版</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/22.html">jasonblog</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="android">android</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">294页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年5月29日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 1个">1</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/10/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/java_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/10/index.html">Java 编码规范</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/6.html">waylau</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="java">java</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">12页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年5月3日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 127个">127</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../book/101/index.html">
<img class="uk-book-cover" src="../../../static/icons/48/chrome_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../book/101/index.html">Chromium中文文档</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../user/62.html">tzivanmoe</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="chrome">chrome</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">165页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月29日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 0个">0</span>
</div>
</div>
</div>
</li>
<hr>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<nav class="tm-navbar uk-navbar uk-navbar-attached reader-nav">
<div class="uk-float-left uk-margin-small-top">
<a href="javascript:;" title="目录菜单" class="show-menu  uk-icon-hover  uk-icon-align-justify uk-margin-right"></a>
<div data-uk-dropdown="{mode:'click',pos:'bottom-left'}" class="font-setting-wrap">
<a class="uk-icon-hover uk-icon-font uk-margin-right" aria-label="字体设置" href="javascript:;"></a>
<div class="uk-dropdown dropdown-menu">
<div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-reduce">小字</button>
<button class="uk-button-link button size-2 font-enlarge">大字</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-1 ">宋体</button>
<button class="uk-button-link button size-2 font-2 ">黑体</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-3 color-theme-sun "><i class="uk-icon-sun-o"></i>白天</button>
<button class="uk-button-link button size-3 color-theme-eye "><i class="uk-icon-eye"></i>护眼</button>
<button class="uk-button-link button size-3 color-theme-moon "><i class="uk-icon-moon-o"></i>夜晚</button></div>
</div>
</div>
<a class="logo uk-margin-right" href="../../../" title="返回首页"><img class="" src="../../../static/components/images/icon_32.png" /></a>
</div>
<div class="uk-navbar-flip  uk-hidden-small">
<div id="share-box"></div>
</div>
</nav>
<div id="menu-id" class="uk-offcanvas reader-offcanvas">
<div class="uk-offcanvas-bar">
<ul class="book-menu-bar uk-nav uk-nav-offcanvas" data-uk-nav>
<li>
<a href="../../../book/170/index.html" data-book-page-rel-url="index.html" data-book-page-id="0" title="封面">封面</a>
</li>
<li>
<a class="pjax" href="../../../book/170/readme.html" data-book-page-rel-url="readme.html" data-book-page-id="0" title="简介">简介</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/79.html" title="安装 scikit-learn" data-book-page-rel-url="docs/79.html" data-book-page-id="11491">安装 scikit-learn</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/1.html" title="1. 监督学习" data-book-page-rel-url="docs/1.html" data-book-page-id="11492">1. 监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/2.html" title="1.1. 广义线性模型" data-book-page-rel-url="docs/2.html" data-book-page-id="11493">1.1. 广义线性模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/3.html" title="1.2. 线性和二次判别分析" data-book-page-rel-url="docs/3.html" data-book-page-id="11494">1.2. 线性和二次判别分析</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/4.html" title="1.3. 内核岭回归" data-book-page-rel-url="docs/4.html" data-book-page-id="11495">1.3. 内核岭回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/5.html" title="1.4. 支持向量机" data-book-page-rel-url="docs/5.html" data-book-page-id="11496">1.4. 支持向量机</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/6.html" title="1.5. 随机梯度下降" data-book-page-rel-url="docs/6.html" data-book-page-id="11497">1.5. 随机梯度下降</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/7.html" title="1.6. 最近邻" data-book-page-rel-url="docs/7.html" data-book-page-id="11498">1.6. 最近邻</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/8.html" title="1.7. 高斯过程" data-book-page-rel-url="docs/8.html" data-book-page-id="11499">1.7. 高斯过程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/9.html" title="1.8. 交叉分解" data-book-page-rel-url="docs/9.html" data-book-page-id="11500">1.8. 交叉分解</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/10.html" title="1.9. 朴素贝叶斯" data-book-page-rel-url="docs/10.html" data-book-page-id="11501">1.9. 朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/11.html" title="1.10. 决策树" data-book-page-rel-url="docs/11.html" data-book-page-id="11502">1.10. 决策树</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/12.html" title="1.11. 集成方法" data-book-page-rel-url="docs/12.html" data-book-page-id="11503">1.11. 集成方法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/13.html" title="1.12. 多类和多标签算法" data-book-page-rel-url="docs/13.html" data-book-page-id="11504">1.12. 多类和多标签算法</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/14.html" title="1.13. 特征选择" data-book-page-rel-url="docs/14.html" data-book-page-id="11505">1.13. 特征选择</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/15.html" title="1.14. 半监督学习" data-book-page-rel-url="docs/15.html" data-book-page-id="11506">1.14. 半监督学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/16.html" title="1.15. 等式回归" data-book-page-rel-url="docs/16.html" data-book-page-id="11507">1.15. 等式回归</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/17.html" title="1.16. 概率校准" data-book-page-rel-url="docs/17.html" data-book-page-id="11508">1.16. 概率校准</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/18.html" title="1.17. 神经网络模型（有监督）" data-book-page-rel-url="docs/18.html" data-book-page-id="11509">1.17. 神经网络模型（有监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/19.html" title="2. 无监督学习" data-book-page-rel-url="docs/19.html" data-book-page-id="11510">2. 无监督学习</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/20.html" title="2.1. 高斯混合模型" data-book-page-rel-url="docs/20.html" data-book-page-id="11511">2.1. 高斯混合模型</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/21.html" title="2.2. 流形学习" data-book-page-rel-url="docs/21.html" data-book-page-id="11512">2.2. 流形学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/22.html" title="2.3. 聚类" data-book-page-rel-url="docs/22.html" data-book-page-id="11513">2.3. 聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/23.html" title="2.4. 双聚类" data-book-page-rel-url="docs/23.html" data-book-page-id="11514">2.4. 双聚类</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/24.html" title="2.5. 分解成分中的信号（矩阵分解问题）" data-book-page-rel-url="docs/24.html" data-book-page-id="11515">2.5. 分解成分中的信号（矩阵分解问题）</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/25.html" title="2.6. 协方差估计" data-book-page-rel-url="docs/25.html" data-book-page-id="11516">2.6. 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/26.html" title="2.7. 经验协方差" data-book-page-rel-url="docs/26.html" data-book-page-id="11517">2.7. 经验协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/27.html" title="2.8. 收敛协方差" data-book-page-rel-url="docs/27.html" data-book-page-id="11518">2.8. 收敛协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/28.html" title="2.9. 稀疏逆协方差" data-book-page-rel-url="docs/28.html" data-book-page-id="11519">2.9. 稀疏逆协方差</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/29.html" title="2.10. Robust 协方差估计" data-book-page-rel-url="docs/29.html" data-book-page-id="11520">2.10. Robust 协方差估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/30.html" title="2.11. 新奇和异常值检测" data-book-page-rel-url="docs/30.html" data-book-page-id="11521">2.11. 新奇和异常值检测</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/31.html" title="2.12. 密度估计" data-book-page-rel-url="docs/31.html" data-book-page-id="11522">2.12. 密度估计</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/32.html" title="2.13. 神经网络模型（无监督）" data-book-page-rel-url="docs/32.html" data-book-page-id="11523">2.13. 神经网络模型（无监督）</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/33.html" title="3. 模型选择和评估" data-book-page-rel-url="docs/33.html" data-book-page-id="11524">3. 模型选择和评估</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/34.html" title="3.1. 交叉验证：评估估算器的表现" data-book-page-rel-url="docs/34.html" data-book-page-id="11525">3.1. 交叉验证：评估估算器的表现</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/35.html" title="3.2. 调整估计器的超参数" data-book-page-rel-url="docs/35.html" data-book-page-id="11526">3.2. 调整估计器的超参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/53.html" title="3.3. 模型评估: 量化预测的质量" data-book-page-rel-url="docs/53.html" data-book-page-id="11527">3.3. 模型评估: 量化预测的质量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/54.html" title="3.4. 模型持久化" data-book-page-rel-url="docs/54.html" data-book-page-id="11528">3.4. 模型持久化</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/55.html" title="3.5. 验证曲线: 绘制分数以评估模型" data-book-page-rel-url="docs/55.html" data-book-page-id="11529">3.5. 验证曲线: 绘制分数以评估模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/56.html" title="4. 数据集转换" data-book-page-rel-url="docs/56.html" data-book-page-id="11530">4. 数据集转换</a>
<ul>
<li>
<a class="pjax" href="../../../book/170/docs/57.html" title="4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器" data-book-page-rel-url="docs/57.html" data-book-page-id="11531">4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/58.html" title="4.2. 特征提取" data-book-page-rel-url="docs/58.html" data-book-page-id="11532">4.2. 特征提取</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/59.html" title="4.3. 预处理数据" data-book-page-rel-url="docs/59.html" data-book-page-id="11533">4.3. 预处理数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/60.html" title="4.4. 无监督降维" data-book-page-rel-url="docs/60.html" data-book-page-id="11534">4.4. 无监督降维</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/61.html" title="4.5. 随机投影" data-book-page-rel-url="docs/61.html" data-book-page-id="11535">4.5. 随机投影</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/62.html" title="4.6. 内核近似" data-book-page-rel-url="docs/62.html" data-book-page-id="11536">4.6. 内核近似</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/63.html" title="4.7. 成对的矩阵, 类别和核函数" data-book-page-rel-url="docs/63.html" data-book-page-id="11537">4.7. 成对的矩阵, 类别和核函数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/64.html" title="4.8. 预测目标 (`y`.html) 的转换" data-book-page-rel-url="docs/64.html" data-book-page-id="11538">4.8. 预测目标 (`y`.html) 的转换</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/65.html" title="5. 数据集加载工具" data-book-page-rel-url="docs/65.html" data-book-page-id="11539">5. 数据集加载工具</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/66.html" title="6. 大规模计算的策略: 更大量的数据" data-book-page-rel-url="docs/66.html" data-book-page-id="11540">6. 大规模计算的策略: 更大量的数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/67.html" title="7. 计算性能" data-book-page-rel-url="docs/67.html" data-book-page-id="11541">7. 计算性能</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/68.html" title="使用 scikit-learn 介绍机器学习" data-book-page-rel-url="docs/68.html" data-book-page-id="11542">使用 scikit-learn 介绍机器学习</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/69.html" title="关于科学数据处理的统计学习教程" data-book-page-rel-url="docs/69.html" data-book-page-id="11543">关于科学数据处理的统计学习教程</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/70.html" title="机器学习: scikit-learn 中的设置以及预估对象" data-book-page-rel-url="docs/70.html" data-book-page-id="11544">机器学习: scikit-learn 中的设置以及预估对象</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/71.html" title="监督学习：从高维观察预测输出变量" data-book-page-rel-url="docs/71.html" data-book-page-id="11545">监督学习：从高维观察预测输出变量</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/72.html" title="模型选择：选择估计量及其参数" data-book-page-rel-url="docs/72.html" data-book-page-id="11546">模型选择：选择估计量及其参数</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/73.html" title="无监督学习: 寻求数据表示" data-book-page-rel-url="docs/73.html" data-book-page-id="11547">无监督学习: 寻求数据表示</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/74.html" title="把它们放在一起" data-book-page-rel-url="docs/74.html" data-book-page-id="11548">把它们放在一起</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/75.html" title="寻求帮助" data-book-page-rel-url="docs/75.html" data-book-page-id="11549">寻求帮助</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/76.html" title="处理文本数据" data-book-page-rel-url="docs/76.html" data-book-page-id="11550">处理文本数据</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/77.html" title="选择正确的评估器(estimator.html)" data-book-page-rel-url="docs/77.html" data-book-page-id="11551">选择正确的评估器(estimator.html)</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/78.html" title="外部资源，视频和谈话" data-book-page-rel-url="docs/78.html" data-book-page-id="11552">外部资源，视频和谈话</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/80.html" title="常见问题" data-book-page-rel-url="docs/80.html" data-book-page-id="11553">常见问题</a>
</li>
<li>
<a class="pjax" href="../../../book/170/docs/81.html" title="时光轴" data-book-page-rel-url="docs/81.html" data-book-page-id="11554">时光轴</a>
</li>
</ul>
</div>
</div>
<script src="https://cdn.staticfile.net/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="../../../static/components/uikit-2.27.5/js/uikit.reader.js"></script>
<script type="text/javascript" src="../../../static/components/social-share/social-share.min.js"></script>
<script>(function(){var bp =document.createElement('script');var curProtocol =window.location.protocol.split(':')[0];if (curProtocol ==='https') {bp.src ='https://zz.bdstatic.com/linksubmit/push.js';}
else {bp.src ='http://push.zhanzhang.baidu.com/push.js';}
var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp,s);})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
<script src="https://cdn.staticfile.net/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.net/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script src="https://cdn.staticfile.net/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="https://cdn.staticfile.net/uikit/2.27.5/js/components/lightbox.min.js"></script>
<link rel="dns-prefetch" href="../../..//cdn.mathjax.org" />
<script type="text/x-mathjax-config">
 function initMathJax() {
    var mathId = $("book-content-section")[0];
    MathJax.Hub.Config({
        tex2jax: {skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a']},
        showProcessingMessages: false,
        messageStyle: "none"
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub,mathId]);
 };
initMathJax();
</script>
<script src='https://cdn.staticfile.net/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML' async></script>
<style>
	.MathJax_Display{display:inline!important;}
</style>
<script type="text/javascript" src="../../../static/components/js/reader.js"></script>
<script type="text/javascript">var bookId =170;var bookPageId =11545;var bookPageRelUrl ='docs/71.html';</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
</body>
</html>