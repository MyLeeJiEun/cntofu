
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>循环神经网络实践-Google 深度学习笔记(Google Deep Learning Notes)</title>
<meta content='循环神经网络实践,Google 深度学习笔记,Google Deep Learning Notes' name='keywords'>
<meta content='循环神经网络实践,Google 深度学习笔记,Google Deep Learning Notes' name='description'>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=1, user-scalable=no"../../../../>
<meta name="applicable-device" content="pc,mobile">
<link rel="shortcut icon" href="../../../../favicon.ico" type="image/x-icon" />
<meta name="renderer" content="webkit">
<link rel="stylesheet" href="../../../../static/components/uikit-2.27.5/css/uikit.custom.css">
<link rel="stylesheet" href="../../../../static/components/social-share/social-share.min.css">
<link rel="stylesheet" href="../../../../static/components/highlight/styles/custom.css">
<link rel="stylesheet" href="../../../../static/components/css/base.css">
<link rel="stylesheet" href="../../../../static/components/css/reader.css">
<link rel="stylesheet" href="../../../../static/components/css/markdown.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5313208362165053" crossorigin="anonymous"></script>
</head>
<body>
<div class=" book-main-wrap uk-container uk-container-center uk-margin-top ">
<div class="uk-grid">
<div class="uk-width-1-1 reader-wrap ">
<div class=" bottom-nav uk-clearfix ">
<div class="uk-align-left ">
<a href="../../../../book/62/note/lesson-4/README.html">
<i class="nav-icon-left uk-icon-small  uk-icon-caret-left"></i>
<span class="">Deep Models..</span>
</a>
</div>
<div class="uk-align-right ">
<a href="../../../../book/62/note/numpy/README.html">
<span class="">NumPy笔记</span>
<i class="nav-icon-right uk-icon-small  uk-icon-caret-right"></i>
</a>
</div>
</div>
<div class="uk-text-center">
<h2 class="book-page-title uk-container-center">
<a href="../../../../book/62/index.html">Google 深度学习笔记 (Google Deep Learning Notes)</a>
<a target="_blank" rel="nofollow" href="https://github.com/ahangchen/GDLnotes" class="uk-icon-button uk-icon-github" title="github项目地址"></a>
</h2>
</div>
<script type="text/javascript" src="../../../../static/components/js/app_intro.js"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5313208362165053" data-ad-slot="1328047120"></ins>
<script>(adsbygoogle =window.adsbygoogle ||[]).push({});</script>
<hr class="uk-article-divider">
<div class="book-content-section  md-content-section  uk-margin-bottom">
<h1 id="循环神经网络实践">循环神经网络实践</h1>
<h2 id="加载数据">加载数据</h2>
<ul>
<li>使用<a href="http://mattmahoney.net/dc/textdata">text8</a>作为训练的文本数据集</li>
</ul>
<p>text8中只包含27种字符：小写的从a到z，以及空格符。如果把它打出来，读起来就像是去掉了所有标点的wikipedia。</p>
<ul>
<li>直接调用lesson1中maybe_download下载text8.zip</li>
<li>用zipfile读取zip内容为字符串，并拆分成单词list</li>
<li>用connections模块统计单词数量并找出最常见的单词</li>
</ul>
<p>达成随机取数据的目标</p>
<h2 id="构造计算单元">构造计算单元</h2>
<pre><code class="language-python">embeddings = tf.Variable(
        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
</code></pre>
<ul>
<li>构造一个vocabulary_size x embedding_size的矩阵，作为embeddings容器，</li>
<li>有vocabulary_size个容量为embedding_size的向量，每个向量代表一个vocabulary，</li>
<li>每个向量的中的分量的值都在-1到1之间随机分布</li>
</ul>
<pre><code class="language-python">embed = tf.nn.embedding_lookup(embeddings, train_dataset)
</code></pre>
<ul>
<li>调用tf.nn.embedding_lookup，索引与train_dataset对应的向量，相当于用train_dataset作为一个id，去检索矩阵中与这个id对应的embedding</li>
</ul>
<pre><code class="language-python">loss = tf.reduce_mean(
        tf.nn.sampled_softmax_loss(softmax_weights, softmax_biases, embed,
                                   train_labels, num_sampled, vocabulary_size))
</code></pre>
<ul>
<li>采样计算训练损失</li>
</ul>
<pre><code class="language-python">optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)
</code></pre>
<ul>
<li> <p>自适应梯度调节器，调节embedding列表的数据，使得偏差最小</p> </li>
<li> <p>预测，并用cos值计算预测向量与实际数据的夹角作为预测准确度（相似度）指标</p> </li>
</ul>
<h2 id="传入数据进行训练">传入数据进行训练</h2>
<ul>
<li>切割数据用于训练，其中：</li>
</ul>
<pre><code class="language-python">data_index = (data_index + 1) % len(data)
</code></pre>
<ul>
<li>依旧是每次取一部分随机数据传入
<ul>
<li>等距离截取一小段文本</li>
<li>构造训练集：每个截取窗口的中间位置作为一个train_data</li>
<li>构造标签：每个截取窗口中，除了train_data之外的部分，随机取几个成为一个list，作为label（这里只随机取了一个）</li>
<li>这样就形成了根据目标词汇预测上下文的机制，即Skip-gram</li>
</ul> </li>
<li>训练100001次，每2000次输出这两千次的平均损失</li>
<li>每10000次计算相似度，并输出与验证集中的词最接近的词汇列表</li>
<li>用tSNE降维呈现词汇接近程度</li>
<li>用matplotlib绘制结果</li>
</ul>
<p><a href="https://img.cntofu.com/book/GDLnotes/res/word2vec_res.png" data-uk-lightbox><img src="https://img.cntofu.com/book/GDLnotes/res/word2vec_res.png" alt=""></a></p>
<p>代码见：<a href="../../src/rnn/word2vec.py">word2vec.py</a></p>
<p>这里我们指定了gpu作为运算设备，会出现这个<a href="https://github.com/tensorflow/tensorflow/issues/2285">issue</a>说明的bug，需要进行如下配置解决：</p>
<pre><code class="language-python">config = tf.ConfigProto(allow_soft_placement=True)
session = tf.Session(graph=graph, config=config)
</code></pre>
<h2 id="cbow">CBOW</h2>
<p>上面训练的是Skip-gram模型，是根据目标词汇预测上下文，而word2vec还有一种方式，CBOW，根据上下文预测目标词汇。</p>
<p>实际上就是将Skip-gram中的输入输出反过来。</p>
<ul>
<li> <p>修改截取数据的方式</p>
<ul>
<li>构造标签：每个截取窗口的中间位置作为一个train_label</li>
<li>构造训练集：每个截取窗口中，除了train_label之外的部分，作为train_data（这里只随机取了一个）</li>
<li>这样就形成了根据上下文预测目标词汇的机制，即CBOW</li>
</ul> </li>
<li> <p>分别从embeding里找到train_data里每个word对应的vector，用tf.reduce_sum将其相加，将相加结果与train_label比较</p> </li>
</ul>
<pre><code class="language-python"># Look up embeddings for inputs.
embed = tf.nn.embedding_lookup(embeddings, train_dataset)
# sum up vectors on first dimensions, as context vectors
embed_sum = tf.reduce_sum(embed, 0)
</code></pre>
<ul>
<li>训练中依旧是调节embeding的参数来优化loss</li>
<li>训练结果如下图，可以看到不同单词的接近程度</li>
</ul>
<p><a href="https://img.cntofu.com/book/GDLnotes/res/cbow_res.png" data-uk-lightbox><img src="https://img.cntofu.com/book/GDLnotes/res/cbow_res.png" alt=""></a></p>
<p>代码见：<a href="../../src/rnn/cbow.py">cbow.py</a></p>
<h2 id="rnn-造句">RNN 造句</h2>
<p>整体思路是，以一个文本中的一个词作为train data，后续的所有词作为train label，从而能够根据一个给定词，预测后续的片段。</p>
<h3 id="训练数据">训练数据</h3>
<ul>
<li>BatchGenerator</li>
<li>text: 全部的文本数据</li>
<li>text_size：全部文本的字符串长度</li>
<li>batch_size：每段训练数据的大小</li>
<li>num_unrollings：要生成的训练数据段的数目</li>
<li>segment：整个训练数据集可以分成几个训练数据片段</li>
<li>cursor：重要，
<ul>
<li>一开始记录每个训练数据片段的起始位置坐标，即这个片段位于text的哪个index</li>
<li>执行next_batch生成一个训练数据的时候，游标会从初始位置自增，直到取够batch_size个数据</li>
</ul> </li>
<li>last_batch：上一个训练数据片段</li>
<li>每调用一次next，生成一个num_unrollings长的array，以last_batch开头，跟着num_unrollings个batch</li>
<li>每个batch的作为train_input，每个batch后面的一个batch作为train_label，每个step训练num_unrolling个batch</li>
</ul>
<h3 id="lstm-cell">lstm-cell</h3>
<ul>
<li> <p>为了解决消失的梯度问题，引入lstm-cell，增强model的记忆能力</p> </li>
<li> <p>根据这篇论文设计lstm-cell: http://arxiv.org/pdf/1402.1128v1.pdf</p> </li>
<li> <p>分别有三个门：输入门，遗忘门，输出门，构成一个cell</p>
<ul>
<li>输入数据是num_nodes个词，可能有vocabulary_size种词</li>
<li>输入门：</li>
</ul> <pre><code class="language-python">input_gate = sigmoid(i * ix + o * im + ib)
</code></pre>
<ul>
<li> <p>给输入乘一个vocabulary_size * num_nodes大小的矩阵，给输出乘一个num_nodes * num_nodes大小的矩阵;</p> </li>
<li> <p>用这两个矩阵调节对输入数据的取舍程度</p> </li>
<li> <p>用sigmoid这个非线性函数进行激活</p> </li>
<li> <p>遗忘门：</p> </li>
</ul> <pre><code class="language-python">forget_gate = sigmoid(i * fx + o * fm + fb)
</code></pre> <p>思路同输入门，用以对历史数据做取舍</p>
<ul>
<li>输出门：</li>
</ul> <pre><code class="language-python">output_gate = sigmoid(i * ox + o * om + ob)
</code></pre> <p>思路同输入门，用以对输出状态做取舍</p>
<ul>
<li>组合：</li>
</ul> <pre><code class="language-python">update = i * cx + o * cm + cb
state = forget_gate * state + input_gate * tanh(update)
lstm_cell = output_gate * tanh(state)
</code></pre>
<ul>
<li>用同样的方式构造新状态update</li>
<li>用遗忘门处理历史状态state</li>
<li>用tanh激活新状态update</li>
<li>用输入门处理新状态update</li>
<li>整合新旧状态，再用tanh激活状态state</li>
<li>用输出门处理state</li>
</ul> </li>
</ul>
<h3 id="lstm优化">lstm优化</h3>
<p>上面的cell中，update，output_gate，forget_gate，input_gate计算方法都是一样的， 可以把四组参数分别合并，一次计算，再分别取出：</p>
<pre><code class="language-python">values = tf.split(tf.matmul(i, input_weights) + tf.matmul(o, output_weights) + bias, gate_count, 1)
input_gate = tf.sigmoid(values[0])
forget_gate = tf.sigmoid(values[1])
update = values[2]
</code></pre>
<p>再将lstm-cell的输出扔到一个WX+b中调整作为输出</p>
<p>代码见：<a href="../../src/rnn/singlew_lstm.py">singlew_lstm.py</a></p>
<h3 id="optimizer">Optimizer</h3>
<ul>
<li>采用one-hot encoding作为label预测</li>
<li>采用交叉熵计算损失</li>
<li>引入learning rate decay</li>
</ul>
<h3 id="flow">Flow</h3>
<ul>
<li>填入训练数据到placeholder中</li>
<li>验证集的准确性用logprob来计算，即对可能性取对数</li>
<li>每10次训练随机挑取5个字母作为起始词，进行造句测试</li>
<li>你可能注意到输出的sentence是由sample得到的词组成的，而非选择概率最高的词，这是因为，如果一直取概率最高的词，最后会一直重复这个概率最高的词</li>
</ul>
<h2 id="beam-search">Beam Search</h2>
<p>上面的流程里，每次都是以一个字符作为单位，可以使用多一点的字符做预测，取最高概率的那个，防止特殊情况导致的误判</p>
<p>在这里我们增加字符为2个，形成bigram，代码见：<a href="../../src/rnn/bigram_lstm.py">bigram_lstm.py</a></p>
<p>主要通过BigramBatchGenerator类实现</p>
<h2 id="embedding-look-up">Embedding look up</h2>
<p>由于bigram情况下，vocabulary_size变为 27*27个，使用one-hot encoding 做predict的话会产生非常稀疏的矩阵，浪费算力，计算速度慢</p>
<p>因此引入embedding_lookup,代码见<a href="../../src/rnn/embed_bigram_lstm.py">embed_bigram_lstm.py</a></p>
<ul>
<li>数据输入：BatchGenerator不再生成one-hot-encoding的向量作为输入，而是直接生成bigram对应的index列表</li>
<li>embedding look up调整embedding，使bigram与vector对应起来</li>
<li>将embedding look up的结果喂给lstm cell即可</li>
<li>输出时，需要将label和output都转为One-hot-encoding，才能用交叉熵和softmax计算损失</li>
<li>在tensor里做data到one-hot-encoding转换时，主要依赖tf.gather函数</li>
<li>在对valid数据做转换时，主要依赖one_hot_voc函数</li>
</ul>
<h2 id="drop-out">Drop out</h2>
<ul>
<li>在lstm cell中对input和output做drop out</li>
<li>Refer to this <a href="http://arxiv.org/abs/1409.2329">article</a></li>
</ul>
<h2 id="seq2seq">Seq2Seq</h2>
<ul>
<li>最后一个问题是，将一个句子中每个词转为它的逆序字符串，也就是一个seq到seq的转换</li>
<li>正经的实现思路是，word 2 vector 2 lstm 2 vector 2 word</li>
<li>不过tensorflow已经有了这样一个模型来做这件事情：Seq2SeqModel，关于这个模型可以看<a href="http://www.cnblogs.com/edwardbi/p/5559338.html">这个分析</a> 以及tensorflow的<a href="https://github.com/tensorflow/tensorflow/blob/63409bd23facad471973b110df998782c0e19c06/tensorflow/models/rnn/translate/translate.py#L132">example</a></li>
<li>只需要从batch中，根据字符串逆序的规律生成target sequence，放到seq2seqmodel里即可，主要依赖rev_id函数</li>
<li>实现见seq2seq.py</li>
<li>注意，用Seq2SeqModel的时候，size和num_layer会在学习到正确的规律前就收敛，我把它调大了一点</li>
</ul>
<pre><code class="language-python">def create_model(sess, forward_only):
    model = seq2seq_model.Seq2SeqModel(source_vocab_size=vocabulary_size,
                                       target_vocab_size=vocabulary_size,
                                       buckets=[(20, 21)],
                                       size=256,
                                       num_layers=4,
                                       max_gradient_norm=5.0,
                                       batch_size=batch_size,
                                       learning_rate=1.0,
                                       learning_rate_decay_factor=0.9,
                                       use_lstm=True,
                                       forward_only=forward_only)
    return model
</code></pre>
<ul>
<li>参数含义
<ul>
<li>source_vocab_size: size of the source vocabulary.</li>
<li>target_vocab_size: size of the target vocabulary.</li>
<li>buckets: a list of pairs (I, O), where I specifies maximum input length that will be processed in that bucket, and O specifies maximum output length. Training instances that have inputs longer than I or outputs longer than O will be pushed to the next bucket and padded accordingly. We assume that the list is sorted, e.g., [(2, 4), (8, 16)].</li>
<li>size: number of units in each layer of the model.</li>
<li>num_layers: number of layers in the model.</li>
<li>max_gradient_norm: gradients will be clipped to maximally this norm.</li>
<li>batch_size: the size of the batches used during training; the model construction is independent of batch_size, so it can be changed after initialization if this is convenient, e.g., for decoding.</li>
<li>learning_rate: learning rate to start with.</li>
<li>learning_rate_decay_factor: decay learning rate by this much when needed.</li>
<li>use_lstm: if true, we use LSTM cells instead of GRU cells.</li>
<li>num_samples: number of samples for sampled softmax.</li>
<li>forward_only: if set, we do not construct the backward pass in the model.</li>
</ul> </li>
</ul>
<h2 id="参考链接">参考链接</h2>
<ul>
<li><a href="https://www.zhihu.com/question/28473843/answer/68797210">林洲汉-知乎</a></li>
<li><a href="http://www.jeyzhang.com/tensorflow-learning-notes-3.html">词向量</a></li>
<li><a href="https://github.com/rudolfix/udacity_deeplearn/">rudolfix - udacity_deeplearn</a></li>
<li><a href="http://www.cnblogs.com/edwardbi/p/5559338.html">Edwardbi - 解析Tensorflow官方English-Franch翻译器demo</a></li>
</ul>
</div>
<hr class="uk-article-divider">
<div class="uk-block uk-block-muted uk-padding-top-remove uk-padding-bottom-remove uk-margin-large-top  book-recommend-wrap">
<div class="uk-margin-top uk-margin-bottom uk-margin-left uk-margin-right">
<div class="uk-margin uk-text-muted "><i class="uk-icon-outdent uk-icon-justify uk-margin-small-right"></i>书籍推荐</div>
<div class="books">
<ul class="uk-book-list">
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/157/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/157/index.html">吴恩达cs229</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/89.html">jiacheng-pan</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">15页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月12日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 0个">0</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/94/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/94/index.html">机器学习实战</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/57.html">RedstoneWill</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">24页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月29日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 7个">7</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/85/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/85/index.html">机器学习原理</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/54.html">shunliz</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">221页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月24日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 2个">2</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/80/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/java_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/80/index.html">Java后端开发相关学习笔记</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/51.html">Kuangcp</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="java">java</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="linux">linux</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">172页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月24日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 23个">23</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/203/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/java_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/203/index.html">Java Web 入门开发教程</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/115.html">skyline75489</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="java">java</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">22页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2021年10月24日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 647个">647</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/72/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/javascript_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/72/index.html">前端开发规范手册</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/45.html">Aaaaaashu</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="javascript">javascript</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="css3">css3</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="html5">html5</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">20页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月8日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 693个">693</span>
</div>
</div>
</div>
</li>
<hr>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<nav class="tm-navbar uk-navbar uk-navbar-attached reader-nav">
<div class="uk-float-left uk-margin-small-top">
<a href="javascript:;" title="目录菜单" class="show-menu  uk-icon-hover  uk-icon-align-justify uk-margin-right"></a>
<div data-uk-dropdown="{mode:'click',pos:'bottom-left'}" class="font-setting-wrap">
<a class="uk-icon-hover uk-icon-font uk-margin-right" aria-label="字体设置" href="javascript:;"></a>
<div class="uk-dropdown dropdown-menu">
<div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-reduce">小字</button>
<button class="uk-button-link button size-2 font-enlarge">大字</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-1 ">宋体</button>
<button class="uk-button-link button size-2 font-2 ">黑体</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-3 color-theme-sun "><i class="uk-icon-sun-o"></i>白天</button>
<button class="uk-button-link button size-3 color-theme-eye "><i class="uk-icon-eye"></i>护眼</button>
<button class="uk-button-link button size-3 color-theme-moon "><i class="uk-icon-moon-o"></i>夜晚</button></div>
</div>
</div>
<a class="logo uk-margin-right" href="../../../../" title="返回首页"><img class="" src="../../../../static/components/images/icon_32.png" /></a>
</div>
<div class="uk-navbar-flip  uk-hidden-small">
<div id="share-box"></div>
</div>
</nav>
<div id="menu-id" class="uk-offcanvas reader-offcanvas">
<div class="uk-offcanvas-bar">
<ul class="book-menu-bar uk-nav uk-nav-offcanvas" data-uk-nav>
<li>
<a href="../../../../book/62/index.html" data-book-page-rel-url="index.html" data-book-page-id="0" title="封面">封面</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/readme.html" data-book-page-rel-url="readme.html" data-book-page-id="0" title="简介">简介</a>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="Lesson 1" disabled data-book-page-rel-url="" data-book-page-id="5346">Lesson 1</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-1/README.html" title="Machine Learning to Deep Learning" data-book-page-rel-url="note/lesson-1/README.html" data-book-page-id="5347">Machine Learning to Deep Learning</a>
<ul>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-1/logistic_classify.html" title="Logistic Classification" data-book-page-rel-url="note/lesson-1/logistic_classify.html" data-book-page-id="5348">Logistic Classification</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-1/practical.html" title="Logistic Classification实践" data-book-page-rel-url="note/lesson-1/practical.html" data-book-page-id="5349">Logistic Classification实践</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-1/Stochastic_Optimization.html" title="Stochastic Optimization" data-book-page-rel-url="note/lesson-1/Stochastic_Optimization.html" data-book-page-id="5350">Stochastic Optimization</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="Lesson 2" disabled data-book-page-rel-url="" data-book-page-id="5351">Lesson 2</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-2/README.html" title="Deep Neural Network" data-book-page-rel-url="note/lesson-2/README.html" data-book-page-id="5352">Deep Neural Network</a>
<ul>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-2/limit_linear.html" title="Limit of Linear Model" data-book-page-rel-url="note/lesson-2/limit_linear.html" data-book-page-id="5353">Limit of Linear Model</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-2/neural_network.html" title="Neural network" data-book-page-rel-url="note/lesson-2/neural_network.html" data-book-page-id="5354">Neural network</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-2/neural_practical.html" title="神经网络实践" data-book-page-rel-url="note/lesson-2/neural_practical.html" data-book-page-id="5355">神经网络实践</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="优化神经网络：" disabled data-book-page-rel-url="" data-book-page-id="5356">优化神经网络：</a>
<ul>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-2/deep_network.html" title="Deep Network" data-book-page-rel-url="note/lesson-2/deep_network.html" data-book-page-id="5357">Deep Network</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-2/deep_network_practice.html" title="深度神经网络实践" data-book-page-rel-url="note/lesson-2/deep_network_practice.html" data-book-page-id="5358">深度神经网络实践</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="Lesson 3" disabled data-book-page-rel-url="" data-book-page-id="5359">Lesson 3</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-3/README.html" title="Convolutional Networks" data-book-page-rel-url="note/lesson-3/README.html" data-book-page-id="5360">Convolutional Networks</a>
<ul>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-3/practice.html" title="卷积神经网络实践" data-book-page-rel-url="note/lesson-3/practice.html" data-book-page-id="5361">卷积神经网络实践</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="Lessson 4" disabled data-book-page-rel-url="" data-book-page-id="5362">Lessson 4</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-4/README.html" title="Deep Models for Text and Sequence" data-book-page-rel-url="note/lesson-4/README.html" data-book-page-id="5363">Deep Models for Text and Sequence</a>
<ul>
<li>
<a class="pjax" href="../../../../book/62/note/lesson-4/rnn_practice.html" title="循环神经网络实践" data-book-page-rel-url="note/lesson-4/rnn_practice.html" data-book-page-id="5364">循环神经网络实践</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/numpy/README.html" title="NumPy笔记" data-book-page-rel-url="note/numpy/README.html" data-book-page-id="5365">NumPy笔记</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/matplotlib/README.html" title="matplotlib笔记" data-book-page-rel-url="note/matplotlib/README.html" data-book-page-id="5366">matplotlib笔记</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/sklearn/README.html" title="sklearn笔记" data-book-page-rel-url="note/sklearn/README.html" data-book-page-id="5367">sklearn笔记</a>
</li>
<li>
<a class="pjax" href="../../../../book/62/note/tensorflow/README.html" title="TensorFlow笔记" data-book-page-rel-url="note/tensorflow/README.html" data-book-page-id="5368">TensorFlow笔记</a>
</li>
</ul>
</div>
</div>
<script src="https://cdn.staticfile.net/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="../../../../static/components/uikit-2.27.5/js/uikit.reader.js"></script>
<script type="text/javascript" src="../../../../static/components/social-share/social-share.min.js"></script>
<script>(function(){var bp =document.createElement('script');var curProtocol =window.location.protocol.split(':')[0];if (curProtocol ==='https') {bp.src ='https://zz.bdstatic.com/linksubmit/push.js';}
else {bp.src ='http://push.zhanzhang.baidu.com/push.js';}
var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp,s);})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
<script src="https://cdn.staticfile.net/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.net/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script src="https://cdn.staticfile.net/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="https://cdn.staticfile.net/uikit/2.27.5/js/components/lightbox.min.js"></script>
<link rel="dns-prefetch" href="../../../..//cdn.mathjax.org" />
<script type="text/x-mathjax-config">
 function initMathJax() {
    var mathId = $("book-content-section")[0];
    MathJax.Hub.Config({
        tex2jax: {skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a']},
        showProcessingMessages: false,
        messageStyle: "none"
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub,mathId]);
 };
initMathJax();
</script>
<script src='https://cdn.staticfile.net/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML' async></script>
<style>
	.MathJax_Display{display:inline!important;}
</style>
<script type="text/javascript" src="../../../../static/components/js/reader.js"></script>
<script type="text/javascript">var bookId =62;var bookPageId =5364;var bookPageRelUrl ='note/lesson-4/rnn_practice.html';</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
</body>
</html>