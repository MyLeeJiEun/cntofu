
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>GAN原理-机器学习原理</title>
<meta content='GAN原理,机器学习原理' name='keywords'>
<meta content='GAN原理,机器学习原理' name='description'>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=1, user-scalable=no"../../../../>
<meta name="applicable-device" content="pc,mobile">
<link rel="shortcut icon" href="../../../../favicon.ico" type="image/x-icon" />
<meta name="renderer" content="webkit">
<link rel="stylesheet" href="../../../../static/components/uikit-2.27.5/css/uikit.custom.css">
<link rel="stylesheet" href="../../../../static/components/social-share/social-share.min.css">
<link rel="stylesheet" href="../../../../static/components/highlight/styles/custom.css">
<link rel="stylesheet" href="../../../../static/components/css/base.css">
<link rel="stylesheet" href="../../../../static/components/css/reader.css">
<link rel="stylesheet" href="../../../../static/components/css/markdown.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5313208362165053" crossorigin="anonymous"></script>
</head>
<body>
<div class=" book-main-wrap uk-container uk-container-center uk-margin-top ">
<div class="uk-grid">
<div class="uk-width-1-1 reader-wrap ">
<div class=" bottom-nav uk-clearfix ">
<div class="uk-align-left ">
<a href="../../../../book/85/dl/gan/gan.html">
<i class="nav-icon-left uk-icon-small  uk-icon-caret-left"></i>
<span class="">对抗生成网络(Gene..</span>
</a>
</div>
<div class="uk-align-right ">
<a href="../../../../book/85/dl/gan/infogan.html">
<span class="">InfoGAN</span>
<i class="nav-icon-right uk-icon-small  uk-icon-caret-right"></i>
</a>
</div>
</div>
<div class="uk-text-center">
<h2 class="book-page-title uk-container-center">
<a href="../../../../book/85/index.html">机器学习原理</a>
<a target="_blank" rel="nofollow" href="https://github.com/shunliz/Machine-Learning" class="uk-icon-button uk-icon-github" title="github项目地址"></a>
</h2>
</div>
<script type="text/javascript" src="../../../../static/components/js/app_intro.js"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5313208362165053" data-ad-slot="1328047120"></ins>
<script>(adsbygoogle =window.adsbygoogle ||[]).push({});</script>
<hr class="uk-article-divider">
<div class="book-content-section  md-content-section  uk-margin-bottom">
<h1 id="gan原理">GAN原理</h1>
<hr>
<p><a href="https://pic4.zhimg.com/v2-95c709a87749e0778248fc8fdd289b83_r.jpg" data-uk-lightbox><img src="https://pic4.zhimg.com/v2-95c709a87749e0778248fc8fdd289b83_r.jpg" alt=""></a></p>
<p>Generative Adversarial Network，就是大家耳熟能详的GAN，由Ian Goodfellow首先提出，在这两年更是深度学习中最热门的东西，仿佛什么东西都能由GAN做出来。我最近刚入门GAN，看了些资料，做一些笔记。</p>
<h2 id="1generation">1.Generation</h2>
<p>什么是生成（generation）？就是模型通过学习一些数据，然后生成类似的数据。让机器看一些动物图片，然后自己来产生动物的图片，这就是生成。</p>
<p>以前就有很多可以用来生成的技术了，比如auto-encoder（自编码器），结构如下图：</p>
<p><a href="https://pic3.zhimg.com/v2-6286121d0904483dfef269f8093eb842_b.png" data-uk-lightbox><img src="https://pic3.zhimg.com/v2-6286121d0904483dfef269f8093eb842_b.png" alt=""></a></p>
<p>你训练一个encoder，把input转换成code，然后训练一个decoder，把code转换成一个image，然后计算得到的image和input之间的MSE（mean square error），训练完这个model之后，取出后半部分NN Decoder，输入一个随机的code，就能generate一个image。</p>
<p>但是auto-encoder生成image的效果，当然看着很别扭啦，一眼就能看出真假。所以后来还提出了比如VAE这样的生成模型，我对此也不是很了解，在这就不细说。</p>
<p>上述的这些生成模型，其实有一个非常严重的弊端。比如VAE，它生成的image是希望和input越相似越好，但是model是如何来衡量这个相似呢？model会计算一个loss，采用的大多是MSE，即每一个像素上的均方差。loss小真的表示相似嘛？<a href="https://pic2.zhimg.com/v2-ff75e66a8b9042bcde8fbd69f570e045_b.png" data-uk-lightbox><img src="https://pic2.zhimg.com/v2-ff75e66a8b9042bcde8fbd69f570e045_b.png" alt=""></a></p>
<p>比如这两张图，第一张，我们认为是好的生成图片，第二张是差的生成图片，但是对于上述的model来说，这两张图片计算出来的loss是一样大的，所以会认为是一样好的图片。</p>
<p>这就是上述生成模型的弊端，用来衡量生成图片好坏的标准并不能很好的完成想要实现的目的。于是就有了下面要讲的GAN。</p>
<h2 id="2gan">2.GAN</h2>
<p>大名鼎鼎的GAN是如何生成图片的呢？首先大家都知道GAN有两个网络，一个是generator，一个是discriminator，从二人零和博弈中受启发，通过两个网络互相对抗来达到最好的生成效果。流程如下：</p>
<p><a href="https://pic2.zhimg.com/v2-6277da1cacd7a7fb7c0d326eb47c2135_b.png" data-uk-lightbox><img src="https://pic2.zhimg.com/v2-6277da1cacd7a7fb7c0d326eb47c2135_b.png" alt=""></a></p>
<p>主要流程类似上面这个图。首先，有一个一代的generator，它能生成一些很差的图片，然后有一个一代的discriminator，它能准确的把生成的图片，和真实的图片分类，简而言之，这个discriminator就是一个二分类器，对生成的图片输出0，对真实的图片输出1。</p>
<p>接着，开始训练出二代的generator，它能生成稍好一点的图片，能够让一代的discriminator认为这些生成的图片是真实的图片。然后会训练出一个二代的discriminator，它能准确的识别出真实的图片，和二代generator生成的图片。以此类推，会有三代，四代。。。n代的generator和discriminator，最后discriminator无法分辨生成的图片和真实图片，这个网络就拟合了。</p>
<p>这就是GAN，运行过程就是这么的简单。这就结束了嘛？显然没有，下面还要介绍一下GAN的原理。</p>
<h2 id="3原理">3.原理</h2>
<p>首先我们知道真实图片集的分布<a href="http://www.zhihu.com/equation?tex=P_%7Bdata%7D%28x%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7Bdata%7D%28x%29" alt="" title="P_{data}(x)"></a>，x是一个真实图片，可以想象成一个向量，这个向量集合的分布就是<a href="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" alt="" title="P_{data}"></a>。我们需要生成一些也在这个分布内的图片，如果直接就是这个分布的话，怕是做不到的。</p>
<p>我们现在有的generator生成的分布可以假设为<a href="http://www.zhihu.com/equation?tex=P_G%28x%3B%5Ctheta%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G%28x%3B%5Ctheta%29" alt="" title="P_G(x;\theta)"></a>，这是一个由<a href="http://www.zhihu.com/equation?tex=%5Ctheta" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta" alt="" title="\theta"></a>控制的分布，<a href="http://www.zhihu.com/equation?tex=%5Ctheta" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta" alt="" title="\theta"></a>是这个分布的参数（如果是高斯混合模型，那么<a href="http://www.zhihu.com/equation?tex=%5Ctheta" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta" alt="" title="\theta"></a>就是每个高斯分布的平均值和方差）</p>
<p>假设我们在真实分布中取出一些数据，<a href="http://www.zhihu.com/equation?tex=%5C%7Bx%5E1%2C+x%5E2%2C+%5Cdots%2Cx%5Em+%5C%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5C%7Bx%5E1%2C+x%5E2%2C+%5Cdots%2Cx%5Em+%5C%7D" alt="" title="{x^1, x^2, \dots,x^m }"></a>，我们想要计算一个似然<a href="http://www.zhihu.com/equation?tex=P_G%28x%5Ei%3B%5Ctheta%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G%28x%5Ei%3B%5Ctheta%29" alt="" title="P_G(x^i;\theta)"></a></p>
<p>对于这些数据，在生成模型中的似然就是<a href="http://www.zhihu.com/equation?tex=L+%3D+%5Cprod_%7Bi%3D1%7D%5E%7Bm%7DP_G%28x%5Ei%3B%5Ctheta%29+" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=L+%3D+%5Cprod_%7Bi%3D1%7D%5E%7Bm%7DP_G%28x%5Ei%3B%5Ctheta%29+" alt="" title="L = \prod_{i=1}^{m}P_G(x^i;\theta) "></a></p>
<p>我们想要最大化这个似然，等价于让generator生成那些真实图片的概率最大。这就变成了一个最大似然估计的问题了，我们需要找到一个<a href="http://www.zhihu.com/equation?tex=%5Ctheta+%5E%2A" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta+%5E%2A" alt="" title="\theta ^*"></a>来最大化这个似然。</p>
<p><a href="http://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D%0A%5Ctheta+%5E%2A+%26%3D+arg%5C+%5Cmax_%7B%5Ctheta%7D%5Cprod_%7Bi%3D1%7D%5E%7Bm%7DP_G%28x%5Ei%3B%5Ctheta%29+%5C%5C%0A%26%3Darg%5C+%5Cmax_%7B%5Ctheta%7D%5C+log%5Cprod_%7Bi%3D1%7D%5E%7Bm%7DP_G%28x%5Ei%3B%5Ctheta%29+%5C%5C%0A%26%3Darg%5C+%5Cmax_%7B%5Ctheta%7D+%5Csum_%7Bi%3D1%7D%5E%7Bm%7DlogP_G%28x%5Ei%3B%5Ctheta%29+%5C%5C%0A%26+%5Capprox+arg%5C+%5Cmax_%7B%5Ctheta%7D%5C+E_%7Bx%5Csim+P_%7Bdata%7D%7D%5BlogP_G%28x%3B%5Ctheta%29%5D+%5C%5C%0A%26+%3D+arg%5C+%5Cmax_%7B%5Ctheta%7D%5Cint_%7Bx%7D+P_%7Bdata%7D%28x%29logP_G%28x%3B%5Ctheta%29dx+-+%5Cint_%7Bx%7DP_%7Bdata%7D%28x%29logP_%7Bdata%7D%28x%29dx+%5C%5C%0A%26%3Darg%5C+%5Cmax_%7B%5Ctheta%7D%5Cint_%7Bx%7DP_%7Bdata%7D%28x%29%28logP_G%28x%3B%5Ctheta%29-logP_%7Bdata%7D%28x%29%29dx+%5C%5C%0A%26%3Darg%5C+%5Cmin_%7B%5Ctheta%7D%5Cint_%7Bx%7DP_%7Bdata%7D%28x%29log+%5Cfrac%7BP_%7Bdata%7D%28x%29%7D%7BP_G%28x%3B%5Ctheta%29%7Ddx+%5C%5C%0A%26%3Darg%5C+%5Cmin_%7B%5Ctheta%7D%5C+KL%28P_%7Bdata%7D%28x%29%7C%7CP_G%28x%3B%5Ctheta%29%29%0A%5Cend%7Balign%7D%0A+" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D%0A%5Ctheta+%5E%2A+%26%3D+arg%5C+%5Cmax_%7B%5Ctheta%7D%5Cprod_%7Bi%3D1%7D%5E%7Bm%7DP_G%28x%5Ei%3B%5Ctheta%29+%5C%5C%0A%26%3Darg%5C+%5Cmax_%7B%5Ctheta%7D%5C+log%5Cprod_%7Bi%3D1%7D%5E%7Bm%7DP_G%28x%5Ei%3B%5Ctheta%29+%5C%5C%0A%26%3Darg%5C+%5Cmax_%7B%5Ctheta%7D+%5Csum_%7Bi%3D1%7D%5E%7Bm%7DlogP_G%28x%5Ei%3B%5Ctheta%29+%5C%5C%0A%26+%5Capprox+arg%5C+%5Cmax_%7B%5Ctheta%7D%5C+E_%7Bx%5Csim+P_%7Bdata%7D%7D%5BlogP_G%28x%3B%5Ctheta%29%5D+%5C%5C%0A%26+%3D+arg%5C+%5Cmax_%7B%5Ctheta%7D%5Cint_%7Bx%7D+P_%7Bdata%7D%28x%29logP_G%28x%3B%5Ctheta%29dx+-+%5Cint_%7Bx%7DP_%7Bdata%7D%28x%29logP_%7Bdata%7D%28x%29dx+%5C%5C%0A%26%3Darg%5C+%5Cmax_%7B%5Ctheta%7D%5Cint_%7Bx%7DP_%7Bdata%7D%28x%29%28logP_G%28x%3B%5Ctheta%29-logP_%7Bdata%7D%28x%29%29dx+%5C%5C%0A%26%3Darg%5C+%5Cmin_%7B%5Ctheta%7D%5Cint_%7Bx%7DP_%7Bdata%7D%28x%29log+%5Cfrac%7BP_%7Bdata%7D%28x%29%7D%7BP_G%28x%3B%5Ctheta%29%7Ddx+%5C%5C%0A%26%3Darg%5C+%5Cmin_%7B%5Ctheta%7D%5C+KL%28P_%7Bdata%7D%28x%29%7C%7CP_G%28x%3B%5Ctheta%29%29%0A%5Cend%7Balign%7D%0A+" alt="" title="\begin{align}
\theta ^* &amp;= arg\ \max_{\theta}\prod_{i=1}^{m}P_G(x^i;\theta) \
&amp;=arg\ \max_{\theta}\ log\prod_{i=1}^{m}P_G(x^i;\theta) \
&amp;=arg\ \max_{\theta} \sum_{i=1}^{m}logP_G(x^i;\theta) \
&amp; \approx arg\ \max_{\theta}\ E_{x\sim P_{data}}[logP_G(x;\theta)] \
&amp; = arg\ \max_{\theta}\int_{x} P_{data}(x)logP_G(x;\theta)dx - \int_{x}P_{data}(x)logP_{data}(x)dx \
&amp;=arg\ \max_{\theta}\int_{x}P_{data}(x)(logP_G(x;\theta)-logP_{data}(x))dx \
&amp;=arg\ \min_{\theta}\int_{x}P_{data}(x)log \frac{P_{data}(x)}{P_G(x;\theta)}dx \
&amp;=arg\ \min_{\theta}\ KL(P_{data}(x)||P_G(x;\theta))
\end{align}
"></a></p>
<p>寻找一个<a href="http://www.zhihu.com/equation?tex=%5Ctheta+%5E%2A" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta+%5E%2A" alt="" title="\theta ^*"></a>来最大化这个似然，等价于最大化log似然。因为此时这m个数据，是从真实分布中取的，所以也就约等于，真实分布中的所有x在<a href="http://www.zhihu.com/equation?tex=P_%7BG%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7BG%7D" alt="" title="P_{G}"></a>分布中的log似然的期望。</p>
<p>真实分布中的所有x的期望，等价于求概率积分，所以可以转化成积分运算，因为减号后面的项和<a href="http://www.zhihu.com/equation?tex=%5Ctheta" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta" alt="" title="\theta"></a>无关，所以添上之后还是等价的。然后提出共有的项，括号内的反转，max变min，就可以转化为KL divergence的形式了，KL divergence描述的是两个概率分布之间的差异。</p>
<p>所以最大化似然，让generator最大概率的生成真实图片，也就是要找一个<a href="http://www.zhihu.com/equation?tex=%5Ctheta" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta" alt="" title="\theta"></a>让<a href="http://www.zhihu.com/equation?tex=P_G" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G" alt="" title="P_G"></a>更接近于<a href="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" alt="" title="P_{data}"></a></p>
<p>那如何来找这个最合理的<a href="http://www.zhihu.com/equation?tex=%5Ctheta" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Ctheta" alt="" title="\theta"></a>呢？我们可以假设<a href="http://www.zhihu.com/equation?tex=P_G%28x%3B%5Ctheta%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G%28x%3B%5Ctheta%29" alt="" title="P_G(x;\theta)"></a>是一个神经网络。</p>
<p>首先随机一个向量z，通过G(z)=x这个网络，生成图片x，那么我们如何比较两个分布是否相似呢？只要我们取一组sample z，这组z符合一个分布，那么通过网络就可以生成另一个分布<a href="http://www.zhihu.com/equation?tex=P_G" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G" alt="" title="P_G"></a>，然后来比较与真实分布<a href="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" alt="" title="P_{data}"></a></p>
<p>大家都知道，神经网络只要有非线性激活函数，就可以去拟合任意的函数，那么分布也是一样，所以可以用一直正态分布，或者高斯分布，取样去训练一个神经网络，学习到一个很复杂的分布。</p>
<p><a href="https://pic1.zhimg.com/v2-bc64f778f95312aa0c37d2ddb62358ec_b.png" data-uk-lightbox><img src="https://pic1.zhimg.com/v2-bc64f778f95312aa0c37d2ddb62358ec_b.png" alt=""></a></p>
<p>如何来找到更接近的分布，这就是GAN的贡献了。先给出GAN的公式：</p>
<p><a href="http://www.zhihu.com/equation?tex=V%28G%2CD%29%3DE_%7Bx%5Csim+P_%7Bdata%7D%7D%5BlogD%28x%29%5D+%2B+E_%7Bx%5Csim+P_G%7D%5Blog%281-D%28x%29%29%5D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=V%28G%2CD%29%3DE_%7Bx%5Csim+P_%7Bdata%7D%7D%5BlogD%28x%29%5D+%2B+E_%7Bx%5Csim+P_G%7D%5Blog%281-D%28x%29%29%5D" alt="" title="V(G,D)=E_{x\sim P_{data}}[logD(x)] + E_{x\sim P_G}[log(1-D(x))]"></a></p>
<p>这个式子的好处在于，固定G，<a href="http://www.zhihu.com/equation?tex=%5Cmax%5C++V%28G%2CD%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cmax%5C++V%28G%2CD%29" alt="" title="\max\  V(G,D)"></a>就表示<a href="http://www.zhihu.com/equation?tex=P_G" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G" alt="" title="P_G"></a>和<a href="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" alt="" title="P_{data}"></a>之间的差异，然后要找一个最好的G，让这个最大值最小，也就是两个分布之间的差异最小。</p>
<p><a href="http://www.zhihu.com/equation?tex=G%5E%2A%3Darg%5C+%5Cmin_%7BG%7D%5C+%5Cmax_D%5C+V%28G%2CD%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=G%5E%2A%3Darg%5C+%5Cmin_%7BG%7D%5C+%5Cmax_D%5C+V%28G%2CD%29" alt="" title="G^*=arg\ \min_{G}\ \max_D\ V(G,D)"></a></p>
<p>表面上看这个的意思是，D要让这个式子尽可能的大，也就是对于x是真实分布中，D(x)要接近与1，对于x来自于生成的分布，D(x)要接近于0，然后G要让式子尽可能的小，让来自于生成分布中的x，D(x)尽可能的接近1</p>
<p>现在我们先固定G，来求解最优的D</p>
<p><a href="https://pic1.zhimg.com/v2-bc7aef1f4608f037f0ec08a88d8c71bc_b.png" data-uk-lightbox><img src="https://pic1.zhimg.com/v2-bc7aef1f4608f037f0ec08a88d8c71bc_b.png" alt=""></a><a href="https://pic2.zhimg.com/v2-0e6fdaf7666cfab881c59d2bee203671_b.png" data-uk-lightbox><img src="https://pic2.zhimg.com/v2-0e6fdaf7666cfab881c59d2bee203671_b.png" alt=""></a>对于一个给定的x，得到最优的D如上图，范围在(0,1)内，把最优的D带入<a href="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29" alt="" title="\max_D\ V(G,D)"></a>，可以得到：<a href="https://pic1.zhimg.com/v2-9cb3d142f47715df12378f105c11d1f4_b.png" data-uk-lightbox><img src="https://pic1.zhimg.com/v2-9cb3d142f47715df12378f105c11d1f4_b.png" alt=""></a></p>
<p><a href="https://pic2.zhimg.com/v2-6bbb3dd20f5b01f864fc72481159a95d_b.png" data-uk-lightbox><img src="https://pic2.zhimg.com/v2-6bbb3dd20f5b01f864fc72481159a95d_b.png" alt=""></a>JS divergence是KL divergence的对称平滑版本，表示了两个分布之间的差异，这个推导就表明了上面所说的，固定G，<a href="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29" alt="" title="\max_D\ V(G,D)"></a>表示两个分布之间的差异，最小值是-2log2，最大值为0。</p>
<p>现在我们需要找个G，来最小化<a href="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29" alt="" title="\max_D\ V(G,D)"></a>，观察上式，当<a href="http://www.zhihu.com/equation?tex=P_G%28x%29%3DP_%7Bdata%7D%28x%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G%28x%29%3DP_%7Bdata%7D%28x%29" alt="" title="P_G(x)=P_{data}(x)"></a>时，G是最优的。</p>
<h2 id="4训练">4.训练</h2>
<p>有了上面推导的基础之后，我们就可以开始训练GAN了。结合我们开头说的，两个网络交替训练，我们可以在起初有一个<a href="http://www.zhihu.com/equation?tex=G_0" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=G_0" alt="" title="G_0"></a>和<a href="http://www.zhihu.com/equation?tex=D_0" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=D_0" alt="" title="D_0"></a>，先训练<a href="http://www.zhihu.com/equation?tex=D_0" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=D_0" alt="" title="D_0"></a>找到<a href="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G_0%2CD_0%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G_0%2CD_0%29" alt="" title="\max_D\ V(G_0,D_0)"></a>，然后固定<a href="http://www.zhihu.com/equation?tex=D_0" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=D_0" alt="" title="D_0"></a>开始训练<a href="http://www.zhihu.com/equation?tex=G_0" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=G_0" alt="" title="G_0"></a>,训练的过程都可以使用gradient descent，以此类推，训练<a href="http://www.zhihu.com/equation?tex=D_1%2CG_1%2CD_2%2CG_2%2C%5Cdots" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=D_1%2CG_1%2CD_2%2CG_2%2C%5Cdots" alt="" title="D_1,G_1,D_2,G_2,\dots"></a></p>
<p>但是这里有个问题就是，你可能在<a href="http://www.zhihu.com/equation?tex=D_0%5E%2A" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=D_0%5E%2A" alt="" title="D_0^*"></a>的位置取到了<a href="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G_0%2CD_0%29%3DV%28G_0%2CD_0%5E%2A%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G_0%2CD_0%29%3DV%28G_0%2CD_0%5E%2A%29" alt="" title="\max_D\ V(G_0,D_0)=V(G_0,D_0^*)"></a>，然后更新<a href="http://www.zhihu.com/equation?tex=G_0" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=G_0" alt="" title="G_0"></a>为<a href="http://www.zhihu.com/equation?tex=G_1" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=G_1" alt="" title="G_1"></a>,可能<a href="http://www.zhihu.com/equation?tex=V%28G_1%2CD_0%5E%2A%29%3CV%28G_0%2CD_0%5E%2A%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=V%28G_1%2CD_0%5E%2A%29%3CV%28G_0%2CD_0%5E%2A%29" alt="" title="V(G_1,D_0^*)<V(G_0,D_0^*)"></a>了，但是并不保证会出现一个新的点<a href="http://www.zhihu.com/equation?tex=D_1%5E%2A" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=D_1%5E%2A" alt="" title="D_1^*"></a>使得<a href="http://www.zhihu.com/equation?tex=V%28G_1%2CD_1%5E%2A%29+%3E+V%28G_0%2CD_0%5E%2A%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=V%28G_1%2CD_1%5E%2A%29+%3E+V%28G_0%2CD_0%5E%2A%29" alt="" title="V(G_1,D_1^*)> V(G_0,D_0^*)"></a>，这样更新G就没达到它原来应该要的效果，如下图所示：</p>
<p><a href="https://pic2.zhimg.com/v2-f0cd8b79a1dc8fb08c9a0bd2b7424065_b.png" data-uk-lightbox><img src="https://pic2.zhimg.com/v2-f0cd8b79a1dc8fb08c9a0bd2b7424065_b.png" alt=""></a></p>
<p>避免上述情况的方法就是更新G的时候，不要更新G太多。</p>
<p>知道了网络的训练顺序，我们还需要设定两个loss function，一个是D的loss，一个是G的loss。下面是整个GAN的训练具体步骤：</p>
<p><a href="https://pic3.zhimg.com/v2-9b9cf73c1064a87a26ef3c0f9eac7b76_b.png" data-uk-lightbox><img src="https://pic3.zhimg.com/v2-9b9cf73c1064a87a26ef3c0f9eac7b76_b.png" alt=""></a></p>
<p>上述步骤在机器学习和深度学习中也是非常常见，易于理解。</p>
<h2 id="5存在的问题">5.存在的问题</h2>
<p>但是上面G的loss function还是有一点小问题，下图是两个函数的图像：</p>
<p><a href="https://pic4.zhimg.com/v2-e0ab404f7b693a4127ef887a3ffa2ba3_b.png" data-uk-lightbox><img src="https://pic4.zhimg.com/v2-e0ab404f7b693a4127ef887a3ffa2ba3_b.png" alt=""></a><a href="http://www.zhihu.com/equation?tex=log%281-D%28x%29%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=log%281-D%28x%29%29" alt="" title="log(1-D(x))"></a>是我们计算时G的loss function，但是我们发现，在D(x)接近于0的时候，这个函数十分平滑，梯度非常的小。这就会导致，在训练的初期，G想要骗过D，变化十分的缓慢，而上面的函数，趋势和下面的是一样的，都是递减的。但是它的优势是在D(x)接近0的时候，梯度很大，有利于训练，在D(x)越来越大之后，梯度减小，这也很符合实际，在初期应该训练速度更快，到后期速度减慢。</p>
<p>所以我们把G的loss function修改为<a href="http://www.zhihu.com/equation?tex=minimize%5C+V+%3D+-%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7Dlog%28D%28x%5Ei%29%29" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=minimize%5C+V+%3D+-%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7Dlog%28D%28x%5Ei%29%29" alt="" title="minimize\ V = -\frac{1}{m}\sum_{i=1}^{m}log(D(x^i))"></a>，这样可以提高训练的速度。</p>
<p>还有一个问题，在其他paper中提出，就是经过实验发现，经过许多次训练，loss一直都是平的，也就是<a href="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29%3D0" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=%5Cmax_D%5C+V%28G%2CD%29%3D0" alt="" title="\max_D\ V(G,D)=0"></a>，JS divergence一直都是log2，<a href="http://www.zhihu.com/equation?tex=P_G" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G" alt="" title="P_G"></a>和<a href="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" alt="" title="P_{data}"></a>完全没有交集，但是实际上两个分布是有交集的，造成这个的原因是因为，我们无法真正计算期望和积分，只能使用sample的方法，如果训练的过拟合了，D还是能够完全把两部分的点分开，如下图：</p>
<p><a href="https://pic1.zhimg.com/v2-5e68140c9f3b2fec91649929f90e6138_b.png" data-uk-lightbox><img src="https://pic1.zhimg.com/v2-5e68140c9f3b2fec91649929f90e6138_b.png" alt=""></a></p>
<p>对于这个问题，我们是否应该让D变得弱一点，减弱它的分类能力，但是从理论上讲，为了让它能够有效的区分真假图片，我们又希望它能够powerful，所以这里就产生了矛盾。</p>
<p>还有可能的原因是，虽然两个分布都是高维的，但是两个分布都十分的窄，可能交集相当小，这样也会导致JS divergence算出来=log2，约等于没有交集。</p>
<p>解决的一些方法，有添加噪声，让两个分布变得更宽，可能可以增大它们的交集，这样JS divergence就可以计算，但是随着时间变化，噪声需要逐渐变小。</p>
<p>还有一个问题叫Mode Collapse，如下图：</p>
<p><a href="https://pic4.zhimg.com/v2-ab84e45babe1a71bc19963b0455bfdcf_b.png" data-uk-lightbox><img src="https://pic4.zhimg.com/v2-ab84e45babe1a71bc19963b0455bfdcf_b.png" alt=""></a></p>
<p>这个图的意思是，data的分布是一个双峰的，但是学习到的生成分布却只有单峰，我们可以看到模型学到的数据，但是却不知道它没有学到的分布。</p>
<p>造成这个情况的原因是，KL divergence里的两个分布写反了</p>
<p><a href="https://pic2.zhimg.com/v2-47e26e6096ef6967f064986c23e373e5_b.png" data-uk-lightbox><img src="https://pic2.zhimg.com/v2-47e26e6096ef6967f064986c23e373e5_b.png" alt=""></a></p>
<p>这个图很清楚的显示了，如果是第一个KL divergence的写法，为了防止出现无穷大，所以有<a href="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_%7Bdata%7D" alt="" title="P_{data}"></a>出现的地方都必须要有<a href="http://www.zhihu.com/equation?tex=P_G" data-uk-lightbox><img src="http://www.zhihu.com/equation?tex=P_G" alt="" title="P_G"></a>覆盖，就不会出现Mode Collapse</p>
</div>
<hr class="uk-article-divider">
<div class="uk-block uk-block-muted uk-padding-top-remove uk-padding-bottom-remove uk-margin-large-top  book-recommend-wrap">
<div class="uk-margin-top uk-margin-bottom uk-margin-left uk-margin-right">
<div class="uk-margin uk-text-muted "><i class="uk-icon-outdent uk-icon-justify uk-margin-small-right"></i>书籍推荐</div>
<div class="books">
<ul class="uk-book-list">
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/129/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/129/index.html">机器学习实战</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/69.html">gaolinjie</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">18页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年7月8日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 10个">10</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/56/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/56/index.html">神经网络与深度学习</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/32.html">tigerneil</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">9页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月5日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 239个">239</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/94/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/94/index.html">机器学习实战</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/57.html">RedstoneWill</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">24页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月29日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 7个">7</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/44/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/linux_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/44/index.html">Shell 编程范例</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/23.html">泰晓科技</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="linux">linux</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">15页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年5月30日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 296个">296</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/139/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/docker_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/139/index.html">Docker — 从入门到实践</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/48.html">yeasy</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="docker">docker</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">159页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年9月5日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 9408个">9408</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/158/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/java_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/158/index.html">java语法整理</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/90.html">niliv</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="java">java</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">42页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2019年5月26日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 2个">2</span>
</div>
</div>
</div>
</li>
<hr>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<nav class="tm-navbar uk-navbar uk-navbar-attached reader-nav">
<div class="uk-float-left uk-margin-small-top">
<a href="javascript:;" title="目录菜单" class="show-menu  uk-icon-hover  uk-icon-align-justify uk-margin-right"></a>
<div data-uk-dropdown="{mode:'click',pos:'bottom-left'}" class="font-setting-wrap">
<a class="uk-icon-hover uk-icon-font uk-margin-right" aria-label="字体设置" href="javascript:;"></a>
<div class="uk-dropdown dropdown-menu">
<div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-reduce">小字</button>
<button class="uk-button-link button size-2 font-enlarge">大字</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-1 ">宋体</button>
<button class="uk-button-link button size-2 font-2 ">黑体</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-3 color-theme-sun "><i class="uk-icon-sun-o"></i>白天</button>
<button class="uk-button-link button size-3 color-theme-eye "><i class="uk-icon-eye"></i>护眼</button>
<button class="uk-button-link button size-3 color-theme-moon "><i class="uk-icon-moon-o"></i>夜晚</button></div>
</div>
</div>
<a class="logo uk-margin-right" href="../../../../" title="返回首页"><img class="" src="../../../../static/components/images/icon_32.png" /></a>
</div>
<div class="uk-navbar-flip  uk-hidden-small">
<div id="share-box"></div>
</div>
</nav>
<div id="menu-id" class="uk-offcanvas reader-offcanvas">
<div class="uk-offcanvas-bar">
<ul class="book-menu-bar uk-nav uk-nav-offcanvas" data-uk-nav>
<li>
<a href="../../../../book/85/index.html" data-book-page-rel-url="index.html" data-book-page-id="0" title="封面">封面</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/readme.html" data-book-page-rel-url="readme.html" data-book-page-id="0" title="简介">简介</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/README.html" title="前言" data-book-page-rel-url="README.html" data-book-page-id="6588">前言</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/math.html" title="第一部分 数学基础" data-book-page-rel-url="math/math.html" data-book-page-id="6589">第一部分 数学基础</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/introduction.html" title="第一章 数学分析" data-book-page-rel-url="math/analytic/introduction.html" data-book-page-id="6590">第一章 数学分析</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/gradient_descent.html" title="梯度下降" data-book-page-rel-url="math/analytic/gradient_descent.html" data-book-page-id="6591">梯度下降</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/shu-zhi-ji-suan.html" title="数值计算" data-book-page-rel-url="math/analytic/shu-zhi-ji-suan.html" data-book-page-id="6592">数值计算</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/overfitting.html" title="过拟合数学原理与解决方案" data-book-page-rel-url="math/analytic/overfitting.html" data-book-page-id="6593">过拟合数学原理与解决方案</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/cross-validation.html" title="交叉验证" data-book-page-rel-url="math/analytic/cross-validation.html" data-book-page-id="6594">交叉验证</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/least-square.html" title="最小二乘" data-book-page-rel-url="math/analytic/least-square.html" data-book-page-id="6595">最小二乘</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/lagelangri-kkt.html" title="拉格朗日乘子法（Lagrange Multiplier) 和KKT条件" data-book-page-rel-url="math/analytic/lagelangri-kkt.html" data-book-page-id="6596">拉格朗日乘子法（Lagrange Multiplier) 和KKT条件</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/niudun.html" title="牛顿法" data-book-page-rel-url="math/analytic/niudun.html" data-book-page-id="6597">牛顿法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/tuyouhua.html" title="凸优化" data-book-page-rel-url="math/analytic/tuyouhua.html" data-book-page-id="6598">凸优化</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/common-function.html" title="常用函数" data-book-page-rel-url="math/analytic/common-function.html" data-book-page-id="6599">常用函数</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability.html" title="第二章 概率论" data-book-page-rel-url="math/probability.html" data-book-page-id="6600">第二章 概率论</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/math/probability/prob-methodology.html" title="统计学习方法概论" data-book-page-rel-url="math/probability/prob-methodology.html" data-book-page-id="6601">统计学习方法概论</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/mle.html" title="最大似然估计" data-book-page-rel-url="math/probability/mle.html" data-book-page-id="6602">最大似然估计</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/mcmc1.html" title="蒙特卡罗方法" data-book-page-rel-url="math/probability/mcmc1.html" data-book-page-id="6603">蒙特卡罗方法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/markov-chain.html" title="马尔科夫链" data-book-page-rel-url="math/probability/markov-chain.html" data-book-page-id="6604">马尔科夫链</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/mcmc-mh.html" title="MCMC采样和M-H采样" data-book-page-rel-url="math/probability/mcmc-mh.html" data-book-page-id="6605">MCMC采样和M-H采样</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/gibbs.html" title="Gibbs采样" data-book-page-rel-url="math/probability/gibbs.html" data-book-page-id="6606">Gibbs采样</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/linear-matrix/linear-matrix.html" title="第三章 矩阵和线性代数" data-book-page-rel-url="math/linear-matrix/linear-matrix.html" data-book-page-id="6607">第三章 矩阵和线性代数</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/math/linear-matrix/lapack.html" title="LAPACK" data-book-page-rel-url="math/linear-matrix/lapack.html" data-book-page-id="6608">LAPACK</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/linear-matrix/tezhengzhihetezhengxiangliang.html" title="特征值与特征向量" data-book-page-rel-url="math/linear-matrix/tezhengzhihetezhengxiangliang.html" data-book-page-id="6609">特征值与特征向量</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/ml.html" title="第二部分 机器学习" data-book-page-rel-url="ml/ml.html" data-book-page-id="6610">第二部分 机器学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml.html" title="第四章 机器学习基础" data-book-page-rel-url="ml/pythonml.html" data-book-page-id="6611">第四章 机器学习基础</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/pythonji-qi-shu-xue-ku.html" title="Python及其数学库" data-book-page-rel-url="ml/pythonml/pythonji-qi-shu-xue-ku.html" data-book-page-id="6612">Python及其数学库</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/ji-qi-xue-xi-ku.html" title="机器学习库" data-book-page-rel-url="ml/pythonml/ji-qi-xue-xi-ku.html" data-book-page-id="6613">机器学习库</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/ml-metrics.html" title="模型度量" data-book-page-rel-url="ml/pythonml/ml-metrics.html" data-book-page-id="6614">模型度量</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/gen-descri.html" title="生成模型和判别模型" data-book-page-rel-url="ml/pythonml/gen-descri.html" data-book-page-id="6615">生成模型和判别模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/distance.html" title="机器学习中的距离" data-book-page-rel-url="ml/pythonml/distance.html" data-book-page-id="6616">机器学习中的距离</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/cleanup-feature.html" title="第六课：数据清洗和特征选择" data-book-page-rel-url="ml/clean-feature/cleanup-feature.html" data-book-page-id="6617">第六课：数据清洗和特征选择</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/pca.html" title="PCA" data-book-page-rel-url="ml/clean-feature/pca.html" data-book-page-id="6618">PCA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/ica.html" title="ICA" data-book-page-rel-url="ml/clean-feature/ica.html" data-book-page-id="6619">ICA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/one-hot.html" title="One-hot编码" data-book-page-rel-url="ml/clean-feature/one-hot.html" data-book-page-id="6620">One-hot编码</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/scikit-pca.html" title="scikit-learn PCA" data-book-page-rel-url="ml/clean-feature/scikit-pca.html" data-book-page-id="6621">scikit-learn PCA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/xian-xing-pan-bie-fen-xi-lda.html" title="线性判别分析LDA" data-book-page-rel-url="ml/clean-feature/xian-xing-pan-bie-fen-xi-lda.html" data-book-page-id="6622">线性判别分析LDA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/scikit-lda.html" title="用scikit-learn进行LDA降维" data-book-page-rel-url="ml/clean-feature/scikit-lda.html" data-book-page-id="6623">用scikit-learn进行LDA降维</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/svd.html" title="奇异值分解(SVD)原理与在降维中的应用" data-book-page-rel-url="ml/clean-feature/svd.html" data-book-page-id="6624">奇异值分解(SVD)原理与在降维中的应用</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/lle.html" title="局部线性嵌入(LLE)原理" data-book-page-rel-url="ml/clean-feature/lle.html" data-book-page-id="6625">局部线性嵌入(LLE)原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/scikit-lle.html" title="scikit-learn LLE" data-book-page-rel-url="ml/clean-feature/scikit-lle.html" data-book-page-id="6626">scikit-learn LLE</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/spark-fselect.html" title="spark特征选择" data-book-page-rel-url="ml/clean-feature/spark-fselect.html" data-book-page-id="6627">spark特征选择</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/spark-fextract.html" title="Spark特征提取" data-book-page-rel-url="ml/clean-feature/spark-fextract.html" data-book-page-id="6628">Spark特征提取</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/outlier-detect.html" title="异常数据监测" data-book-page-rel-url="ml/clean-feature/outlier-detect.html" data-book-page-id="6629">异常数据监测</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/datapreprocess.html" title="数据预处理" data-book-page-rel-url="ml/clean-feature/datapreprocess.html" data-book-page-id="6630">数据预处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/te-zheng-gong-cheng.html" title="特征工程" data-book-page-rel-url="ml/clean-feature/te-zheng-gong-cheng.html" data-book-page-id="6631">特征工程</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/regression.html" title="第七课： 回归" data-book-page-rel-url="ml/regression/regression.html" data-book-page-id="6632">第七课： 回归</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/linear-regression.html" title="1.  线性回归" data-book-page-rel-url="ml/regression/linear-regression.html" data-book-page-id="6633">1. 线性回归</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/max-entropy.html" title="10.最大熵模型" data-book-page-rel-url="ml/regression/max-entropy.html" data-book-page-id="6634">10.最大熵模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/kl.html" title="11.K-L散度" data-book-page-rel-url="ml/regression/kl.html" data-book-page-id="6635">11.K-L散度</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/cordinate-angle.html" title="坐标下降和最小角" data-book-page-rel-url="ml/regression/cordinate-angle.html" data-book-page-id="6636">坐标下降和最小角</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/linear-regression-summary.html" title="线性回归小结" data-book-page-rel-url="ml/regression/linear-regression-summary.html" data-book-page-id="6637">线性回归小结</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/logistic.html" title="Logistic回归" data-book-page-rel-url="ml/regression/logistic.html" data-book-page-id="6638">Logistic回归</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/logistichui-gui-xiao-jie.html" title="Logistic回归小结" data-book-page-rel-url="ml/regression/logistichui-gui-xiao-jie.html" data-book-page-id="6639">Logistic回归小结</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/softmax.html" title="SoftMax回归" data-book-page-rel-url="ml/regression/softmax.html" data-book-page-id="6640">SoftMax回归</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree.html" title="第九课：决策树" data-book-page-rel-url="ml/decisiontree.html" data-book-page-id="6641">第九课：决策树</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/id3.html" title="ID3" data-book-page-rel-url="ml/decisiontree/id3.html" data-book-page-id="6642">ID3</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/c45.html" title="C4.5" data-book-page-rel-url="ml/decisiontree/c45.html" data-book-page-id="6643">C4.5</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/cart.html" title="CART" data-book-page-rel-url="ml/decisiontree/cart.html" data-book-page-id="6644">CART</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/summary.html" title="总结" data-book-page-rel-url="ml/decisiontree/summary.html" data-book-page-id="6645">总结</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/code.html" title="实现代码" data-book-page-rel-url="ml/decisiontree/code.html" data-book-page-id="6646">实现代码</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm.html" title="第十三课：SVM" data-book-page-rel-url="ml/svm.html" data-book-page-id="6647">第十三课：SVM</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/gan-zhi-ji-mo-xing.html" title="感知机模型" data-book-page-rel-url="ml/svm/gan-zhi-ji-mo-xing.html" data-book-page-id="6648">感知机模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/linear-svm.html" title="线性SVM" data-book-page-rel-url="ml/svm/linear-svm.html" data-book-page-id="6649">线性SVM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/soft-margin-max.html" title="软间隔最大化模型" data-book-page-rel-url="ml/svm/soft-margin-max.html" data-book-page-id="6650">软间隔最大化模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/kernel-method.html" title="核函数" data-book-page-rel-url="ml/svm/kernel-method.html" data-book-page-id="6651">核函数</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/smo.html" title="SMO算法原理" data-book-page-rel-url="ml/svm/smo.html" data-book-page-id="6652">SMO算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/svm-regression.html" title="SVM回归" data-book-page-rel-url="ml/svm/svm-regression.html" data-book-page-id="6653">SVM回归</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/scikit-learn-svm.html" title="scikit-learn SVM" data-book-page-rel-url="ml/svm/scikit-learn-svm.html" data-book-page-id="6654">scikit-learn SVM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/gaosi-kernel.html" title="支持向量机高斯核调参" data-book-page-rel-url="ml/svm/gaosi-kernel.html" data-book-page-id="6655">支持向量机高斯核调参</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/svm-code.html" title="SVM代码实现" data-book-page-rel-url="ml/svm/svm-code.html" data-book-page-id="6656">SVM代码实现</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate.html" title="集成学习" data-book-page-rel-url="ml/integrate.html" data-book-page-id="6657">集成学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/adaboost.html" title="Adaboost原理" data-book-page-rel-url="ml/integrate/adaboost.html" data-book-page-id="6658">Adaboost原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/scikit-learn-adaboost.html" title="scikit-learn Adaboost" data-book-page-rel-url="ml/integrate/scikit-learn-adaboost.html" data-book-page-id="6659">scikit-learn Adaboost</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/gbdt.html" title="梯度提升树（GBDT）" data-book-page-rel-url="ml/integrate/gbdt.html" data-book-page-id="6660">梯度提升树（GBDT）</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/scikit-gbdt.html" title="scikit GBDT" data-book-page-rel-url="ml/integrate/scikit-gbdt.html" data-book-page-id="6661">scikit GBDT</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/random-forest.html" title="Bagging与随机森林" data-book-page-rel-url="ml/integrate/random-forest.html" data-book-page-id="6662">Bagging与随机森林</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/xgboost.html" title="XGBOOST" data-book-page-rel-url="ml/integrate/xgboost.html" data-book-page-id="6663">XGBOOST</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/scikit-learn-rf.html" title="scikit-learn 随机森林" data-book-page-rel-url="ml/integrate/scikit-learn-rf.html" data-book-page-id="6664">scikit-learn 随机森林</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster.html" title="第十五课：聚类" data-book-page-rel-url="ml/cluster.html" data-book-page-id="6665">第十五课：聚类</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/kmeans.html" title="K-Mean" data-book-page-rel-url="ml/cluster/kmeans.html" data-book-page-id="6666">K-Mean</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/KNN.html" title="KNN" data-book-page-rel-url="ml/cluster/KNN.html" data-book-page-id="6667">KNN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/knnshi-jian.html" title="scikit-learn KNN" data-book-page-rel-url="ml/cluster/knnshi-jian.html" data-book-page-id="6668">scikit-learn KNN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/knn-code.html" title="KNN 代码" data-book-page-rel-url="ml/cluster/knn-code.html" data-book-page-id="6669">KNN 代码</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-k-means.html" title="scikit-learn K-Means" data-book-page-rel-url="ml/cluster/scikit-k-means.html" data-book-page-id="6670">scikit-learn K-Means</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/birch.html" title="BIRCH聚类算法原理" data-book-page-rel-url="ml/cluster/birch.html" data-book-page-id="6671">BIRCH聚类算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-learn-birch.html" title="scikit-learn BIRCH" data-book-page-rel-url="ml/cluster/scikit-learn-birch.html" data-book-page-id="6672">scikit-learn BIRCH</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/dbscan.html" title="DBSCAN密度聚类算法" data-book-page-rel-url="ml/cluster/dbscan.html" data-book-page-id="6673">DBSCAN密度聚类算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-learn-dbscan.html" title="scikit-learn DBSCAN" data-book-page-rel-url="ml/cluster/scikit-learn-dbscan.html" data-book-page-id="6674">scikit-learn DBSCAN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/spectral.html" title="谱聚类（spectral clustering）原理" data-book-page-rel-url="ml/cluster/spectral.html" data-book-page-id="6675">谱聚类（spectral clustering）原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-spectral.html" title="scikit-learn 谱聚类" data-book-page-rel-url="ml/cluster/scikit-spectral.html" data-book-page-id="6676">scikit-learn 谱聚类</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/ap.html" title="近邻传播算法" data-book-page-rel-url="ml/cluster/ap.html" data-book-page-id="6677">近邻传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/gmm.html" title="混合高斯模型" data-book-page-rel-url="ml/cluster/gmm.html" data-book-page-id="6678">混合高斯模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/associative.html" title="关联分析" data-book-page-rel-url="ml/associative/associative.html" data-book-page-id="6679">关联分析</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/cca.html" title="典型关联分析(CCA)原理" data-book-page-rel-url="ml/associative/cca.html" data-book-page-id="6680">典型关联分析(CCA)原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/apriori.html" title="Apriori算法原理" data-book-page-rel-url="ml/associative/apriori.html" data-book-page-id="6681">Apriori算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/fptree.html" title="FP Tree算法原理" data-book-page-rel-url="ml/associative/fptree.html" data-book-page-id="6682">FP Tree算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/prefixspan.html" title="PrefixSpan算法原理" data-book-page-rel-url="ml/associative/prefixspan.html" data-book-page-id="6683">PrefixSpan算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/spark-fptree-prefixspan.html" title="Spark FP Tree算法和PrefixSpan算法" data-book-page-rel-url="ml/associative/spark-fptree-prefixspan.html" data-book-page-id="6684">Spark FP Tree算法和PrefixSpan算法</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/recommand.html" title="推荐算法" data-book-page-rel-url="ml/recommand/recommand.html" data-book-page-id="6685">推荐算法</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/matrix-filter.html" title="矩阵分解协同过滤推荐算法" data-book-page-rel-url="ml/recommand/matrix-filter.html" data-book-page-id="6686">矩阵分解协同过滤推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/simrank.html" title="SimRank协同过滤推荐算法" data-book-page-rel-url="ml/recommand/simrank.html" data-book-page-id="6687">SimRank协同过滤推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recomand/spark-factor.html" title="Spark矩阵分解推荐算法" data-book-page-rel-url="ml/recomand/spark-factor.html" data-book-page-id="6688">Spark矩阵分解推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/fm.html" title="分解机(Factorization Machines)推荐算法原理" data-book-page-rel-url="ml/recommand/fm.html" data-book-page-id="6689">分解机(Factorization Machines)推荐算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/meituan.html" title="美团推荐算法" data-book-page-rel-url="ml/recommand/meituan.html" data-book-page-id="6690">美团推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/mr-itemcf.html" title="MapReduce ItemCF" data-book-page-rel-url="ml/recommand/mr-itemcf.html" data-book-page-id="6691">MapReduce ItemCF</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/label-recommand.html" title="基于标签的用户推荐系统" data-book-page-rel-url="ml/recommand/label-recommand.html" data-book-page-id="6692">基于标签的用户推荐系统</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/em/em.html" title="第十七课：EM算法" data-book-page-rel-url="ml/em/em.html" data-book-page-id="6693">第十七课：EM算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes.html" title="第十九课：贝叶斯网络" data-book-page-rel-url="ml/bayes.html" data-book-page-id="6694">第十九课：贝叶斯网络</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/po-su-bei-xie-si.html" title="朴素贝叶斯" data-book-page-rel-url="ml/bayes/po-su-bei-xie-si.html" data-book-page-id="6695">朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/scikit-simple-bayes.html" title="scikit-learn朴素贝叶斯" data-book-page-rel-url="ml/bayes/scikit-simple-bayes.html" data-book-page-id="6696">scikit-learn朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/simple-bayes-real-use.html" title="朴素贝叶斯实际应用" data-book-page-rel-url="ml/bayes/simple-bayes-real-use.html" data-book-page-id="6697">朴素贝叶斯实际应用</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/simple-bayes-code.html" title="朴素贝叶斯代码" data-book-page-rel-url="ml/bayes/simple-bayes-code.html" data-book-page-id="6698">朴素贝叶斯代码</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/lda/lda.html" title="第二十一课：LDA主题模型" data-book-page-rel-url="ml/lda/lda.html" data-book-page-id="6699">第二十一课：LDA主题模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/hmm.html" title="第二十三课：隐马尔科夫模型HMM" data-book-page-rel-url="ml/hmm/hmm.html" data-book-page-id="6700">第二十三课：隐马尔科夫模型HMM</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/hmm-forward-backward.html" title="HMM前向后向算法评估观察序列概率" data-book-page-rel-url="ml/hmm/hmm-forward-backward.html" data-book-page-id="6701">HMM前向后向算法评估观察序列概率</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/bmwl-hmm.html" title="鲍姆-韦尔奇算法求解HMM参数" data-book-page-rel-url="ml/hmm/bmwl-hmm.html" data-book-page-id="6702">鲍姆-韦尔奇算法求解HMM参数</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/viterb-hmm.html" title="维特比算法解码隐藏状态序列" data-book-page-rel-url="ml/hmm/viterb-hmm.html" data-book-page-id="6703">维特比算法解码隐藏状态序列</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/hmmlearn.html" title="用hmmlearn学习隐马尔科夫模型HMM" data-book-page-rel-url="ml/hmm/hmmlearn.html" data-book-page-id="6704">用hmmlearn学习隐马尔科夫模型HMM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/markv-mengtekluo.html" title="马尔科夫蒙特卡洛" data-book-page-rel-url="ml/hmm/markv-mengtekluo.html" data-book-page-id="6705">马尔科夫蒙特卡洛</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/crf.html" title="条件随机场CRF" data-book-page-rel-url="ml/crf/crf.html" data-book-page-id="6706">条件随机场CRF</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/linear-crf.html" title="从随机场到线性链条件随机场" data-book-page-rel-url="ml/crf/linear-crf.html" data-book-page-id="6707">从随机场到线性链条件随机场</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/back-forth.html" title="前向后向算法评估标记序列概率" data-book-page-rel-url="ml/crf/back-forth.html" data-book-page-id="6708">前向后向算法评估标记序列概率</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/crf-viterbi.html" title="维特比算法解码" data-book-page-rel-url="ml/crf/crf-viterbi.html" data-book-page-id="6709">维特比算法解码</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/dl.html" title="第三部分 深度学习" data-book-page-rel-url="dl/dl.html" data-book-page-id="6710">第三部分 深度学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/layers.html" title="深度学习层" data-book-page-rel-url="dl/layers/layers.html" data-book-page-id="6711">深度学习层</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/core.html" title="核心层" data-book-page-rel-url="dl/layers/core.html" data-book-page-id="6712">核心层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/conv.html" title="卷积层" data-book-page-rel-url="dl/layers/conv.html" data-book-page-id="6713">卷积层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/pooling.html" title="池化层" data-book-page-rel-url="dl/layers/pooling.html" data-book-page-id="6714">池化层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/lcnn.html" title="局部连接层" data-book-page-rel-url="dl/layers/lcnn.html" data-book-page-id="6715">局部连接层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/rnn.html" title="循环层" data-book-page-rel-url="dl/layers/rnn.html" data-book-page-id="6716">循环层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/ebbedded.html" title="嵌入层" data-book-page-rel-url="dl/layers/ebbedded.html" data-book-page-id="6717">嵌入层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/merge.html" title="合并层" data-book-page-rel-url="dl/layers/merge.html" data-book-page-id="6718">合并层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/activation.html" title="高级激活层" data-book-page-rel-url="dl/layers/activation.html" data-book-page-id="6719">高级激活层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/regular.html" title="归一化层" data-book-page-rel-url="dl/layers/regular.html" data-book-page-id="6720">归一化层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/nosie.html" title="噪声层" data-book-page-rel-url="dl/layers/nosie.html" data-book-page-id="6721">噪声层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/wrapper.html" title="层包裹" data-book-page-rel-url="dl/layers/wrapper.html" data-book-page-id="6722">层包裹</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/userdefine.html" title="自定义层" data-book-page-rel-url="dl/layers/userdefine.html" data-book-page-id="6723">自定义层</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/introduction.html" title="第二十五课：深度学习" data-book-page-rel-url="dl/introduction/introduction.html" data-book-page-id="6724">第二十五课：深度学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/ji-ben-gai-nian.html" title="基本概念" data-book-page-rel-url="dl/introduction/ji-ben-gai-nian.html" data-book-page-id="6725">基本概念</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-fp.html" title="深度神经网络（DNN）模型与前向传播算法" data-book-page-rel-url="dl/introduction/dnn-fp.html" data-book-page-id="6726">深度神经网络（DNN）模型与前向传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-bp.html" title="深度神经网络（DNN）反向传播算法(BP)" data-book-page-rel-url="dl/introduction/dnn-bp.html" data-book-page-id="6727">深度神经网络（DNN）反向传播算法(BP)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/back-propagation.html" title="反向传播" data-book-page-rel-url="dl/introduction/back-propagation.html" data-book-page-id="6728">反向传播</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/READ.html" title="反向传播2" data-book-page-rel-url="dl/introduction/READ.html" data-book-page-id="6729">反向传播2</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-loss.html" title="DNN损失函数和激活函数的选择" data-book-page-rel-url="dl/introduction/dnn-loss.html" data-book-page-id="6730">DNN损失函数和激活函数的选择</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-normal.html" title="深度神经网络（DNN）的正则化" data-book-page-rel-url="dl/introduction/dnn-normal.html" data-book-page-id="6731">深度神经网络（DNN）的正则化</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reference.html" title="参考文献" data-book-page-rel-url="dl/reference.html" data-book-page-id="6732">参考文献</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/introduction.html" title="第二十六课 卷积神 经网络(Convolutional Neural Netowrk)" data-book-page-rel-url="dl/cnn/introduction.html" data-book-page-id="6733">第二十六课 卷积神 经网络(Convolutional Neural Netowrk)</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/cnn-arch.html" title="卷积神经网络(CNN)模型结构" data-book-page-rel-url="dl/cnn/cnn-arch.html" data-book-page-id="6734">卷积神经网络(CNN)模型结构</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/cnn-fp.html" title="卷积神经网络(CNN)前向传播算法" data-book-page-rel-url="dl/cnn/cnn-fp.html" data-book-page-id="6735">卷积神经网络(CNN)前向传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/cnn-bp.html" title="卷积神经网络(CNN)反向传播算法" data-book-page-rel-url="dl/cnn/cnn-bp.html" data-book-page-id="6736">卷积神经网络(CNN)反向传播算法</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/gan.html" title="对抗生成网络(Generative Adversarial Networks)" data-book-page-rel-url="dl/gan/gan.html" data-book-page-id="6737">对抗生成网络(Generative Adversarial Networks)</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/gan/gan-principle.html" title="GAN原理" data-book-page-rel-url="ml/gan/gan-principle.html" data-book-page-id="6738">GAN原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/infogan.html" title="InfoGAN" data-book-page-rel-url="dl/gan/infogan.html" data-book-page-id="6739">InfoGAN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/dcgan.html" title="DCGAN" data-book-page-rel-url="dl/gan/dcgan.html" data-book-page-id="6740">DCGAN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/vae.html" title="VAE" data-book-page-rel-url="dl/gan/vae.html" data-book-page-id="6741">VAE</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/rbm.html" title="受限波尔兹曼机" data-book-page-rel-url="dl/rbm/rbm.html" data-book-page-id="6742">受限波尔兹曼机</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/rbm-code.html" title="RBM code" data-book-page-rel-url="dl/rbm/rbm-code.html" data-book-page-id="6743">RBM code</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/dbn.html" title="DBN" data-book-page-rel-url="dl/rbm/dbn.html" data-book-page-id="6744">DBN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/rbm-yuanli.html" title="RBM原理" data-book-page-rel-url="dl/rbm/rbm-yuanli.html" data-book-page-id="6745">RBM原理</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/rnn.html" title="RNN" data-book-page-rel-url="dl/rnn/rnn.html" data-book-page-id="6746">RNN</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/bidirectional-rnns.html" title="Bidirectional RNNs" data-book-page-rel-url="dl/rnn/bidirectional-rnns.html" data-book-page-id="6747">Bidirectional RNNs</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/deep-bidirectional-rnns.html" title="Deep (Bidirectional) RNNs" data-book-page-rel-url="dl/rnn/deep-bidirectional-rnns.html" data-book-page-id="6748">Deep (Bidirectional) RNNs</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/lstm.html" title="LSTM模型与前向反向传播算法" data-book-page-rel-url="dl/rnn/lstm.html" data-book-page-id="6749">LSTM模型与前向反向传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/bptt.html" title="随时间反向传播（BPTT）算法" data-book-page-rel-url="dl/rnn/bptt.html" data-book-page-id="6750">随时间反向传播（BPTT）算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/rnn-bptt.html" title="循环神经网络(RNN)模型与前向反向传播算法" data-book-page-rel-url="dl/rnn/rnn-bptt.html" data-book-page-id="6751">循环神经网络(RNN)模型与前向反向传播算法</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/encoder.html" title="自动编码器" data-book-page-rel-url="dl/encoder/encoder.html" data-book-page-id="6752">自动编码器</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/stack-denoise-encoder.html" title="堆叠降噪自动编码器" data-book-page-rel-url="dl/encoder/stack-denoise-encoder.html" data-book-page-id="6753">堆叠降噪自动编码器</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/denoise-encoder.html" title="降噪自动编码器" data-book-page-rel-url="dl/encoder/denoise-encoder.html" data-book-page-id="6754">降噪自动编码器</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/sparse-autoencoder.html" title="sparse自动编码器" data-book-page-rel-url="dl/encoder/sparse-autoencoder.html" data-book-page-id="6755">sparse自动编码器</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/keras-autoencoder.html" title="Keras自动编码器" data-book-page-rel-url="dl/encoder/keras-autoencoder.html" data-book-page-id="6756">Keras自动编码器</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/word2vec.html" title="word2vec" data-book-page-rel-url="dl/word2vec/word2vec.html" data-book-page-id="6757">word2vec</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/cbow-skip-n.html" title="CBOW与Skip-Gram模型基础" data-book-page-rel-url="dl/word2vec/cbow-skip-n.html" data-book-page-id="6758">CBOW与Skip-Gram模型基础</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/hierarc-softmax.html" title="基于Hierarchical Softmax的模型" data-book-page-rel-url="dl/word2vec/hierarc-softmax.html" data-book-page-id="6759">基于Hierarchical Softmax的模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/negative-sampling.html" title="基于Negative Sampling的模型" data-book-page-rel-url="dl/word2vec/negative-sampling.html" data-book-page-id="6760">基于Negative Sampling的模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/reinforcement.html" title="增强学习" data-book-page-rel-url="dl/reinforcement/reinforcement.html" data-book-page-id="6761">增强学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/q-learning.html" title="Q-Learning" data-book-page-rel-url="dl/reinforcement/q-learning.html" data-book-page-id="6762">Q-Learning</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/policy-network.html" title="策略网络" data-book-page-rel-url="dl/reinforcement/policy-network.html" data-book-page-id="6763">策略网络</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/banditsuan-fa.html" title="bandit算法" data-book-page-rel-url="dl/reinforcement/banditsuan-fa.html" data-book-page-id="6764">bandit算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/meng-te-qia-luo-shu-sou-suo.html" title="蒙特卡洛树搜索" data-book-page-rel-url="dl/reinforcement/meng-te-qia-luo-shu-sou-suo.html" data-book-page-id="6765">蒙特卡洛树搜索</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/multi-bandit.html" title="多臂赌博机(Multi-arm Bandits)" data-book-page-rel-url="dl/reinforcement/multi-bandit.html" data-book-page-id="6766">多臂赌博机(Multi-arm Bandits)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/mdp.html" title="马尔可夫决策过程MDP" data-book-page-rel-url="dl/reinforcement/mdp.html" data-book-page-id="6767">马尔可夫决策过程MDP</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/dynamic-programming.html" title="动态编程" data-book-page-rel-url="dl/reinforcement/dynamic-programming.html" data-book-page-id="6768">动态编程</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/monte-carlo.html" title="蒙特卡洛方法" data-book-page-rel-url="dl/reinforcement/monte-carlo.html" data-book-page-id="6769">蒙特卡洛方法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/shi-xu-cha-fen-xue-xi.html" title="时序差分学习" data-book-page-rel-url="dl/reinforcement/shi-xu-cha-fen-xue-xi.html" data-book-page-id="6770">时序差分学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/a3csuan-fa.html" title="A3C算法" data-book-page-rel-url="dl/reinforcement/a3csuan-fa.html" data-book-page-id="6771">A3C算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/multi-steps-bootstraping.html" title="Multi-steps bootstraping" data-book-page-rel-url="dl/reinforcement/multi-steps-bootstraping.html" data-book-page-id="6772">Multi-steps bootstraping</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/tabular-method.html" title="Planning and Learning with Tabular Methods" data-book-page-rel-url="dl/reinforcement/tabular-method.html" data-book-page-id="6773">Planning and Learning with Tabular Methods</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/dqn.html" title="DQN" data-book-page-rel-url="dl/reinforcement/dqn.html" data-book-page-id="6774">DQN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/policy-gridient.html" title="Policy Gridient" data-book-page-rel-url="dl/reinforcement/policy-gridient.html" data-book-page-id="6775">Policy Gridient</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/actor-critic.html" title="Actor Critic" data-book-page-rel-url="dl/reinforcement/actor-critic.html" data-book-page-id="6776">Actor Critic</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/ddpg.html" title="DDPG (Deep Deterministic Policy Gradient)" data-book-page-rel-url="dl/reinforcement/ddpg.html" data-book-page-id="6777">DDPG (Deep Deterministic Policy Gradient)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/ppo.html" title="PPO(Proximal Policy Optimization )" data-book-page-rel-url="dl/reinforcement/ppo.html" data-book-page-id="6778">PPO(Proximal Policy Optimization )</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/alpha-beta.html" title="Alpha-Beta剪枝算法详解" data-book-page-rel-url="dl/reinforcement/alpha-beta.html" data-book-page-id="6779">Alpha-Beta剪枝算法详解</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/evolution/evolution.html" title="进化算法" data-book-page-rel-url="ml/evolution/evolution.html" data-book-page-id="6780">进化算法</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/evolution/yichuansuanfa.html" title="遗传算法" data-book-page-rel-url="ml/evolution/yichuansuanfa.html" data-book-page-id="6781">遗传算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/evolution/evolution-strategy.html" title="进化策略" data-book-page-rel-url="ml/evolution/evolution-strategy.html" data-book-page-id="6782">进化策略</a>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="NEAT" disabled data-book-page-rel-url="ml/evolution/neat.html" data-book-page-id="6783">NEAT</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/nlp.html" title="自然语言处理" data-book-page-rel-url="nlp/nlp.html" data-book-page-id="6784">自然语言处理</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/nlp/text-mine.html" title="文本挖掘的分词原理" data-book-page-rel-url="nlp/text-mine.html" data-book-page-id="6785">文本挖掘的分词原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/hashtrick.html" title="HashTrick" data-book-page-rel-url="nlp/hashtrick.html" data-book-page-id="6786">HashTrick</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/tf-idf.html" title="TF-IDF" data-book-page-rel-url="nlp/tf-idf.html" data-book-page-id="6787">TF-IDF</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/preprocessing.html" title="中文文本挖掘预处理" data-book-page-rel-url="nlp/preprocessing.html" data-book-page-id="6788">中文文本挖掘预处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/english-preprocess.html" title="英文文本挖掘预处理" data-book-page-rel-url="nlp/english-preprocess.html" data-book-page-id="6789">英文文本挖掘预处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/lsi.html" title="潜在语义索引(LSI)" data-book-page-rel-url="nlp/lda/lsi.html" data-book-page-id="6790">潜在语义索引(LSI)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/nmf.html" title="非负矩阵分解(NMF)" data-book-page-rel-url="nlp/lda/nmf.html" data-book-page-id="6791">非负矩阵分解(NMF)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/lda.html" title="LDA基础" data-book-page-rel-url="nlp/lda/lda.html" data-book-page-id="6792">LDA基础</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/lda-gibbs.html" title="LDA求解之Gibbs采样算法" data-book-page-rel-url="nlp/lda/lda-gibbs.html" data-book-page-id="6793">LDA求解之Gibbs采样算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/vi-em.html" title="LDA求解之变分推断EM算法" data-book-page-rel-url="nlp/lda/vi-em.html" data-book-page-id="6794">LDA求解之变分推断EM算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/scikit-learn-lda.html" title="scikit-learn LDA主题模型" data-book-page-rel-url="nlp/lda/scikit-learn-lda.html" data-book-page-id="6795">scikit-learn LDA主题模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/voice/introduction.html" title="语音识别" data-book-page-rel-url="voice/introduction.html" data-book-page-id="6796">语音识别</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/voice/gmm-hmm.html" title="GMM-HMM" data-book-page-rel-url="voice/gmm-hmm.html" data-book-page-id="6797">GMM-HMM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/voice/voicemulumd.html" title="目录" data-book-page-rel-url="voice/voicemulumd.html" data-book-page-id="6798">目录</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/introduction.html" title="第四部分 学习资源" data-book-page-rel-url="resources/introduction.html" data-book-page-id="6799">第四部分 学习资源</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/resources/ml/list.html" title="机器学习" data-book-page-rel-url="resources/ml/list.html" data-book-page-id="6800">机器学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/rl/list.html" title="强化学习" data-book-page-rel-url="resources/rl/list.html" data-book-page-id="6801">强化学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/nlp/list.html" title="自然语言处理" data-book-page-rel-url="resources/nlp/list.html" data-book-page-id="6802">自然语言处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/dl/list.html" title="深度学习" data-book-page-rel-url="resources/dl/list.html" data-book-page-id="6803">深度学习</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="流行网络结构" disabled data-book-page-rel-url="" data-book-page-id="6804">流行网络结构</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/popnet/mobilenet.html" title="mobilenet" data-book-page-rel-url="dl/popnet/mobilenet.html" data-book-page-id="6805">mobilenet</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/popnet/resnet.html" title="ResNet" data-book-page-rel-url="dl/popnet/resnet.html" data-book-page-id="6806">ResNet</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="并行学习" disabled data-book-page-rel-url="" data-book-page-id="6807">并行学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/paralleldl/mei-tuan-bing-xing-xue-xi-shi-jian.html" title="美团并行学习实践" data-book-page-rel-url="dl/paralleldl/mei-tuan-bing-xing-xue-xi-shi-jian.html" data-book-page-id="6808">美团并行学习实践</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="AI应用" disabled data-book-page-rel-url="" data-book-page-id="6809">AI应用</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/dlapp/mei-tuan-wai-mai-ai-ji-zhu.html" title="美团外卖AI技术" data-book-page-rel-url="dl/dlapp/mei-tuan-wai-mai-ai-ji-zhu.html" data-book-page-id="6810">美团外卖AI技术</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/dlapp/mei-tuan-tui-jian-pai-xu.html" title="美团推荐排序" data-book-page-rel-url="dl/dlapp/mei-tuan-tui-jian-pai-xu.html" data-book-page-id="6811">美团推荐排序</a>
</li>
</ul>
</li>
</ul>
</div>
</div>
<script src="https://cdn.staticfile.net/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="../../../../static/components/uikit-2.27.5/js/uikit.reader.js"></script>
<script type="text/javascript" src="../../../../static/components/social-share/social-share.min.js"></script>
<script>(function(){var bp =document.createElement('script');var curProtocol =window.location.protocol.split(':')[0];if (curProtocol ==='https') {bp.src ='https://zz.bdstatic.com/linksubmit/push.js';}
else {bp.src ='http://push.zhanzhang.baidu.com/push.js';}
var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp,s);})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
<script src="https://cdn.staticfile.net/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.net/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script src="https://cdn.staticfile.net/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="https://cdn.staticfile.net/uikit/2.27.5/js/components/lightbox.min.js"></script>
<link rel="dns-prefetch" href="../../../..//cdn.mathjax.org" />
<script type="text/x-mathjax-config">
 function initMathJax() {
    var mathId = $("book-content-section")[0];
    MathJax.Hub.Config({
        tex2jax: {skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a']},
        showProcessingMessages: false,
        messageStyle: "none"
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub,mathId]);
 };
initMathJax();
</script>
<script src='https://cdn.staticfile.net/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML' async></script>
<style>
	.MathJax_Display{display:inline!important;}
</style>
<script type="text/javascript" src="../../../../static/components/js/reader.js"></script>
<script type="text/javascript">var bookId =85;var bookPageId =6738;var bookPageRelUrl ='ml/gan/gan-principle.html';</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
</body>
</html>