
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>Keras自动编码器-机器学习原理</title>
<meta content='Keras自动编码器,机器学习原理' name='keywords'>
<meta content='Keras自动编码器,机器学习原理' name='description'>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=1, user-scalable=no"../../../../>
<meta name="applicable-device" content="pc,mobile">
<link rel="shortcut icon" href="../../../../favicon.ico" type="image/x-icon" />
<meta name="renderer" content="webkit">
<link rel="stylesheet" href="../../../../static/components/uikit-2.27.5/css/uikit.custom.css">
<link rel="stylesheet" href="../../../../static/components/social-share/social-share.min.css">
<link rel="stylesheet" href="../../../../static/components/highlight/styles/custom.css">
<link rel="stylesheet" href="../../../../static/components/css/base.css">
<link rel="stylesheet" href="../../../../static/components/css/reader.css">
<link rel="stylesheet" href="../../../../static/components/css/markdown.css">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5313208362165053" crossorigin="anonymous"></script>
</head>
<body>
<div class=" book-main-wrap uk-container uk-container-center uk-margin-top ">
<div class="uk-grid">
<div class="uk-width-1-1 reader-wrap ">
<div class=" bottom-nav uk-clearfix ">
<div class="uk-align-left ">
<a href="../../../../book/85/dl/encoder/sparse-autoencoder.html">
<i class="nav-icon-left uk-icon-small  uk-icon-caret-left"></i>
<span class="">sparse自动编码器</span>
</a>
</div>
<div class="uk-align-right ">
<a href="../../../../book/85/dl/word2vec/word2vec.html">
<span class="">word2vec</span>
<i class="nav-icon-right uk-icon-small  uk-icon-caret-right"></i>
</a>
</div>
</div>
<div class="uk-text-center">
<h2 class="book-page-title uk-container-center">
<a href="../../../../book/85/index.html">机器学习原理</a>
<a target="_blank" rel="nofollow" href="https://github.com/shunliz/Machine-Learning" class="uk-icon-button uk-icon-github" title="github项目地址"></a>
</h2>
</div>
<script type="text/javascript" src="../../../../static/components/js/app_intro.js"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5313208362165053" data-ad-slot="1328047120"></ins>
<script>(adsbygoogle =window.adsbygoogle ||[]).push({});</script>
<hr class="uk-article-divider">
<div class="book-content-section  md-content-section  uk-margin-bottom">
<h1 id="自动编码器各种各样的自动编码器">自动编码器：各种各样的自动编码器</h1>
<h2 id="文章信息">文章信息</h2>
<p><font color="#FF0000">本文地址：<a href="http://blog.keras.io/building-autoencoders-in-keras.html"><font color="#FF0000">http://blog.keras.io/building-autoencoders-in-keras.html</font></a></font></p>
<font color="#FF0000"> </font>
<p><font color="#FF0000">本文作者：Francois Chollet </font></p>
<h3 id="什么是自动编码器autoencoder">什么是自动编码器（Autoencoder）</h3>
<p><a href="https://github.com/MoyanZitto/keras-cn/raw/master/docs/legacy/images/autoencoder_schema.jpg" data-uk-lightbox><img src="https://github.com/MoyanZitto/keras-cn/raw/master/docs/legacy/images/autoencoder_schema.jpg" alt="autoencoder_schema.jpg"></a></p>
<p>自动编码器是一种数据的压缩算法，其中数据的压缩和解压缩函数是1）数据相关的,2）有损的，3）从样本中自动学习的。在大部分提到自动编码器的场合，压缩和解压缩的函数是通过神经网络实现的。</p>
<p>1）自动编码器是数据相关的（data-specific 或 data-dependent），这意味着自动编码器只能压缩那些与训练数据类似的数据。自编码器与一般的压缩算法，如MPEG-2，MP3等压缩算法不同，一般的通用算法只假设了数据是“图像”或“声音”，而没有指定是哪种图像或声音。比如，使用人脸训练出来的自动编码器在压缩别的图片，比如树木时性能很差，因为它学习到的特征是与人脸相关的。</p>
<p>2）自动编码器是有损的，意思是解压缩的输出与原来的输入相比是退化的，MP3，JPEG等压缩算法也是如此。这与无损压缩算法不同。</p>
<p>3）自动编码器是从数据样本中自动学习的，这意味着很容易对指定类的输入训练出一种特定的编码器，而不需要完成任何新工作。</p>
<p>搭建一个自动编码器需要完成下面三样工作：搭建编码器，搭建解码器，设定一个损失函数，用以衡量由于压缩而损失掉的信息。编码器和解码器一般都是参数化的方程，并关于损失函数可导，典型情况是使用神经网络。编码器和解码器的参数可以通过最小化损失函数而优化，例如SGD。</p>
<h3 id="自编码器是一个好的数据压缩算法吗">自编码器是一个好的数据压缩算法吗</h3>
<p>通常情况下，使用自编码器做数据压缩，性能并不怎么样。以图片压缩为例，想要训练一个能和JPEG性能相提并论的自编码器非常困难，并且要达到这个性能，你还必须要把图片的类型限定在很小的一个范围内（例如JPEG不怎么行的某类图片）。自编码器依赖于数据的特性使得它在面对真实数据的压缩上并不可行，你只能在指定类型的数据上获得还可以的效果，但谁知道未来会有啥新需求？</p>
<h3 id="那么自编码器擅长做什么">那么，自编码器擅长做什么？</h3>
<p>自编码器在实际应用中用的很少，2012年人们发现在卷积神经网络中使用自编码器做逐层预训练可以训练深度网络，但很快人们发现良好的初始化策略在训练深度网络上要比费劲的逐层预训练有效得多，2014年出现的Batch Normalization技术使得更深的网络也可以被有效训练，到了2015年底，通过使用残差学习（ResNet）我们基本上可以训练任意深度的神经网络。</p>
<p>目前自编码器的应用主要有两个方面，第一是数据去噪，第二是为进行可视化而降维。配合适当的维度和稀疏约束，自编码器可以学习到比PCA等技术更有意思的数据投影。</p>
<p>对于2D的数据可视化，<a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding"><font color="#FF0000">t-SNE</font></a>（读作tee-snee）或许是目前最好的算法，但通常还是需要原数据的维度相对低一些。所以，可视化高维数据的一个好办法是首先使用自编码器将维度降低到较低的水平（如32维），然后再使用t-SNE将其投影在2D平面上。Keras版本的t-SNE由Kyle McDonald实现了一下，放在了<a href="https://github.com/kylemcdonald/Parametric-t-SNE/blob/master/Parametric t-SNE (Keras).ipynb"><font color="#FF0000">这里</font></a>，另外<a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"><font color="#FF0000">scikit-learn</font></a>也有一个简单实用的实现。</p>
<h3 id="自编码器有什么卵用">自编码器有什么卵用</h3>
<p>自编码器的出名来自于网上很多机器学习课程的介绍，总而言之，一堆新手非常热爱自编码器而且怎么也玩不够，这就是这篇文章出现的意义【告诉你自编码器有什么卵用】。</p>
<p>自编码器吸引了一大批研究和关注的主要原因之一是很长时间一段以来它被认为是解决无监督学习的可能方案，即大家觉得自编码器可以在没有标签的时候学习到数据的有用表达。再说一次，自编码器并不是一个真正的无监督学习的算法，而是一个自监督的算法。自监督学习是监督学习的一个实例，其标签产生自输入数据。要获得一个自监督的模型，你需要想出一个靠谱的目标跟一个损失函数，问题来了，仅仅把目标设定为重构输入可能不是正确的选项。基本上，要求模型在像素级上精确重构输入不是机器学习的兴趣所在，学习到高级的抽象特征才是。事实上，当你的主要任务是分类、定位之类的任务时，那些对这类任务而言的最好的特征基本上都是重构输入时的最差的那种特征。</p>
<p>在应用自监督学习的视觉问题中，可能应用自编码器的领域有例如拼图，细节纹理匹配（从低分辨率的图像块中匹配其高分辨率的对应块）。下面这篇文章研究了拼图问题，其实很有意思，不妨一读。<a href="http://arxiv.org/abs/1603.09246"><font color="#FF0000">Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles.</font></a>。此类问题的模型输入有些内置的假设，例如“视觉块比像素级的细节更重要”这样的，这种假设是普通的自编码器没有的。</p>
<p><a href="https://github.com/MoyanZitto/keras-cn/blob/master/docs/legacy/images/jigsaw-puzzle.png" data-uk-lightbox><img src="https://github.com/MoyanZitto/keras-cn/blob/master/docs/legacy/images/jigsaw-puzzle.png" alt="jigsaw-puzzle.png"></a></p>
<h3 id="使用keras建立简单的自编码器">使用Keras建立简单的自编码器</h3>
<p>首先，先建立一个全连接的编码器和解码器</p>
<pre><code class="language-python">from keras.layers import Input, Dense
from keras.models import Model

# this is the size of our encoded representations
encoding_dim = 32  # 32 floats -&gt; compression of factor 24.5, assuming the input is 784 floats

# this is our input placeholder
input_img = Input(shape=(784,))
# "encoded" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu')(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = Dense(784, activation='sigmoid')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input=input_img, output=decoded)
</code></pre>
<p>当然我们可以单独的使用编码器和解码器：</p>
<pre><code class="language-python"># this model maps an input to its encoded representation
encoder = Model(input=input_img, output=encoded)
</code></pre>
<pre><code class="language-python"># create a placeholder for an encoded (32-dimensional) input
encoded_input = Input(shape=(encoding_dim,))
# retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# create the decoder model
decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))
</code></pre>
<p>下面我们训练自编码器，来重构MNIST中的数字，这里使用逐像素的交叉熵作为损失函数，优化器为adam</p>
<pre><code class="language-python">autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
</code></pre>
<p>然后准备MNIST数据，将其归一化和向量化，然后训练：</p>
<pre><code class="language-python">from keras.datasets import mnist
import numpy as np
(x_train, _), (x_test, _) = mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print x_train.shape
print x_test.shape

autoencoder.fit(x_train, x_train,
                nb_epoch=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))
</code></pre>
<p>50个epoch后，看起来我们的自编码器优化的不错了，损失是0.10，我们可视化一下重构出来的输出：</p>
<pre><code class="language-python"># encode and decode some digits
# note that we take them from the *test* set
# use Matplotlib (don't ask)
import matplotlib.pyplot as plt

encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)


n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
</code></pre>
<p>这里是结果：</p>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/basic_ae_32.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/basic_ae_32.png" alt="basic_ae_32.png"></a></p>
<h3 id="稀疏自编码器为码字加上稀疏性约束">稀疏自编码器：为码字加上稀疏性约束</h3>
<p>刚刚我们的隐层有32个神经元，这种情况下，一般而言自编码器学到的是PCA的一个近似（PCA不想科普了）。但是如果我们对隐层单元施加稀疏性约束的话，会得到更为紧凑的表达，只有一小部分神经元会被激活。在Keras中，我们可以通过添加一个activity_regularizer达到对某层激活值进行约束的目的：</p>
<pre><code class="language-python">from keras import regularizers

encoding_dim = 32

input_img = Input(shape=(784,))
# add a Dense layer with a L1 activity regularizer
encoded = Dense(encoding_dim, activation='relu',
                activity_regularizer=regularizers.activity_l1(10e-5))(input_img)
decoded = Dense(784, activation='sigmoid')(encoded)

autoencoder = Model(input=input_img, output=decoded)
</code></pre>
<p>因为我们添加了正则性约束，所以模型过拟合的风险降低，我们可以训练多几次，这次训练100个epoch，得到损失为0.11，多出来的0.01基本上是由于正则项造成的。可视化结果如下：</p>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/sparse_ae_32.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/sparse_ae_32.png" alt="sparse_ae_32 (1).png"></a></p>
<p>结果上没有毛线差别，区别在于编码出来的码字更加稀疏了。稀疏自编码器的在10000个测试图片上的码字均值为3.33，而之前的为7.30</p>
<h3 id="深度自编码器把自编码器叠起来">深度自编码器：把自编码器叠起来</h3>
<p>把多个自编码器叠起来，像这样：</p>
<pre><code class="language-python">input_img = Input(shape=(784,))
encoded = Dense(128, activation='relu')(input_img)
encoded = Dense(64, activation='relu')(encoded)
encoded = Dense(32, activation='relu')(encoded)

decoded = Dense(64, activation='relu')(encoded)
decoded = Dense(128, activation='relu')(decoded)
decoded = Dense(784, activation='sigmoid')(decoded)

autoencoder = Model(input=input_img, output=decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')

autoencoder.fit(x_train, x_train,
                nb_epoch=100,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))
</code></pre>
<p>100个epoch后，loss大概是0.097，比之前的模型好那么一丢丢</p>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/deep_ae_32.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/deep_ae_32.png" alt="deep_ae_32.png"></a></p>
<h3 id="卷积自编码器用卷积层搭建自编码器">卷积自编码器：用卷积层搭建自编码器</h3>
<p>当输入是图像时，使用卷积神经网络基本上总是有意义的。在现实中，用于处理图像的自动编码器几乎都是卷积自动编码器——又简单又快，棒棒哒</p>
<p>卷积自编码器的编码器部分由卷积层和MaxPooling层构成，MaxPooling负责空域下采样。而解码器由卷积层和上采样层构成。</p>
<pre><code class="language-python">from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D
from keras.models import Model

input_img = Input(shape=(1, 28, 28))

x = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(input_img)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
encoded = MaxPooling2D((2, 2), border_mode='same')(x)

# at this point the representation is (8, 4, 4) i.e. 128-dimensional

x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(16, 3, 3, activation='relu')(x)
x = UpSampling2D((2, 2))(x)
decoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
</code></pre>
<p>我们使用28*28*3的原始MNIST图像（尽管看起来还是灰度图）训练网络，图片的像素被归一化到0~1之间。</p>
<pre><code class="language-python">from keras.datasets import mnist
import numpy as np

(x_train, _), (x_test, _) = mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = np.reshape(x_train, (len(x_train), 1, 28, 28))
x_test = np.reshape(x_test, (len(x_test), 1, 28, 28))
</code></pre>
<p>为了可视化训练过程的损失情况，我们使用TensorFlow作为后端，这样就可以启用TensorBoard了。打开一个终端并启动TensorBoard，TensorBoard将读取位于/tmp/autoencoder的日志文件：</p>
<pre><code class="language-python">tensorboard --logdir=/tmp/autoencoder
</code></pre>
<p>然后我们把模型训练50个epoch，并在回调函数列表中传入TensorBoard回调函数，在每个epoch后回调函数将把训练的信息写入刚才的那个日志文件里，并被TensorBoard读取到</p>
<pre><code class="language-python">from keras.callbacks import TensorBoard

autoencoder.fit(x_train, x_train,
                nb_epoch=50,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test, x_test),
                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])
</code></pre>
<p>打开浏览器进入http://0.0.0.0:6006观测结果：</p>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/tb_curves.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/tb_curves.png" alt="tb_curves.png"></a></p>
<p>模型最后的loss是0.094，要比之前的模型都要好得多，因为现在我们的编码器的表达表达能力更强了。</p>
<pre><code class="language-python">decoded_imgs = autoencoder.predict(x_test)

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
</code></pre>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/deep_conv_ae_128.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/deep_conv_ae_128.png" alt="deep_conv_ae_128.png"></a></p>
<p>我们也可以看看中间的码字长什么样，这些码字的shape是8*4*4，我们可以将其reshape成4*32看</p>
<pre><code class="language-python">n = 10
plt.figure(figsize=(20, 8))
for i in range(n):
    ax = plt.subplot(1, n, i)
    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
</code></pre>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/encoded_representations.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/encoded_representations.png" alt="encoded_representations.png"></a></p>
<h3 id="使用自动编码器进行图像去噪">使用自动编码器进行图像去噪</h3>
<p>我们把训练样本用噪声污染，然后使解码器解码出干净的照片，以获得去噪自动编码器。首先我们把原图片加入高斯噪声，然后把像素值clip到0~1</p>
<pre><code class="language-python">from keras.datasets import mnist
import numpy as np

(x_train, _), (x_test, _) = mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = np.reshape(x_train, (len(x_train), 1, 28, 28))
x_test = np.reshape(x_test, (len(x_test), 1, 28, 28))

noise_factor = 0.5
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) 
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) 

x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)
</code></pre>
<p>我们可以先看看被污染的照片长啥样：</p>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/noisy_digits.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/noisy_digits.png" alt="noisy_digits.png"></a></p>
<p>和之前的卷积自动编码器相比，为了提高重构图质量，我们的模型稍有不同</p>
<pre><code class="language-python">input_img = Input(shape=(1, 28, 28))

x = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(input_img)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)
encoded = MaxPooling2D((2, 2), border_mode='same')(x)

# at this point the representation is (32, 7, 7)

x = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
decoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
</code></pre>
<p>先来100个epoch的训练看看结果</p>
<pre><code class="language-python">autoencoder.fit(x_train_noisy, x_train,
                nb_epoch=100,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test_noisy, x_test),
                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])
</code></pre>
<p>结果如下，棒棒哒~</p>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/denoised_digits.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/denoised_digits.png" alt="denoised_digits.png"></a></p>
<p>如果你将这个过程扩展到更大的卷积网络，你可以处理文档和声音的去噪，Kaggle有一个或许你会感兴趣的数据集在<a href="https://www.kaggle.com/c/denoising-dirty-documents"><font color="#FF0000">这里</font></a></p>
<h3 id="序列到序列的自动编码器">序列到序列的自动编码器</h3>
<p>如果你的输入是序列而不是2D的图像，那么你可能想要使用针对序列的模型构造自编码器，如LSTM。要构造基于LSTM的自编码器，首先我们需要一个LSTM的编码器来将输入序列变为一个向量，然后将这个向量重复N此，然后用LSTM的解码器将这个N步的时间序列变为目标序列。</p>
<p>这里我们不针对任何特定的数据库做这件事，只提供代码供读者参考</p>
<pre><code class="language-python">from keras.layers import Input, LSTM, RepeatVector
from keras.models import Model

inputs = Input(shape=(timesteps, input_dim))
encoded = LSTM(latent_dim)(inputs)

decoded = RepeatVector(timesteps)(encoded)
decoded = LSTM(input, return_sequences=True)(decoded)

sequence_autoencoder = Model(inputs, decoded)
encoder = Model(inputs, encoded)
</code></pre>
<h3 id="变分自编码器variational-autoencodervae编码数据的分布">变分自编码器（Variational autoencoder，VAE）：编码数据的分布</h3>
<p>编码自编码器是更现代和有趣的一种自动编码器，它为码字施加约束，使得编码器学习到输入数据的隐变量模型。隐变量模型是连接显变量集和隐变量集的统计模型，隐变量模型的假设是显变量是由隐变量的状态控制的，各个显变量之间条件独立。也就是说，变分编码器不再学习一个任意的函数，而是学习你的数据概率分布的一组参数。通过在这个概率分布中采样，你可以生成新的输入数据，即变分编码器是一个生成模型。</p>
<p>下面是变分编码器的工作原理：</p>
<p>首先，编码器网络将输入样本x转换为隐空间的两个参数，记作z_mean和z_log_sigma。然后，我们随机从隐藏的正态分布中采样得到数据点z，这个隐藏分布我们假设就是产生输入数据的那个分布。z = z_mean + exp(z_log_sigma)*epsilon，epsilon是一个服从正态分布的张量。最后，使用解码器网络将隐空间映射到显空间，即将z转换回原来的输入数据空间。</p>
<p>参数藉由两个损失函数来训练，一个是重构损失函数，该函数要求解码出来的样本与输入的样本相似（与之前的自编码器相同），第二项损失函数是学习到的隐分布与先验分布的KL距离，作为一个正则。实际上把后面这项损失函数去掉也可以，尽管它对学习符合要求的隐空间和防止过拟合有帮助。</p>
<p>因为VAE是一个很复杂的例子，我们把VAE的代码放在了github上，在<a href="https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder.py"><font color="#FF0000">这里</font></a>。在这里我们来一步步回顾一下这个模型是如何搭建的</p>
<p>首先，建立编码网络，将输入影射为隐分布的参数：</p>
<pre><code class="language-python">x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
</code></pre>
<p>然后从这些参数确定的分布中采样，这个样本相当于之前的隐层值</p>
<pre><code class="language-python">def sampling(args):
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., std=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
</code></pre>
<p>最后，将采样得到的点映射回去重构原输入：</p>
<pre><code class="language-python">decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
</code></pre>
<p>到目前为止我们做的工作需要实例化三个模型：</p>
<ul>
<li> <p>一个端到端的自动编码器，用于完成输入信号的重构</p> </li>
<li> <p>一个用于将输入空间映射为隐空间的编码器</p> </li>
<li> <p>一个利用隐空间的分布产生的样本点生成对应的重构样本的生成器</p> </li>
</ul>
<pre><code class="language-python"># end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
</code></pre>
<p>我们使用端到端的模型训练，损失函数是一项重构误差，和一项KL距离</p>
<pre><code class="language-python">def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
</code></pre>
<p>现在使用MNIST库来训练变分编码器：</p>
<pre><code class="language-python">(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))

vae.fit(x_train, x_train,
        shuffle=True,
        nb_epoch=nb_epoch,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
</code></pre>
<p>因为我们的隐空间只有两维，所以我们可以可视化一下。我们来看看2D平面中不同类的近邻分布：</p>
<pre><code class="language-python">x_test_encoded = encoder.predict(x_test, batch_size=batch_size)
plt.figure(figsize=(6, 6))
plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)
plt.colorbar()
plt.show()
</code></pre>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/vae_classes_plane.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/vae_classes_plane.png" alt="vae_classes_plane.png"></a></p>
<p>上图每种颜色代表一个数字，相近聚类的数字代表他们在结构上相似。</p>
<p>因为变分编码器是一个生成模型，我们可以用它来生成新数字。我们可以从隐平面上采样一些点，然后生成对应的显变量，即MNIST的数字：</p>
<pre><code class="language-python"># display a 2D manifold of the digits
n = 15  # figure with 15x15 digits
digit_size = 28
figure = np.zeros((digit_size * n, digit_size * n))
# we will sample n points within [-15, 15] standard deviations
grid_x = np.linspace(-15, 15, n)
grid_y = np.linspace(-15, 15, n)

for i, yi in enumerate(grid_x):
    for j, xi in enumerate(grid_y):
        z_sample = np.array([[xi, yi]]) * epsilon_std
        x_decoded = generator.predict(z_sample)
        digit = x_decoded[0].reshape(digit_size, digit_size)
        figure[i * digit_size: (i + 1) * digit_size,
               j * digit_size: (j + 1) * digit_size] = digit

plt.figure(figsize=(10, 10))
plt.imshow(figure)
plt.show()
</code></pre>
<p><a href="https://img.cntofu.com/book/Machine-Learning/dl/images/vae_digits_manifold.png" data-uk-lightbox><img src="https://img.cntofu.com/book/Machine-Learning/dl/images/vae_digits_manifold.png" alt="vae_digits_manifold.png"></a></p>
<p>OK这就是本文的全部，如果你觉得本文还可以增加点别的主题，可以在Twitter上<a href="https://github.com/fchollet"><strong>@fchollet</strong></a></p>
<h3 id="参考文献">参考文献</h3>
<ul>
<li> <p><a href="http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf"><font color="#FF0000">[1] Why does unsupervised pre-training help deep learning?</font></a></p> </li>
<li> <p><a href="http://arxiv.org/abs/1502.03167"><font color="#FF0000">[2] Batch normalization: Accelerating deep network training by reducing internal covariate shift.</font></a></p> </li>
<li> <p><a href="http://arxiv.org/abs/1512.03385"><font color="#FF0000">[3] Deep Residual Learning for Image Recognition</font></a></p> </li>
<li> <p><a href="http://arxiv.org/abs/1312.6114"><font color="#FF0000">[4] Auto-Encoding Variational Bayes</font></a></p> </li>
</ul>
</div>
<hr class="uk-article-divider">
<div class="uk-block uk-block-muted uk-padding-top-remove uk-padding-bottom-remove uk-margin-large-top  book-recommend-wrap">
<div class="uk-margin-top uk-margin-bottom uk-margin-left uk-margin-right">
<div class="uk-margin uk-text-muted "><i class="uk-icon-outdent uk-icon-justify uk-margin-small-right"></i>书籍推荐</div>
<div class="books">
<ul class="uk-book-list">
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/56/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/56/index.html">神经网络与深度学习</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/32.html">tigerneil</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">9页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月5日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 239个">239</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/62/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/62/index.html">Google 深度学习笔记</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/38.html">ahangchen</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">19页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年6月5日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 1243个">1243</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/129/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/machine-learning_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/129/index.html">机器学习实战</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/69.html">gaolinjie</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="machine-learning">machine-learning</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">18页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年7月8日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 10个">10</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/34/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/markdown_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/34/index.html">Markdown - 简单的世界</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/15.html">wizardforcel</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="markdown">markdown</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">16页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年5月3日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 159个">159</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/127/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/python_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/127/index.html">aiohttp 中文文档</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/68.html">HuberTRoy</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="python">python</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">124页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2018年7月8日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 34个">34</span>
</div>
</div>
</div>
</li>
<hr>
<li>
<div class="uk-book-item">
<div class="uk-book-header uk-clearfix">
<a href="../../../../book/193/index.html">
<img class="uk-book-cover" src="../../../../static/icons/48/html5_48.png" height="48px" alt="">
</a>
<h4 class="uk-book-title uk-margin-small-bottom"><a href="../../../../book/193/index.html">Pixi教程</a></h4>
<div class="uk-book-meta  uk-text-middle uk-float-left">
<a class="uk-margin-small-right  uk-text-middle user-name " href="../../../../user/109.html">Zainking</a>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-badge uk-badge-notification  book-subject" title="html5">html5</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">56页</span>
<span class="uk-margin-small-right  uk-text-middle">•</span>
<span class="uk-margin-small-right  uk-text-middle">2020年5月17日</span>
</div>
<div class="uk-book-tip uk-float-right  uk-text-middle">
<span class="uk-badge uk-badge-notification" title="github star 个"></span>
</div>
</div>
</div>
</li>
<hr>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<nav class="tm-navbar uk-navbar uk-navbar-attached reader-nav">
<div class="uk-float-left uk-margin-small-top">
<a href="javascript:;" title="目录菜单" class="show-menu  uk-icon-hover  uk-icon-align-justify uk-margin-right"></a>
<div data-uk-dropdown="{mode:'click',pos:'bottom-left'}" class="font-setting-wrap">
<a class="uk-icon-hover uk-icon-font uk-margin-right" aria-label="字体设置" href="javascript:;"></a>
<div class="uk-dropdown dropdown-menu">
<div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-reduce">小字</button>
<button class="uk-button-link button size-2 font-enlarge">大字</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-2 font-1 ">宋体</button>
<button class="uk-button-link button size-2 font-2 ">黑体</button>
</div>
<hr>
<div class="buttons uk-clearfix">
<button class="uk-button-link button size-3 color-theme-sun "><i class="uk-icon-sun-o"></i>白天</button>
<button class="uk-button-link button size-3 color-theme-eye "><i class="uk-icon-eye"></i>护眼</button>
<button class="uk-button-link button size-3 color-theme-moon "><i class="uk-icon-moon-o"></i>夜晚</button></div>
</div>
</div>
<a class="logo uk-margin-right" href="../../../../" title="返回首页"><img class="" src="../../../../static/components/images/icon_32.png" /></a>
</div>
<div class="uk-navbar-flip  uk-hidden-small">
<div id="share-box"></div>
</div>
</nav>
<div id="menu-id" class="uk-offcanvas reader-offcanvas">
<div class="uk-offcanvas-bar">
<ul class="book-menu-bar uk-nav uk-nav-offcanvas" data-uk-nav>
<li>
<a href="../../../../book/85/index.html" data-book-page-rel-url="index.html" data-book-page-id="0" title="封面">封面</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/readme.html" data-book-page-rel-url="readme.html" data-book-page-id="0" title="简介">简介</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/README.html" title="前言" data-book-page-rel-url="README.html" data-book-page-id="6588">前言</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/math.html" title="第一部分 数学基础" data-book-page-rel-url="math/math.html" data-book-page-id="6589">第一部分 数学基础</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/introduction.html" title="第一章 数学分析" data-book-page-rel-url="math/analytic/introduction.html" data-book-page-id="6590">第一章 数学分析</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/gradient_descent.html" title="梯度下降" data-book-page-rel-url="math/analytic/gradient_descent.html" data-book-page-id="6591">梯度下降</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/shu-zhi-ji-suan.html" title="数值计算" data-book-page-rel-url="math/analytic/shu-zhi-ji-suan.html" data-book-page-id="6592">数值计算</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/overfitting.html" title="过拟合数学原理与解决方案" data-book-page-rel-url="math/analytic/overfitting.html" data-book-page-id="6593">过拟合数学原理与解决方案</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/cross-validation.html" title="交叉验证" data-book-page-rel-url="math/analytic/cross-validation.html" data-book-page-id="6594">交叉验证</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/least-square.html" title="最小二乘" data-book-page-rel-url="math/analytic/least-square.html" data-book-page-id="6595">最小二乘</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/lagelangri-kkt.html" title="拉格朗日乘子法（Lagrange Multiplier) 和KKT条件" data-book-page-rel-url="math/analytic/lagelangri-kkt.html" data-book-page-id="6596">拉格朗日乘子法（Lagrange Multiplier) 和KKT条件</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/niudun.html" title="牛顿法" data-book-page-rel-url="math/analytic/niudun.html" data-book-page-id="6597">牛顿法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/tuyouhua.html" title="凸优化" data-book-page-rel-url="math/analytic/tuyouhua.html" data-book-page-id="6598">凸优化</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/analytic/common-function.html" title="常用函数" data-book-page-rel-url="math/analytic/common-function.html" data-book-page-id="6599">常用函数</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability.html" title="第二章 概率论" data-book-page-rel-url="math/probability.html" data-book-page-id="6600">第二章 概率论</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/math/probability/prob-methodology.html" title="统计学习方法概论" data-book-page-rel-url="math/probability/prob-methodology.html" data-book-page-id="6601">统计学习方法概论</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/mle.html" title="最大似然估计" data-book-page-rel-url="math/probability/mle.html" data-book-page-id="6602">最大似然估计</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/mcmc1.html" title="蒙特卡罗方法" data-book-page-rel-url="math/probability/mcmc1.html" data-book-page-id="6603">蒙特卡罗方法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/markov-chain.html" title="马尔科夫链" data-book-page-rel-url="math/probability/markov-chain.html" data-book-page-id="6604">马尔科夫链</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/mcmc-mh.html" title="MCMC采样和M-H采样" data-book-page-rel-url="math/probability/mcmc-mh.html" data-book-page-id="6605">MCMC采样和M-H采样</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/probability/gibbs.html" title="Gibbs采样" data-book-page-rel-url="math/probability/gibbs.html" data-book-page-id="6606">Gibbs采样</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/linear-matrix/linear-matrix.html" title="第三章 矩阵和线性代数" data-book-page-rel-url="math/linear-matrix/linear-matrix.html" data-book-page-id="6607">第三章 矩阵和线性代数</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/math/linear-matrix/lapack.html" title="LAPACK" data-book-page-rel-url="math/linear-matrix/lapack.html" data-book-page-id="6608">LAPACK</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/math/linear-matrix/tezhengzhihetezhengxiangliang.html" title="特征值与特征向量" data-book-page-rel-url="math/linear-matrix/tezhengzhihetezhengxiangliang.html" data-book-page-id="6609">特征值与特征向量</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/ml.html" title="第二部分 机器学习" data-book-page-rel-url="ml/ml.html" data-book-page-id="6610">第二部分 机器学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml.html" title="第四章 机器学习基础" data-book-page-rel-url="ml/pythonml.html" data-book-page-id="6611">第四章 机器学习基础</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/pythonji-qi-shu-xue-ku.html" title="Python及其数学库" data-book-page-rel-url="ml/pythonml/pythonji-qi-shu-xue-ku.html" data-book-page-id="6612">Python及其数学库</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/ji-qi-xue-xi-ku.html" title="机器学习库" data-book-page-rel-url="ml/pythonml/ji-qi-xue-xi-ku.html" data-book-page-id="6613">机器学习库</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/ml-metrics.html" title="模型度量" data-book-page-rel-url="ml/pythonml/ml-metrics.html" data-book-page-id="6614">模型度量</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/gen-descri.html" title="生成模型和判别模型" data-book-page-rel-url="ml/pythonml/gen-descri.html" data-book-page-id="6615">生成模型和判别模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/pythonml/distance.html" title="机器学习中的距离" data-book-page-rel-url="ml/pythonml/distance.html" data-book-page-id="6616">机器学习中的距离</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/cleanup-feature.html" title="第六课：数据清洗和特征选择" data-book-page-rel-url="ml/clean-feature/cleanup-feature.html" data-book-page-id="6617">第六课：数据清洗和特征选择</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/pca.html" title="PCA" data-book-page-rel-url="ml/clean-feature/pca.html" data-book-page-id="6618">PCA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/ica.html" title="ICA" data-book-page-rel-url="ml/clean-feature/ica.html" data-book-page-id="6619">ICA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/one-hot.html" title="One-hot编码" data-book-page-rel-url="ml/clean-feature/one-hot.html" data-book-page-id="6620">One-hot编码</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/scikit-pca.html" title="scikit-learn PCA" data-book-page-rel-url="ml/clean-feature/scikit-pca.html" data-book-page-id="6621">scikit-learn PCA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/xian-xing-pan-bie-fen-xi-lda.html" title="线性判别分析LDA" data-book-page-rel-url="ml/clean-feature/xian-xing-pan-bie-fen-xi-lda.html" data-book-page-id="6622">线性判别分析LDA</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/scikit-lda.html" title="用scikit-learn进行LDA降维" data-book-page-rel-url="ml/clean-feature/scikit-lda.html" data-book-page-id="6623">用scikit-learn进行LDA降维</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/svd.html" title="奇异值分解(SVD)原理与在降维中的应用" data-book-page-rel-url="ml/clean-feature/svd.html" data-book-page-id="6624">奇异值分解(SVD)原理与在降维中的应用</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/lle.html" title="局部线性嵌入(LLE)原理" data-book-page-rel-url="ml/clean-feature/lle.html" data-book-page-id="6625">局部线性嵌入(LLE)原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/scikit-lle.html" title="scikit-learn LLE" data-book-page-rel-url="ml/clean-feature/scikit-lle.html" data-book-page-id="6626">scikit-learn LLE</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/spark-fselect.html" title="spark特征选择" data-book-page-rel-url="ml/clean-feature/spark-fselect.html" data-book-page-id="6627">spark特征选择</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/spark-fextract.html" title="Spark特征提取" data-book-page-rel-url="ml/clean-feature/spark-fextract.html" data-book-page-id="6628">Spark特征提取</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/outlier-detect.html" title="异常数据监测" data-book-page-rel-url="ml/clean-feature/outlier-detect.html" data-book-page-id="6629">异常数据监测</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/datapreprocess.html" title="数据预处理" data-book-page-rel-url="ml/clean-feature/datapreprocess.html" data-book-page-id="6630">数据预处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/clean-feature/te-zheng-gong-cheng.html" title="特征工程" data-book-page-rel-url="ml/clean-feature/te-zheng-gong-cheng.html" data-book-page-id="6631">特征工程</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/regression.html" title="第七课： 回归" data-book-page-rel-url="ml/regression/regression.html" data-book-page-id="6632">第七课： 回归</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/linear-regression.html" title="1.  线性回归" data-book-page-rel-url="ml/regression/linear-regression.html" data-book-page-id="6633">1. 线性回归</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/max-entropy.html" title="10.最大熵模型" data-book-page-rel-url="ml/regression/max-entropy.html" data-book-page-id="6634">10.最大熵模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/kl.html" title="11.K-L散度" data-book-page-rel-url="ml/regression/kl.html" data-book-page-id="6635">11.K-L散度</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/cordinate-angle.html" title="坐标下降和最小角" data-book-page-rel-url="ml/regression/cordinate-angle.html" data-book-page-id="6636">坐标下降和最小角</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/linear-regression-summary.html" title="线性回归小结" data-book-page-rel-url="ml/regression/linear-regression-summary.html" data-book-page-id="6637">线性回归小结</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/logistic.html" title="Logistic回归" data-book-page-rel-url="ml/regression/logistic.html" data-book-page-id="6638">Logistic回归</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/logistichui-gui-xiao-jie.html" title="Logistic回归小结" data-book-page-rel-url="ml/regression/logistichui-gui-xiao-jie.html" data-book-page-id="6639">Logistic回归小结</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/regression/softmax.html" title="SoftMax回归" data-book-page-rel-url="ml/regression/softmax.html" data-book-page-id="6640">SoftMax回归</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree.html" title="第九课：决策树" data-book-page-rel-url="ml/decisiontree.html" data-book-page-id="6641">第九课：决策树</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/id3.html" title="ID3" data-book-page-rel-url="ml/decisiontree/id3.html" data-book-page-id="6642">ID3</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/c45.html" title="C4.5" data-book-page-rel-url="ml/decisiontree/c45.html" data-book-page-id="6643">C4.5</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/cart.html" title="CART" data-book-page-rel-url="ml/decisiontree/cart.html" data-book-page-id="6644">CART</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/summary.html" title="总结" data-book-page-rel-url="ml/decisiontree/summary.html" data-book-page-id="6645">总结</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/decisiontree/code.html" title="实现代码" data-book-page-rel-url="ml/decisiontree/code.html" data-book-page-id="6646">实现代码</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm.html" title="第十三课：SVM" data-book-page-rel-url="ml/svm.html" data-book-page-id="6647">第十三课：SVM</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/gan-zhi-ji-mo-xing.html" title="感知机模型" data-book-page-rel-url="ml/svm/gan-zhi-ji-mo-xing.html" data-book-page-id="6648">感知机模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/linear-svm.html" title="线性SVM" data-book-page-rel-url="ml/svm/linear-svm.html" data-book-page-id="6649">线性SVM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/soft-margin-max.html" title="软间隔最大化模型" data-book-page-rel-url="ml/svm/soft-margin-max.html" data-book-page-id="6650">软间隔最大化模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/kernel-method.html" title="核函数" data-book-page-rel-url="ml/svm/kernel-method.html" data-book-page-id="6651">核函数</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/smo.html" title="SMO算法原理" data-book-page-rel-url="ml/svm/smo.html" data-book-page-id="6652">SMO算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/svm-regression.html" title="SVM回归" data-book-page-rel-url="ml/svm/svm-regression.html" data-book-page-id="6653">SVM回归</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/scikit-learn-svm.html" title="scikit-learn SVM" data-book-page-rel-url="ml/svm/scikit-learn-svm.html" data-book-page-id="6654">scikit-learn SVM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/gaosi-kernel.html" title="支持向量机高斯核调参" data-book-page-rel-url="ml/svm/gaosi-kernel.html" data-book-page-id="6655">支持向量机高斯核调参</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/svm/svm-code.html" title="SVM代码实现" data-book-page-rel-url="ml/svm/svm-code.html" data-book-page-id="6656">SVM代码实现</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate.html" title="集成学习" data-book-page-rel-url="ml/integrate.html" data-book-page-id="6657">集成学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/adaboost.html" title="Adaboost原理" data-book-page-rel-url="ml/integrate/adaboost.html" data-book-page-id="6658">Adaboost原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/scikit-learn-adaboost.html" title="scikit-learn Adaboost" data-book-page-rel-url="ml/integrate/scikit-learn-adaboost.html" data-book-page-id="6659">scikit-learn Adaboost</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/gbdt.html" title="梯度提升树（GBDT）" data-book-page-rel-url="ml/integrate/gbdt.html" data-book-page-id="6660">梯度提升树（GBDT）</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/scikit-gbdt.html" title="scikit GBDT" data-book-page-rel-url="ml/integrate/scikit-gbdt.html" data-book-page-id="6661">scikit GBDT</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/random-forest.html" title="Bagging与随机森林" data-book-page-rel-url="ml/integrate/random-forest.html" data-book-page-id="6662">Bagging与随机森林</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/xgboost.html" title="XGBOOST" data-book-page-rel-url="ml/integrate/xgboost.html" data-book-page-id="6663">XGBOOST</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/integrate/scikit-learn-rf.html" title="scikit-learn 随机森林" data-book-page-rel-url="ml/integrate/scikit-learn-rf.html" data-book-page-id="6664">scikit-learn 随机森林</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster.html" title="第十五课：聚类" data-book-page-rel-url="ml/cluster.html" data-book-page-id="6665">第十五课：聚类</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/kmeans.html" title="K-Mean" data-book-page-rel-url="ml/cluster/kmeans.html" data-book-page-id="6666">K-Mean</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/KNN.html" title="KNN" data-book-page-rel-url="ml/cluster/KNN.html" data-book-page-id="6667">KNN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/knnshi-jian.html" title="scikit-learn KNN" data-book-page-rel-url="ml/cluster/knnshi-jian.html" data-book-page-id="6668">scikit-learn KNN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/knn-code.html" title="KNN 代码" data-book-page-rel-url="ml/cluster/knn-code.html" data-book-page-id="6669">KNN 代码</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-k-means.html" title="scikit-learn K-Means" data-book-page-rel-url="ml/cluster/scikit-k-means.html" data-book-page-id="6670">scikit-learn K-Means</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/birch.html" title="BIRCH聚类算法原理" data-book-page-rel-url="ml/cluster/birch.html" data-book-page-id="6671">BIRCH聚类算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-learn-birch.html" title="scikit-learn BIRCH" data-book-page-rel-url="ml/cluster/scikit-learn-birch.html" data-book-page-id="6672">scikit-learn BIRCH</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/dbscan.html" title="DBSCAN密度聚类算法" data-book-page-rel-url="ml/cluster/dbscan.html" data-book-page-id="6673">DBSCAN密度聚类算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-learn-dbscan.html" title="scikit-learn DBSCAN" data-book-page-rel-url="ml/cluster/scikit-learn-dbscan.html" data-book-page-id="6674">scikit-learn DBSCAN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/spectral.html" title="谱聚类（spectral clustering）原理" data-book-page-rel-url="ml/cluster/spectral.html" data-book-page-id="6675">谱聚类（spectral clustering）原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/scikit-spectral.html" title="scikit-learn 谱聚类" data-book-page-rel-url="ml/cluster/scikit-spectral.html" data-book-page-id="6676">scikit-learn 谱聚类</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/ap.html" title="近邻传播算法" data-book-page-rel-url="ml/cluster/ap.html" data-book-page-id="6677">近邻传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/cluster/gmm.html" title="混合高斯模型" data-book-page-rel-url="ml/cluster/gmm.html" data-book-page-id="6678">混合高斯模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/associative.html" title="关联分析" data-book-page-rel-url="ml/associative/associative.html" data-book-page-id="6679">关联分析</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/cca.html" title="典型关联分析(CCA)原理" data-book-page-rel-url="ml/associative/cca.html" data-book-page-id="6680">典型关联分析(CCA)原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/apriori.html" title="Apriori算法原理" data-book-page-rel-url="ml/associative/apriori.html" data-book-page-id="6681">Apriori算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/fptree.html" title="FP Tree算法原理" data-book-page-rel-url="ml/associative/fptree.html" data-book-page-id="6682">FP Tree算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/prefixspan.html" title="PrefixSpan算法原理" data-book-page-rel-url="ml/associative/prefixspan.html" data-book-page-id="6683">PrefixSpan算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/associative/spark-fptree-prefixspan.html" title="Spark FP Tree算法和PrefixSpan算法" data-book-page-rel-url="ml/associative/spark-fptree-prefixspan.html" data-book-page-id="6684">Spark FP Tree算法和PrefixSpan算法</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/recommand.html" title="推荐算法" data-book-page-rel-url="ml/recommand/recommand.html" data-book-page-id="6685">推荐算法</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/matrix-filter.html" title="矩阵分解协同过滤推荐算法" data-book-page-rel-url="ml/recommand/matrix-filter.html" data-book-page-id="6686">矩阵分解协同过滤推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/simrank.html" title="SimRank协同过滤推荐算法" data-book-page-rel-url="ml/recommand/simrank.html" data-book-page-id="6687">SimRank协同过滤推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recomand/spark-factor.html" title="Spark矩阵分解推荐算法" data-book-page-rel-url="ml/recomand/spark-factor.html" data-book-page-id="6688">Spark矩阵分解推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/fm.html" title="分解机(Factorization Machines)推荐算法原理" data-book-page-rel-url="ml/recommand/fm.html" data-book-page-id="6689">分解机(Factorization Machines)推荐算法原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/meituan.html" title="美团推荐算法" data-book-page-rel-url="ml/recommand/meituan.html" data-book-page-id="6690">美团推荐算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/mr-itemcf.html" title="MapReduce ItemCF" data-book-page-rel-url="ml/recommand/mr-itemcf.html" data-book-page-id="6691">MapReduce ItemCF</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/recommand/label-recommand.html" title="基于标签的用户推荐系统" data-book-page-rel-url="ml/recommand/label-recommand.html" data-book-page-id="6692">基于标签的用户推荐系统</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/em/em.html" title="第十七课：EM算法" data-book-page-rel-url="ml/em/em.html" data-book-page-id="6693">第十七课：EM算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes.html" title="第十九课：贝叶斯网络" data-book-page-rel-url="ml/bayes.html" data-book-page-id="6694">第十九课：贝叶斯网络</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/po-su-bei-xie-si.html" title="朴素贝叶斯" data-book-page-rel-url="ml/bayes/po-su-bei-xie-si.html" data-book-page-id="6695">朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/scikit-simple-bayes.html" title="scikit-learn朴素贝叶斯" data-book-page-rel-url="ml/bayes/scikit-simple-bayes.html" data-book-page-id="6696">scikit-learn朴素贝叶斯</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/simple-bayes-real-use.html" title="朴素贝叶斯实际应用" data-book-page-rel-url="ml/bayes/simple-bayes-real-use.html" data-book-page-id="6697">朴素贝叶斯实际应用</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/bayes/simple-bayes-code.html" title="朴素贝叶斯代码" data-book-page-rel-url="ml/bayes/simple-bayes-code.html" data-book-page-id="6698">朴素贝叶斯代码</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/lda/lda.html" title="第二十一课：LDA主题模型" data-book-page-rel-url="ml/lda/lda.html" data-book-page-id="6699">第二十一课：LDA主题模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/hmm.html" title="第二十三课：隐马尔科夫模型HMM" data-book-page-rel-url="ml/hmm/hmm.html" data-book-page-id="6700">第二十三课：隐马尔科夫模型HMM</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/hmm-forward-backward.html" title="HMM前向后向算法评估观察序列概率" data-book-page-rel-url="ml/hmm/hmm-forward-backward.html" data-book-page-id="6701">HMM前向后向算法评估观察序列概率</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/bmwl-hmm.html" title="鲍姆-韦尔奇算法求解HMM参数" data-book-page-rel-url="ml/hmm/bmwl-hmm.html" data-book-page-id="6702">鲍姆-韦尔奇算法求解HMM参数</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/viterb-hmm.html" title="维特比算法解码隐藏状态序列" data-book-page-rel-url="ml/hmm/viterb-hmm.html" data-book-page-id="6703">维特比算法解码隐藏状态序列</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/hmmlearn.html" title="用hmmlearn学习隐马尔科夫模型HMM" data-book-page-rel-url="ml/hmm/hmmlearn.html" data-book-page-id="6704">用hmmlearn学习隐马尔科夫模型HMM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/hmm/markv-mengtekluo.html" title="马尔科夫蒙特卡洛" data-book-page-rel-url="ml/hmm/markv-mengtekluo.html" data-book-page-id="6705">马尔科夫蒙特卡洛</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/crf.html" title="条件随机场CRF" data-book-page-rel-url="ml/crf/crf.html" data-book-page-id="6706">条件随机场CRF</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/linear-crf.html" title="从随机场到线性链条件随机场" data-book-page-rel-url="ml/crf/linear-crf.html" data-book-page-id="6707">从随机场到线性链条件随机场</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/back-forth.html" title="前向后向算法评估标记序列概率" data-book-page-rel-url="ml/crf/back-forth.html" data-book-page-id="6708">前向后向算法评估标记序列概率</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/crf/crf-viterbi.html" title="维特比算法解码" data-book-page-rel-url="ml/crf/crf-viterbi.html" data-book-page-id="6709">维特比算法解码</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/dl.html" title="第三部分 深度学习" data-book-page-rel-url="dl/dl.html" data-book-page-id="6710">第三部分 深度学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/layers.html" title="深度学习层" data-book-page-rel-url="dl/layers/layers.html" data-book-page-id="6711">深度学习层</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/core.html" title="核心层" data-book-page-rel-url="dl/layers/core.html" data-book-page-id="6712">核心层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/conv.html" title="卷积层" data-book-page-rel-url="dl/layers/conv.html" data-book-page-id="6713">卷积层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/pooling.html" title="池化层" data-book-page-rel-url="dl/layers/pooling.html" data-book-page-id="6714">池化层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/lcnn.html" title="局部连接层" data-book-page-rel-url="dl/layers/lcnn.html" data-book-page-id="6715">局部连接层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/rnn.html" title="循环层" data-book-page-rel-url="dl/layers/rnn.html" data-book-page-id="6716">循环层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/ebbedded.html" title="嵌入层" data-book-page-rel-url="dl/layers/ebbedded.html" data-book-page-id="6717">嵌入层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/merge.html" title="合并层" data-book-page-rel-url="dl/layers/merge.html" data-book-page-id="6718">合并层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/activation.html" title="高级激活层" data-book-page-rel-url="dl/layers/activation.html" data-book-page-id="6719">高级激活层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/regular.html" title="归一化层" data-book-page-rel-url="dl/layers/regular.html" data-book-page-id="6720">归一化层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/nosie.html" title="噪声层" data-book-page-rel-url="dl/layers/nosie.html" data-book-page-id="6721">噪声层</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/wrapper.html" title="层包裹" data-book-page-rel-url="dl/layers/wrapper.html" data-book-page-id="6722">层包裹</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/layers/userdefine.html" title="自定义层" data-book-page-rel-url="dl/layers/userdefine.html" data-book-page-id="6723">自定义层</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/introduction.html" title="第二十五课：深度学习" data-book-page-rel-url="dl/introduction/introduction.html" data-book-page-id="6724">第二十五课：深度学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/ji-ben-gai-nian.html" title="基本概念" data-book-page-rel-url="dl/introduction/ji-ben-gai-nian.html" data-book-page-id="6725">基本概念</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-fp.html" title="深度神经网络（DNN）模型与前向传播算法" data-book-page-rel-url="dl/introduction/dnn-fp.html" data-book-page-id="6726">深度神经网络（DNN）模型与前向传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-bp.html" title="深度神经网络（DNN）反向传播算法(BP)" data-book-page-rel-url="dl/introduction/dnn-bp.html" data-book-page-id="6727">深度神经网络（DNN）反向传播算法(BP)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/back-propagation.html" title="反向传播" data-book-page-rel-url="dl/introduction/back-propagation.html" data-book-page-id="6728">反向传播</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/READ.html" title="反向传播2" data-book-page-rel-url="dl/introduction/READ.html" data-book-page-id="6729">反向传播2</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-loss.html" title="DNN损失函数和激活函数的选择" data-book-page-rel-url="dl/introduction/dnn-loss.html" data-book-page-id="6730">DNN损失函数和激活函数的选择</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/introduction/dnn-normal.html" title="深度神经网络（DNN）的正则化" data-book-page-rel-url="dl/introduction/dnn-normal.html" data-book-page-id="6731">深度神经网络（DNN）的正则化</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reference.html" title="参考文献" data-book-page-rel-url="dl/reference.html" data-book-page-id="6732">参考文献</a>
</li>
</ul>
</li>
<li>
l="dl/introduction/dnn-normal.html" data-book-page-id="6731">深度神经网络（DNN）的正则化</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reference.html" title="参考文献" data-book-page-rel-url="dl/reference.html" data-book-page-id="6732">参考文献</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/introduction.html" title="第二十六课 卷积神 经网络(Convolutional Neural Netowrk)" data-book-page-rel-url="dl/cnn/introduction.html" data-book-page-id="6733">第二十六课 卷积神 经网络(Convolutional Neural Netowrk)</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/cnn-arch.html" title="卷积神经网络(CNN)模型结构" data-book-page-rel-url="dl/cnn/cnn-arch.html" data-book-page-id="6734">卷积神经网络(CNN)模型结构</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/cnn-fp.html" title="卷积神经网络(CNN)前向传播算法" data-book-page-rel-url="dl/cnn/cnn-fp.html" data-book-page-id="6735">卷积神经网络(CNN)前向传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/cnn/cnn-bp.html" title="卷积神经网络(CNN)反向传播算法" data-book-page-rel-url="dl/cnn/cnn-bp.html" data-book-page-id="6736">卷积神经网络(CNN)反向传播算法</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/gan.html" title="对抗生成网络(Generative Adversarial Networks)" data-book-page-rel-url="dl/gan/gan.html" data-book-page-id="6737">对抗生成网络(Generative Adversarial Networks)</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/gan/gan-principle.html" title="GAN原理" data-book-page-rel-url="ml/gan/gan-principle.html" data-book-page-id="6738">GAN原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/infogan.html" title="InfoGAN" data-book-page-rel-url="dl/gan/infogan.html" data-book-page-id="6739">InfoGAN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/dcgan.html" title="DCGAN" data-book-page-rel-url="dl/gan/dcgan.html" data-book-page-id="6740">DCGAN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/gan/vae.html" title="VAE" data-book-page-rel-url="dl/gan/vae.html" data-book-page-id="6741">VAE</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/rbm.html" title="受限波尔兹曼机" data-book-page-rel-url="dl/rbm/rbm.html" data-book-page-id="6742">受限波尔兹曼机</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/rbm-code.html" title="RBM code" data-book-page-rel-url="dl/rbm/rbm-code.html" data-book-page-id="6743">RBM code</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/dbn.html" title="DBN" data-book-page-rel-url="dl/rbm/dbn.html" data-book-page-id="6744">DBN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rbm/rbm-yuanli.html" title="RBM原理" data-book-page-rel-url="dl/rbm/rbm-yuanli.html" data-book-page-id="6745">RBM原理</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/rnn.html" title="RNN" data-book-page-rel-url="dl/rnn/rnn.html" data-book-page-id="6746">RNN</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/bidirectional-rnns.html" title="Bidirectional RNNs" data-book-page-rel-url="dl/rnn/bidirectional-rnns.html" data-book-page-id="6747">Bidirectional RNNs</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/deep-bidirectional-rnns.html" title="Deep (Bidirectional) RNNs" data-book-page-rel-url="dl/rnn/deep-bidirectional-rnns.html" data-book-page-id="6748">Deep (Bidirectional) RNNs</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/lstm.html" title="LSTM模型与前向反向传播算法" data-book-page-rel-url="dl/rnn/lstm.html" data-book-page-id="6749">LSTM模型与前向反向传播算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/bptt.html" title="随时间反向传播（BPTT）算法" data-book-page-rel-url="dl/rnn/bptt.html" data-book-page-id="6750">随时间反向传播（BPTT）算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/rnn/rnn-bptt.html" title="循环神经网络(RNN)模型与前向反向传播算法" data-book-page-rel-url="dl/rnn/rnn-bptt.html" data-book-page-id="6751">循环神经网络(RNN)模型与前向反向传播算法</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/encoder.html" title="自动编码器" data-book-page-rel-url="dl/encoder/encoder.html" data-book-page-id="6752">自动编码器</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/stack-denoise-encoder.html" title="堆叠降噪自动编码器" data-book-page-rel-url="dl/encoder/stack-denoise-encoder.html" data-book-page-id="6753">堆叠降噪自动编码器</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/denoise-encoder.html" title="降噪自动编码器" data-book-page-rel-url="dl/encoder/denoise-encoder.html" data-book-page-id="6754">降噪自动编码器</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/sparse-autoencoder.html" title="sparse自动编码器" data-book-page-rel-url="dl/encoder/sparse-autoencoder.html" data-book-page-id="6755">sparse自动编码器</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/encoder/keras-autoencoder.html" title="Keras自动编码器" data-book-page-rel-url="dl/encoder/keras-autoencoder.html" data-book-page-id="6756">Keras自动编码器</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/word2vec.html" title="word2vec" data-book-page-rel-url="dl/word2vec/word2vec.html" data-book-page-id="6757">word2vec</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/cbow-skip-n.html" title="CBOW与Skip-Gram模型基础" data-book-page-rel-url="dl/word2vec/cbow-skip-n.html" data-book-page-id="6758">CBOW与Skip-Gram模型基础</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/hierarc-softmax.html" title="基于Hierarchical Softmax的模型" data-book-page-rel-url="dl/word2vec/hierarc-softmax.html" data-book-page-id="6759">基于Hierarchical Softmax的模型</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/word2vec/negative-sampling.html" title="基于Negative Sampling的模型" data-book-page-rel-url="dl/word2vec/negative-sampling.html" data-book-page-id="6760">基于Negative Sampling的模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/reinforcement.html" title="增强学习" data-book-page-rel-url="dl/reinforcement/reinforcement.html" data-book-page-id="6761">增强学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/q-learning.html" title="Q-Learning" data-book-page-rel-url="dl/reinforcement/q-learning.html" data-book-page-id="6762">Q-Learning</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/policy-network.html" title="策略网络" data-book-page-rel-url="dl/reinforcement/policy-network.html" data-book-page-id="6763">策略网络</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/banditsuan-fa.html" title="bandit算法" data-book-page-rel-url="dl/reinforcement/banditsuan-fa.html" data-book-page-id="6764">bandit算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/meng-te-qia-luo-shu-sou-suo.html" title="蒙特卡洛树搜索" data-book-page-rel-url="dl/reinforcement/meng-te-qia-luo-shu-sou-suo.html" data-book-page-id="6765">蒙特卡洛树搜索</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/multi-bandit.html" title="多臂赌博机(Multi-arm Bandits)" data-book-page-rel-url="dl/reinforcement/multi-bandit.html" data-book-page-id="6766">多臂赌博机(Multi-arm Bandits)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/mdp.html" title="马尔可夫决策过程MDP" data-book-page-rel-url="dl/reinforcement/mdp.html" data-book-page-id="6767">马尔可夫决策过程MDP</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/dynamic-programming.html" title="动态编程" data-book-page-rel-url="dl/reinforcement/dynamic-programming.html" data-book-page-id="6768">动态编程</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/monte-carlo.html" title="蒙特卡洛方法" data-book-page-rel-url="dl/reinforcement/monte-carlo.html" data-book-page-id="6769">蒙特卡洛方法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/shi-xu-cha-fen-xue-xi.html" title="时序差分学习" data-book-page-rel-url="dl/reinforcement/shi-xu-cha-fen-xue-xi.html" data-book-page-id="6770">时序差分学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/a3csuan-fa.html" title="A3C算法" data-book-page-rel-url="dl/reinforcement/a3csuan-fa.html" data-book-page-id="6771">A3C算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/multi-steps-bootstraping.html" title="Multi-steps bootstraping" data-book-page-rel-url="dl/reinforcement/multi-steps-bootstraping.html" data-book-page-id="6772">Multi-steps bootstraping</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/tabular-method.html" title="Planning and Learning with Tabular Methods" data-book-page-rel-url="dl/reinforcement/tabular-method.html" data-book-page-id="6773">Planning and Learning with Tabular Methods</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/dqn.html" title="DQN" data-book-page-rel-url="dl/reinforcement/dqn.html" data-book-page-id="6774">DQN</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/policy-gridient.html" title="Policy Gridient" data-book-page-rel-url="dl/reinforcement/policy-gridient.html" data-book-page-id="6775">Policy Gridient</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/actor-critic.html" title="Actor Critic" data-book-page-rel-url="dl/reinforcement/actor-critic.html" data-book-page-id="6776">Actor Critic</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/ddpg.html" title="DDPG (Deep Deterministic Policy Gradient)" data-book-page-rel-url="dl/reinforcement/ddpg.html" data-book-page-id="6777">DDPG (Deep Deterministic Policy Gradient)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/ppo.html" title="PPO(Proximal Policy Optimization )" data-book-page-rel-url="dl/reinforcement/ppo.html" data-book-page-id="6778">PPO(Proximal Policy Optimization )</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/reinforcement/alpha-beta.html" title="Alpha-Beta剪枝算法详解" data-book-page-rel-url="dl/reinforcement/alpha-beta.html" data-book-page-id="6779">Alpha-Beta剪枝算法详解</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/evolution/evolution.html" title="进化算法" data-book-page-rel-url="ml/evolution/evolution.html" data-book-page-id="6780">进化算法</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/ml/evolution/yichuansuanfa.html" title="遗传算法" data-book-page-rel-url="ml/evolution/yichuansuanfa.html" data-book-page-id="6781">遗传算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/ml/evolution/evolution-strategy.html" title="进化策略" data-book-page-rel-url="ml/evolution/evolution-strategy.html" data-book-page-id="6782">进化策略</a>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="NEAT" disabled data-book-page-rel-url="ml/evolution/neat.html" data-book-page-id="6783">NEAT</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/nlp.html" title="自然语言处理" data-book-page-rel-url="nlp/nlp.html" data-book-page-id="6784">自然语言处理</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/nlp/text-mine.html" title="文本挖掘的分词原理" data-book-page-rel-url="nlp/text-mine.html" data-book-page-id="6785">文本挖掘的分词原理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/hashtrick.html" title="HashTrick" data-book-page-rel-url="nlp/hashtrick.html" data-book-page-id="6786">HashTrick</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/tf-idf.html" title="TF-IDF" data-book-page-rel-url="nlp/tf-idf.html" data-book-page-id="6787">TF-IDF</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/preprocessing.html" title="中文文本挖掘预处理" data-book-page-rel-url="nlp/preprocessing.html" data-book-page-id="6788">中文文本挖掘预处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/english-preprocess.html" title="英文文本挖掘预处理" data-book-page-rel-url="nlp/english-preprocess.html" data-book-page-id="6789">英文文本挖掘预处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/lsi.html" title="潜在语义索引(LSI)" data-book-page-rel-url="nlp/lda/lsi.html" data-book-page-id="6790">潜在语义索引(LSI)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/nmf.html" title="非负矩阵分解(NMF)" data-book-page-rel-url="nlp/lda/nmf.html" data-book-page-id="6791">非负矩阵分解(NMF)</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/lda.html" title="LDA基础" data-book-page-rel-url="nlp/lda/lda.html" data-book-page-id="6792">LDA基础</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/lda-gibbs.html" title="LDA求解之Gibbs采样算法" data-book-page-rel-url="nlp/lda/lda-gibbs.html" data-book-page-id="6793">LDA求解之Gibbs采样算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/vi-em.html" title="LDA求解之变分推断EM算法" data-book-page-rel-url="nlp/lda/vi-em.html" data-book-page-id="6794">LDA求解之变分推断EM算法</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/nlp/lda/scikit-learn-lda.html" title="scikit-learn LDA主题模型" data-book-page-rel-url="nlp/lda/scikit-learn-lda.html" data-book-page-id="6795">scikit-learn LDA主题模型</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/voice/introduction.html" title="语音识别" data-book-page-rel-url="voice/introduction.html" data-book-page-id="6796">语音识别</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/voice/gmm-hmm.html" title="GMM-HMM" data-book-page-rel-url="voice/gmm-hmm.html" data-book-page-id="6797">GMM-HMM</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/voice/voicemulumd.html" title="目录" data-book-page-rel-url="voice/voicemulumd.html" data-book-page-id="6798">目录</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/introduction.html" title="第四部分 学习资源" data-book-page-rel-url="resources/introduction.html" data-book-page-id="6799">第四部分 学习资源</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/resources/ml/list.html" title="机器学习" data-book-page-rel-url="resources/ml/list.html" data-book-page-id="6800">机器学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/rl/list.html" title="强化学习" data-book-page-rel-url="resources/rl/list.html" data-book-page-id="6801">强化学习</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/nlp/list.html" title="自然语言处理" data-book-page-rel-url="resources/nlp/list.html" data-book-page-id="6802">自然语言处理</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/resources/dl/list.html" title="深度学习" data-book-page-rel-url="resources/dl/list.html" data-book-page-id="6803">深度学习</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="流行网络结构" disabled data-book-page-rel-url="" data-book-page-id="6804">流行网络结构</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/popnet/mobilenet.html" title="mobilenet" data-book-page-rel-url="dl/popnet/mobilenet.html" data-book-page-id="6805">mobilenet</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/popnet/resnet.html" title="ResNet" data-book-page-rel-url="dl/popnet/resnet.html" data-book-page-id="6806">ResNet</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="并行学习" disabled data-book-page-rel-url="" data-book-page-id="6807">并行学习</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/paralleldl/mei-tuan-bing-xing-xue-xi-shi-jian.html" title="美团并行学习实践" data-book-page-rel-url="dl/paralleldl/mei-tuan-bing-xing-xue-xi-shi-jian.html" data-book-page-id="6808">美团并行学习实践</a>
</li>
</ul>
</li>
<li>
<a class="pjax" href="javascript:;" class="uk-link-muted uk-text-muted" title="AI应用" disabled data-book-page-rel-url="" data-book-page-id="6809">AI应用</a>
<ul>
<li>
<a class="pjax" href="../../../../book/85/dl/dlapp/mei-tuan-wai-mai-ai-ji-zhu.html" title="美团外卖AI技术" data-book-page-rel-url="dl/dlapp/mei-tuan-wai-mai-ai-ji-zhu.html" data-book-page-id="6810">美团外卖AI技术</a>
</li>
<li>
<a class="pjax" href="../../../../book/85/dl/dlapp/mei-tuan-tui-jian-pai-xu.html" title="美团推荐排序" data-book-page-rel-url="dl/dlapp/mei-tuan-tui-jian-pai-xu.html" data-book-page-id="6811">美团推荐排序</a>
</li>
</ul>
</li>
</ul>
</div>
</div>
<script src="https://cdn.staticfile.net/jquery/1.12.4/jquery.min.js"></script>
<script type="text/javascript" src="../../../../static/components/uikit-2.27.5/js/uikit.reader.js"></script>
<script type="text/javascript" src="../../../../static/components/social-share/social-share.min.js"></script>
<script>(function(){var bp =document.createElement('script');var curProtocol =window.location.protocol.split(':')[0];if (curProtocol ==='https') {bp.src ='https://zz.bdstatic.com/linksubmit/push.js';}
else {bp.src ='http://push.zhanzhang.baidu.com/push.js';}
var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp,s);})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
<script src="https://cdn.staticfile.net/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.net/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>
<script src="https://cdn.staticfile.net/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="https://cdn.staticfile.net/uikit/2.27.5/js/components/lightbox.min.js"></script>
<link rel="dns-prefetch" href="../../../..//cdn.mathjax.org" />
<script type="text/x-mathjax-config">
 function initMathJax() {
    var mathId = $("book-content-section")[0];
    MathJax.Hub.Config({
        tex2jax: {skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a']},
        showProcessingMessages: false,
        messageStyle: "none"
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub,mathId]);
 };
initMathJax();
</script>
<script src='https://cdn.staticfile.net/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML' async></script>
<style>
	.MathJax_Display{display:inline!important;}
</style>
<script type="text/javascript" src="../../../../static/components/js/reader.js"></script>
<script type="text/javascript">var bookId =85;var bookPageId =6756;var bookPageRelUrl ='dl/encoder/keras-autoencoder.html';</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-38429407-1"></script>
<script>window.dataLayer =window.dataLayer ||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-38429407-1');</script>
<script>var _hmt =_hmt ||[];(function() {var hm =document.createElement("script");hm.src ="https://hm.baidu.com/hm.js?f28e71bd2b5dee3439448dca9f534107";var s =document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm,s);})();</script>
</body>
</html>